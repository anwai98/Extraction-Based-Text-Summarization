{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summariser v5.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5v3IIfHigR2",
        "colab_type": "code",
        "outputId": "39a3ab54-248f-4d4c-93a0-4e6ec175c7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#importing the natural language toolkit and downloading the important libraries\n",
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHquqwDjipTl",
        "colab_type": "code",
        "outputId": "3e71dfec-0d41-4e33-d714-7a05b3563a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#installing docx2text library\n",
        "pip install docx2txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.6/dist-packages (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oeu66PgIjQYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing docx2text and changing the docx file imported to text \n",
        "import docx2txt\n",
        "k = docx2txt.process(\"text.docx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDLMnKZqjV_l",
        "colab_type": "code",
        "outputId": "854bd8fe-78b2-4b76-acfb-e8baa293cddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#finding the number of characters in the text saved as in the name k\n",
        "len(k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QBtMoUUjYtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenization basically refers to splitting up a larger body of text into smaller lines, words or even creating words for a non-English language.\n",
        "#importing sent_tokenize function from nltk and sentence tokenizing the text \n",
        "from nltk.tokenize import sent_tokenize\n",
        "corpus=sent_tokenize(k)\n",
        "cor=corpus.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kipUJB26jdi8",
        "colab_type": "code",
        "outputId": "6f1f3e69-8c0c-4318-c292-60c3fa8edd9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#finding the number of sentences\n",
        "len(cor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ1HJFNAjhbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the re library and cleaning the text of any punctuation marks, numbers and eddy spaces\n",
        "import re\n",
        "corpuss=[]\n",
        "for k in corpus:\n",
        "  text = re.sub('[^a-zA-Z]', ' ', k)#allows just a-z and A-Z and replaces all other characters with space\n",
        "  text = re.sub(r'\\s+', ' ', text)#replaces multiple space sequences with a single space\n",
        "  corpuss.append(text)\n",
        "corpus=corpuss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77YWqMGNjp-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#changing all the alphabetic characters to lower space\n",
        "import string\n",
        "corpuss=[s.lower() for s in corpus]\n",
        "corpus=corpuss.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8dJlIf_juHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing all the stopwords in the english language from the nltk package\n",
        "from nltk.corpus import stopwords\n",
        "stop_words=stopwords.words('english')\n",
        "def remove_stopwords(sen):                 ## Here we are removing all the stopwords form the sentence\n",
        "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
        "    return sen_new\n",
        "cleaned = [remove_stopwords(r.split()) for r in corpuss]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiV3xydVEVqx",
        "colab_type": "code",
        "outputId": "14181404-60fd-47c2-fa13-ff3928ff5b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(stop_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX8x8ilujxnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#here we are defining a method to word tokenize\n",
        "def Tokenization(corpus):        \n",
        "    y=[]\n",
        "    for i in range(0,len(corpus)):\n",
        "      a=corpus[i].split(\" \")\n",
        "      y.append(a)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3TSN3dTkArV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining a function to renove stop words and calling the Tokenization method to tokenize\n",
        "def remove_stop_words(corpus):\n",
        " \n",
        "    stop_words = nltk.corpus.stopwords.words('english')\n",
        "  \n",
        "    corpus_wo_stopwords=[]\n",
        "    a=Tokenization(corpus)\n",
        "    for i in a:\n",
        "      x=[]\n",
        "      for j in i:\n",
        "        if j not in stop_words:\n",
        "          x=x+[j]\n",
        "      corpus_wo_stopwords+=[x]\n",
        "        \n",
        "    return corpus_wo_stopwords\n",
        "#word tokenizing the raw text and removing stopwords from a copy of the raw text that we have kept untouched without doing sentence tokenization because these words will be used to find their word vectors    \n",
        "PP_corpus = remove_stop_words(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvbFVWofkIOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the unique words from the word tokenized list\n",
        "def get_unique_words(PP_corpus):\n",
        "    unique_words=set()\n",
        "    for i in PP_corpus:\n",
        "      for j in i:\n",
        "          unique_words.add(j)\n",
        "    return unique_words\n",
        "  \n",
        "unique_words = get_unique_words(PP_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW-w5db0kQTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mapping each unique words in a dictionry against an integer\n",
        "def mapping(unique_words):\n",
        "    y1=unique_words\n",
        "    ind=list(range(len(y1)))\n",
        "    d = {k:v for k,v in zip(y1,ind)}\n",
        "    return d\n",
        "    \n",
        "word2int = mapping(unique_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_7kQVtrkcO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the data using skip gram model.Skip gram model here is giving us the output as a list of tuples where each tuple has two elements. The first element is the centre word and the second element is the context word. It depends on thewindow length we have provided. \n",
        "import pandas as pd\n",
        "\n",
        "def data_gen(PP_corpus, window_size):\n",
        "   \n",
        "    w=window_size\n",
        "    y=PP_corpus\n",
        "    li=[]\n",
        "    k=0\n",
        "    for i in range(len(y)):\n",
        "      for j in range(len(y[i])):\n",
        "        for h in range(-w,w+1):\n",
        "          if(j+h>=0 and j+h<len(y[i])):\n",
        "            if(not(j==j+h)):\n",
        "              li+=[(y[i][j],y[i][j+h])]\n",
        "    data = li   \n",
        "\n",
        "    return data\n",
        "\n",
        "    \n",
        "data = data_gen(PP_corpus, 2)\n",
        "df = pd.DataFrame(data, columns = ['input', 'label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_afSaMF1ZVQx",
        "colab_type": "code",
        "outputId": "5bf12292-2b5a-4f27-a350-2c3e52f211a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('artificial', 'intelligence'),\n",
              " ('artificial', 'ai'),\n",
              " ('intelligence', 'artificial'),\n",
              " ('intelligence', 'ai'),\n",
              " ('intelligence', 'science'),\n",
              " ('ai', 'artificial'),\n",
              " ('ai', 'intelligence'),\n",
              " ('ai', 'science'),\n",
              " ('ai', 'set'),\n",
              " ('science', 'intelligence'),\n",
              " ('science', 'ai'),\n",
              " ('science', 'set'),\n",
              " ('science', 'computational'),\n",
              " ('set', 'ai'),\n",
              " ('set', 'science'),\n",
              " ('set', 'computational'),\n",
              " ('set', 'technologies'),\n",
              " ('computational', 'science'),\n",
              " ('computational', 'set'),\n",
              " ('computational', 'technologies'),\n",
              " ('computational', 'inspired'),\n",
              " ('technologies', 'set'),\n",
              " ('technologies', 'computational'),\n",
              " ('technologies', 'inspired'),\n",
              " ('technologies', 'typically'),\n",
              " ('inspired', 'computational'),\n",
              " ('inspired', 'technologies'),\n",
              " ('inspired', 'typically'),\n",
              " ('inspired', 'operate'),\n",
              " ('typically', 'technologies'),\n",
              " ('typically', 'inspired'),\n",
              " ('typically', 'operate'),\n",
              " ('typically', 'quite'),\n",
              " ('operate', 'inspired'),\n",
              " ('operate', 'typically'),\n",
              " ('operate', 'quite'),\n",
              " ('operate', 'differently'),\n",
              " ('quite', 'typically'),\n",
              " ('quite', 'operate'),\n",
              " ('quite', 'differently'),\n",
              " ('quite', 'ways'),\n",
              " ('differently', 'operate'),\n",
              " ('differently', 'quite'),\n",
              " ('differently', 'ways'),\n",
              " ('differently', 'people'),\n",
              " ('ways', 'quite'),\n",
              " ('ways', 'differently'),\n",
              " ('ways', 'people'),\n",
              " ('ways', 'use'),\n",
              " ('people', 'differently'),\n",
              " ('people', 'ways'),\n",
              " ('people', 'use'),\n",
              " ('people', 'nervous'),\n",
              " ('use', 'ways'),\n",
              " ('use', 'people'),\n",
              " ('use', 'nervous'),\n",
              " ('use', 'systems'),\n",
              " ('nervous', 'people'),\n",
              " ('nervous', 'use'),\n",
              " ('nervous', 'systems'),\n",
              " ('nervous', 'bodies'),\n",
              " ('systems', 'use'),\n",
              " ('systems', 'nervous'),\n",
              " ('systems', 'bodies'),\n",
              " ('systems', 'sense'),\n",
              " ('bodies', 'nervous'),\n",
              " ('bodies', 'systems'),\n",
              " ('bodies', 'sense'),\n",
              " ('bodies', 'learn'),\n",
              " ('sense', 'systems'),\n",
              " ('sense', 'bodies'),\n",
              " ('sense', 'learn'),\n",
              " ('sense', 'reason'),\n",
              " ('learn', 'bodies'),\n",
              " ('learn', 'sense'),\n",
              " ('learn', 'reason'),\n",
              " ('learn', 'take'),\n",
              " ('reason', 'sense'),\n",
              " ('reason', 'learn'),\n",
              " ('reason', 'take'),\n",
              " ('reason', 'action'),\n",
              " ('take', 'learn'),\n",
              " ('take', 'reason'),\n",
              " ('take', 'action'),\n",
              " ('take', ''),\n",
              " ('action', 'reason'),\n",
              " ('action', 'take'),\n",
              " ('action', ''),\n",
              " ('', 'take'),\n",
              " ('', 'action'),\n",
              " ('rate', 'progress'),\n",
              " ('rate', 'ai'),\n",
              " ('progress', 'rate'),\n",
              " ('progress', 'ai'),\n",
              " ('progress', 'patchy'),\n",
              " ('ai', 'rate'),\n",
              " ('ai', 'progress'),\n",
              " ('ai', 'patchy'),\n",
              " ('ai', 'unpredictable'),\n",
              " ('patchy', 'progress'),\n",
              " ('patchy', 'ai'),\n",
              " ('patchy', 'unpredictable'),\n",
              " ('patchy', 'significant'),\n",
              " ('unpredictable', 'ai'),\n",
              " ('unpredictable', 'patchy'),\n",
              " ('unpredictable', 'significant'),\n",
              " ('unpredictable', 'advances'),\n",
              " ('significant', 'patchy'),\n",
              " ('significant', 'unpredictable'),\n",
              " ('significant', 'advances'),\n",
              " ('significant', 'since'),\n",
              " ('advances', 'unpredictable'),\n",
              " ('advances', 'significant'),\n",
              " ('advances', 'since'),\n",
              " ('advances', 'field'),\n",
              " ('since', 'significant'),\n",
              " ('since', 'advances'),\n",
              " ('since', 'field'),\n",
              " ('since', 'inception'),\n",
              " ('field', 'advances'),\n",
              " ('field', 'since'),\n",
              " ('field', 'inception'),\n",
              " ('field', 'sixty'),\n",
              " ('inception', 'since'),\n",
              " ('inception', 'field'),\n",
              " ('inception', 'sixty'),\n",
              " ('inception', 'years'),\n",
              " ('sixty', 'field'),\n",
              " ('sixty', 'inception'),\n",
              " ('sixty', 'years'),\n",
              " ('sixty', 'ago'),\n",
              " ('years', 'inception'),\n",
              " ('years', 'sixty'),\n",
              " ('years', 'ago'),\n",
              " ('years', ''),\n",
              " ('ago', 'sixty'),\n",
              " ('ago', 'years'),\n",
              " ('ago', ''),\n",
              " ('', 'years'),\n",
              " ('', 'ago'),\n",
              " ('mostly', 'academic'),\n",
              " ('mostly', 'area'),\n",
              " ('academic', 'mostly'),\n",
              " ('academic', 'area'),\n",
              " ('academic', 'study'),\n",
              " ('area', 'mostly'),\n",
              " ('area', 'academic'),\n",
              " ('area', 'study'),\n",
              " ('area', 'twenty'),\n",
              " ('study', 'academic'),\n",
              " ('study', 'area'),\n",
              " ('study', 'twenty'),\n",
              " ('study', 'first'),\n",
              " ('twenty', 'area'),\n",
              " ('twenty', 'study'),\n",
              " ('twenty', 'first'),\n",
              " ('twenty', 'century'),\n",
              " ('first', 'study'),\n",
              " ('first', 'twenty'),\n",
              " ('first', 'century'),\n",
              " ('first', 'ai'),\n",
              " ('century', 'twenty'),\n",
              " ('century', 'first'),\n",
              " ('century', 'ai'),\n",
              " ('century', 'enables'),\n",
              " ('ai', 'first'),\n",
              " ('ai', 'century'),\n",
              " ('ai', 'enables'),\n",
              " ('ai', 'constellation'),\n",
              " ('enables', 'century'),\n",
              " ('enables', 'ai'),\n",
              " ('enables', 'constellation'),\n",
              " ('enables', 'mainstream'),\n",
              " ('constellation', 'ai'),\n",
              " ('constellation', 'enables'),\n",
              " ('constellation', 'mainstream'),\n",
              " ('constellation', 'technologies'),\n",
              " ('mainstream', 'enables'),\n",
              " ('mainstream', 'constellation'),\n",
              " ('mainstream', 'technologies'),\n",
              " ('mainstream', 'substantial'),\n",
              " ('technologies', 'constellation'),\n",
              " ('technologies', 'mainstream'),\n",
              " ('technologies', 'substantial'),\n",
              " ('technologies', 'impact'),\n",
              " ('substantial', 'mainstream'),\n",
              " ('substantial', 'technologies'),\n",
              " ('substantial', 'impact'),\n",
              " ('substantial', 'everyday'),\n",
              " ('impact', 'technologies'),\n",
              " ('impact', 'substantial'),\n",
              " ('impact', 'everyday'),\n",
              " ('impact', 'lives'),\n",
              " ('everyday', 'substantial'),\n",
              " ('everyday', 'impact'),\n",
              " ('everyday', 'lives'),\n",
              " ('everyday', ''),\n",
              " ('lives', 'impact'),\n",
              " ('lives', 'everyday'),\n",
              " ('lives', ''),\n",
              " ('', 'everyday'),\n",
              " ('', 'lives'),\n",
              " ('computer', 'vision'),\n",
              " ('computer', 'ai'),\n",
              " ('vision', 'computer'),\n",
              " ('vision', 'ai'),\n",
              " ('vision', 'planning'),\n",
              " ('ai', 'computer'),\n",
              " ('ai', 'vision'),\n",
              " ('ai', 'planning'),\n",
              " ('ai', 'example'),\n",
              " ('planning', 'vision'),\n",
              " ('planning', 'ai'),\n",
              " ('planning', 'example'),\n",
              " ('planning', 'drive'),\n",
              " ('example', 'ai'),\n",
              " ('example', 'planning'),\n",
              " ('example', 'drive'),\n",
              " ('example', 'video'),\n",
              " ('drive', 'planning'),\n",
              " ('drive', 'example'),\n",
              " ('drive', 'video'),\n",
              " ('drive', 'games'),\n",
              " ('video', 'example'),\n",
              " ('video', 'drive'),\n",
              " ('video', 'games'),\n",
              " ('video', 'bigger'),\n",
              " ('games', 'drive'),\n",
              " ('games', 'video'),\n",
              " ('games', 'bigger'),\n",
              " ('games', 'entertainment'),\n",
              " ('bigger', 'video'),\n",
              " ('bigger', 'games'),\n",
              " ('bigger', 'entertainment'),\n",
              " ('bigger', 'industry'),\n",
              " ('entertainment', 'games'),\n",
              " ('entertainment', 'bigger'),\n",
              " ('entertainment', 'industry'),\n",
              " ('entertainment', 'hollywood'),\n",
              " ('industry', 'bigger'),\n",
              " ('industry', 'entertainment'),\n",
              " ('industry', 'hollywood'),\n",
              " ('industry', ''),\n",
              " ('hollywood', 'entertainment'),\n",
              " ('hollywood', 'industry'),\n",
              " ('hollywood', ''),\n",
              " ('', 'industry'),\n",
              " ('', 'hollywood'),\n",
              " ('deep', 'learning'),\n",
              " ('deep', 'form'),\n",
              " ('learning', 'deep'),\n",
              " ('learning', 'form'),\n",
              " ('learning', 'machine'),\n",
              " ('form', 'deep'),\n",
              " ('form', 'learning'),\n",
              " ('form', 'machine'),\n",
              " ('form', 'learning'),\n",
              " ('machine', 'learning'),\n",
              " ('machine', 'form'),\n",
              " ('machine', 'learning'),\n",
              " ('machine', 'based'),\n",
              " ('learning', 'form'),\n",
              " ('learning', 'machine'),\n",
              " ('learning', 'based'),\n",
              " ('learning', 'layered'),\n",
              " ('based', 'machine'),\n",
              " ('based', 'learning'),\n",
              " ('based', 'layered'),\n",
              " ('based', 'representations'),\n",
              " ('layered', 'learning'),\n",
              " ('layered', 'based'),\n",
              " ('layered', 'representations'),\n",
              " ('layered', 'variables'),\n",
              " ('representations', 'based'),\n",
              " ('representations', 'layered'),\n",
              " ('representations', 'variables'),\n",
              " ('representations', 'referred'),\n",
              " ('variables', 'layered'),\n",
              " ('variables', 'representations'),\n",
              " ('variables', 'referred'),\n",
              " ('variables', 'neural'),\n",
              " ('referred', 'representations'),\n",
              " ('referred', 'variables'),\n",
              " ('referred', 'neural'),\n",
              " ('referred', 'networks'),\n",
              " ('neural', 'variables'),\n",
              " ('neural', 'referred'),\n",
              " ('neural', 'networks'),\n",
              " ('neural', 'made'),\n",
              " ('networks', 'referred'),\n",
              " ('networks', 'neural'),\n",
              " ('networks', 'made'),\n",
              " ('networks', 'speech'),\n",
              " ('made', 'neural'),\n",
              " ('made', 'networks'),\n",
              " ('made', 'speech'),\n",
              " ('made', 'understanding'),\n",
              " ('speech', 'networks'),\n",
              " ('speech', 'made'),\n",
              " ('speech', 'understanding'),\n",
              " ('speech', 'practical'),\n",
              " ('understanding', 'made'),\n",
              " ('understanding', 'speech'),\n",
              " ('understanding', 'practical'),\n",
              " ('understanding', 'phones'),\n",
              " ('practical', 'speech'),\n",
              " ('practical', 'understanding'),\n",
              " ('practical', 'phones'),\n",
              " ('practical', 'kitchens'),\n",
              " ('phones', 'understanding'),\n",
              " ('phones', 'practical'),\n",
              " ('phones', 'kitchens'),\n",
              " ('phones', 'algorithms'),\n",
              " ('kitchens', 'practical'),\n",
              " ('kitchens', 'phones'),\n",
              " ('kitchens', 'algorithms'),\n",
              " ('kitchens', 'applied'),\n",
              " ('algorithms', 'phones'),\n",
              " ('algorithms', 'kitchens'),\n",
              " ('algorithms', 'applied'),\n",
              " ('algorithms', 'widely'),\n",
              " ('applied', 'kitchens'),\n",
              " ('applied', 'algorithms'),\n",
              " ('applied', 'widely'),\n",
              " ('applied', 'array'),\n",
              " ('widely', 'algorithms'),\n",
              " ('widely', 'applied'),\n",
              " ('widely', 'array'),\n",
              " ('widely', 'applications'),\n",
              " ('array', 'applied'),\n",
              " ('array', 'widely'),\n",
              " ('array', 'applications'),\n",
              " ('array', 'rely'),\n",
              " ('applications', 'widely'),\n",
              " ('applications', 'array'),\n",
              " ('applications', 'rely'),\n",
              " ('applications', 'pattern'),\n",
              " ('rely', 'array'),\n",
              " ('rely', 'applications'),\n",
              " ('rely', 'pattern'),\n",
              " ('rely', 'recognition'),\n",
              " ('pattern', 'applications'),\n",
              " ('pattern', 'rely'),\n",
              " ('pattern', 'recognition'),\n",
              " ('pattern', ''),\n",
              " ('recognition', 'rely'),\n",
              " ('recognition', 'pattern'),\n",
              " ('recognition', ''),\n",
              " ('', 'pattern'),\n",
              " ('', 'recognition'),\n",
              " ('natural', 'language'),\n",
              " ('natural', 'processing'),\n",
              " ('language', 'natural'),\n",
              " ('language', 'processing'),\n",
              " ('language', 'nlp'),\n",
              " ('processing', 'natural'),\n",
              " ('processing', 'language'),\n",
              " ('processing', 'nlp'),\n",
              " ('processing', 'knowledge'),\n",
              " ('nlp', 'language'),\n",
              " ('nlp', 'processing'),\n",
              " ('nlp', 'knowledge'),\n",
              " ('nlp', 'representation'),\n",
              " ('knowledge', 'processing'),\n",
              " ('knowledge', 'nlp'),\n",
              " ('knowledge', 'representation'),\n",
              " ('knowledge', 'reasoning'),\n",
              " ('representation', 'nlp'),\n",
              " ('representation', 'knowledge'),\n",
              " ('representation', 'reasoning'),\n",
              " ('representation', 'enabled'),\n",
              " ('reasoning', 'knowledge'),\n",
              " ('reasoning', 'representation'),\n",
              " ('reasoning', 'enabled'),\n",
              " ('reasoning', 'machine'),\n",
              " ('enabled', 'representation'),\n",
              " ('enabled', 'reasoning'),\n",
              " ('enabled', 'machine'),\n",
              " ('enabled', 'beat'),\n",
              " ('machine', 'reasoning'),\n",
              " ('machine', 'enabled'),\n",
              " ('machine', 'beat'),\n",
              " ('machine', 'jeopardy'),\n",
              " ('beat', 'enabled'),\n",
              " ('beat', 'machine'),\n",
              " ('beat', 'jeopardy'),\n",
              " ('beat', 'champion'),\n",
              " ('jeopardy', 'machine'),\n",
              " ('jeopardy', 'beat'),\n",
              " ('jeopardy', 'champion'),\n",
              " ('jeopardy', 'bringing'),\n",
              " ('champion', 'beat'),\n",
              " ('champion', 'jeopardy'),\n",
              " ('champion', 'bringing'),\n",
              " ('champion', 'new'),\n",
              " ('bringing', 'jeopardy'),\n",
              " ('bringing', 'champion'),\n",
              " ('bringing', 'new'),\n",
              " ('bringing', 'power'),\n",
              " ('new', 'champion'),\n",
              " ('new', 'bringing'),\n",
              " ('new', 'power'),\n",
              " ('new', 'web'),\n",
              " ('power', 'bringing'),\n",
              " ('power', 'new'),\n",
              " ('power', 'web'),\n",
              " ('power', 'searches'),\n",
              " ('web', 'new'),\n",
              " ('web', 'power'),\n",
              " ('web', 'searches'),\n",
              " ('web', ''),\n",
              " ('searches', 'power'),\n",
              " ('searches', 'web'),\n",
              " ('searches', ''),\n",
              " ('', 'web'),\n",
              " ('', 'searches'),\n",
              " ('impressive', 'technologies'),\n",
              " ('impressive', 'highly'),\n",
              " ('technologies', 'impressive'),\n",
              " ('technologies', 'highly'),\n",
              " ('technologies', 'tailored'),\n",
              " ('highly', 'impressive'),\n",
              " ('highly', 'technologies'),\n",
              " ('highly', 'tailored'),\n",
              " ('highly', 'particular'),\n",
              " ('tailored', 'technologies'),\n",
              " ('tailored', 'highly'),\n",
              " ('tailored', 'particular'),\n",
              " ('tailored', 'tasks'),\n",
              " ('particular', 'highly'),\n",
              " ('particular', 'tailored'),\n",
              " ('particular', 'tasks'),\n",
              " ('particular', ''),\n",
              " ('tasks', 'tailored'),\n",
              " ('tasks', 'particular'),\n",
              " ('tasks', ''),\n",
              " ('', 'particular'),\n",
              " ('', 'tasks'),\n",
              " ('application', 'typically'),\n",
              " ('application', 'requires'),\n",
              " ('typically', 'application'),\n",
              " ('typically', 'requires'),\n",
              " ('typically', 'years'),\n",
              " ('requires', 'application'),\n",
              " ('requires', 'typically'),\n",
              " ('requires', 'years'),\n",
              " ('requires', 'specialized'),\n",
              " ('years', 'typically'),\n",
              " ('years', 'requires'),\n",
              " ('years', 'specialized'),\n",
              " ('years', 'research'),\n",
              " ('specialized', 'requires'),\n",
              " ('specialized', 'years'),\n",
              " ('specialized', 'research'),\n",
              " ('specialized', 'careful'),\n",
              " ('research', 'years'),\n",
              " ('research', 'specialized'),\n",
              " ('research', 'careful'),\n",
              " ('research', 'unique'),\n",
              " ('careful', 'specialized'),\n",
              " ('careful', 'research'),\n",
              " ('careful', 'unique'),\n",
              " ('careful', 'construction'),\n",
              " ('unique', 'research'),\n",
              " ('unique', 'careful'),\n",
              " ('unique', 'construction'),\n",
              " ('unique', ''),\n",
              " ('construction', 'careful'),\n",
              " ('construction', 'unique'),\n",
              " ('construction', ''),\n",
              " ('', 'unique'),\n",
              " ('', 'construction'),\n",
              " ('similarly', 'targeted'),\n",
              " ('similarly', 'applications'),\n",
              " ('targeted', 'similarly'),\n",
              " ('targeted', 'applications'),\n",
              " ('targeted', 'substantial'),\n",
              " ('applications', 'similarly'),\n",
              " ('applications', 'targeted'),\n",
              " ('applications', 'substantial'),\n",
              " ('applications', 'increases'),\n",
              " ('substantial', 'targeted'),\n",
              " ('substantial', 'applications'),\n",
              " ('substantial', 'increases'),\n",
              " ('substantial', 'future'),\n",
              " ('increases', 'applications'),\n",
              " ('increases', 'substantial'),\n",
              " ('increases', 'future'),\n",
              " ('increases', 'uses'),\n",
              " ('future', 'substantial'),\n",
              " ('future', 'increases'),\n",
              " ('future', 'uses'),\n",
              " ('future', 'ai'),\n",
              " ('uses', 'increases'),\n",
              " ('uses', 'future'),\n",
              " ('uses', 'ai'),\n",
              " ('uses', 'technologies'),\n",
              " ('ai', 'future'),\n",
              " ('ai', 'uses'),\n",
              " ('ai', 'technologies'),\n",
              " ('ai', 'including'),\n",
              " ('technologies', 'uses'),\n",
              " ('technologies', 'ai'),\n",
              " ('technologies', 'including'),\n",
              " ('technologies', 'self'),\n",
              " ('including', 'ai'),\n",
              " ('including', 'technologies'),\n",
              " ('including', 'self'),\n",
              " ('including', 'driving'),\n",
              " ('self', 'technologies'),\n",
              " ('self', 'including'),\n",
              " ('self', 'driving'),\n",
              " ('self', 'cars'),\n",
              " ('driving', 'including'),\n",
              " ('driving', 'self'),\n",
              " ('driving', 'cars'),\n",
              " ('driving', 'healthcare'),\n",
              " ('cars', 'self'),\n",
              " ('cars', 'driving'),\n",
              " ('cars', 'healthcare'),\n",
              " ('cars', 'diagnostics'),\n",
              " ('healthcare', 'driving'),\n",
              " ('healthcare', 'cars'),\n",
              " ('healthcare', 'diagnostics'),\n",
              " ('healthcare', 'targeted'),\n",
              " ('diagnostics', 'cars'),\n",
              " ('diagnostics', 'healthcare'),\n",
              " ('diagnostics', 'targeted'),\n",
              " ('diagnostics', 'treatments'),\n",
              " ('targeted', 'healthcare'),\n",
              " ('targeted', 'diagnostics'),\n",
              " ('targeted', 'treatments'),\n",
              " ('targeted', 'physical'),\n",
              " ('treatments', 'diagnostics'),\n",
              " ('treatments', 'targeted'),\n",
              " ('treatments', 'physical'),\n",
              " ('treatments', 'assistance'),\n",
              " ('physical', 'targeted'),\n",
              " ('physical', 'treatments'),\n",
              " ('physical', 'assistance'),\n",
              " ('physical', 'elder'),\n",
              " ('assistance', 'treatments'),\n",
              " ('assistance', 'physical'),\n",
              " ('assistance', 'elder'),\n",
              " ('assistance', 'care'),\n",
              " ('elder', 'physical'),\n",
              " ('elder', 'assistance'),\n",
              " ('elder', 'care'),\n",
              " ('elder', 'expected'),\n",
              " ('care', 'assistance'),\n",
              " ('care', 'elder'),\n",
              " ('care', 'expected'),\n",
              " ('care', ''),\n",
              " ('expected', 'elder'),\n",
              " ('expected', 'care'),\n",
              " ('expected', ''),\n",
              " ('', 'care'),\n",
              " ('', 'expected'),\n",
              " ('ai', 'robotics'),\n",
              " ('ai', 'also'),\n",
              " ('robotics', 'ai'),\n",
              " ('robotics', 'also'),\n",
              " ('robotics', 'applied'),\n",
              " ('also', 'ai'),\n",
              " ('also', 'robotics'),\n",
              " ('also', 'applied'),\n",
              " ('also', 'across'),\n",
              " ('applied', 'robotics'),\n",
              " ('applied', 'also'),\n",
              " ('applied', 'across'),\n",
              " ('applied', 'globe'),\n",
              " ('across', 'also'),\n",
              " ('across', 'applied'),\n",
              " ('across', 'globe'),\n",
              " ('across', 'industries'),\n",
              " ('globe', 'applied'),\n",
              " ('globe', 'across'),\n",
              " ('globe', 'industries'),\n",
              " ('globe', 'struggling'),\n",
              " ('industries', 'across'),\n",
              " ('industries', 'globe'),\n",
              " ('industries', 'struggling'),\n",
              " ('industries', 'attract'),\n",
              " ('struggling', 'globe'),\n",
              " ('struggling', 'industries'),\n",
              " ('struggling', 'attract'),\n",
              " ('struggling', 'younger'),\n",
              " ('attract', 'industries'),\n",
              " ('attract', 'struggling'),\n",
              " ('attract', 'younger'),\n",
              " ('attract', 'workers'),\n",
              " ('younger', 'struggling'),\n",
              " ('younger', 'attract'),\n",
              " ('younger', 'workers'),\n",
              " ('younger', 'agriculture'),\n",
              " ('workers', 'attract'),\n",
              " ('workers', 'younger'),\n",
              " ('workers', 'agriculture'),\n",
              " ('workers', 'food'),\n",
              " ('agriculture', 'younger'),\n",
              " ('agriculture', 'workers'),\n",
              " ('agriculture', 'food'),\n",
              " ('agriculture', 'processing'),\n",
              " ('food', 'workers'),\n",
              " ('food', 'agriculture'),\n",
              " ('food', 'processing'),\n",
              " ('food', 'fulfillment'),\n",
              " ('processing', 'agriculture'),\n",
              " ('processing', 'food'),\n",
              " ('processing', 'fulfillment'),\n",
              " ('processing', 'centers'),\n",
              " ('fulfillment', 'food'),\n",
              " ('fulfillment', 'processing'),\n",
              " ('fulfillment', 'centers'),\n",
              " ('fulfillment', 'factories'),\n",
              " ('centers', 'processing'),\n",
              " ('centers', 'fulfillment'),\n",
              " ('centers', 'factories'),\n",
              " ('centers', ''),\n",
              " ('factories', 'fulfillment'),\n",
              " ('factories', 'centers'),\n",
              " ('factories', ''),\n",
              " ('', 'centers'),\n",
              " ('', 'factories'),\n",
              " ('facilitate', 'delivery'),\n",
              " ('facilitate', 'online'),\n",
              " ('delivery', 'facilitate'),\n",
              " ('delivery', 'online'),\n",
              " ('delivery', 'purchases'),\n",
              " ('online', 'facilitate'),\n",
              " ('online', 'delivery'),\n",
              " ('online', 'purchases'),\n",
              " ('online', 'flying'),\n",
              " ('purchases', 'delivery'),\n",
              " ('purchases', 'online'),\n",
              " ('purchases', 'flying'),\n",
              " ('purchases', 'drones'),\n",
              " ('flying', 'online'),\n",
              " ('flying', 'purchases'),\n",
              " ('flying', 'drones'),\n",
              " ('flying', 'self'),\n",
              " ('drones', 'purchases'),\n",
              " ('drones', 'flying'),\n",
              " ('drones', 'self'),\n",
              " ('drones', 'driving'),\n",
              " ('self', 'flying'),\n",
              " ('self', 'drones'),\n",
              " ('self', 'driving'),\n",
              " ('self', 'trucks'),\n",
              " ('driving', 'drones'),\n",
              " ('driving', 'self'),\n",
              " ('driving', 'trucks'),\n",
              " ('driving', 'robots'),\n",
              " ('trucks', 'self'),\n",
              " ('trucks', 'driving'),\n",
              " ('trucks', 'robots'),\n",
              " ('trucks', 'get'),\n",
              " ('robots', 'driving'),\n",
              " ('robots', 'trucks'),\n",
              " ('robots', 'get'),\n",
              " ('robots', 'stairs'),\n",
              " ('get', 'trucks'),\n",
              " ('get', 'robots'),\n",
              " ('get', 'stairs'),\n",
              " ('get', 'front'),\n",
              " ('stairs', 'robots'),\n",
              " ('stairs', 'get'),\n",
              " ('stairs', 'front'),\n",
              " ('stairs', 'door'),\n",
              " ('front', 'get'),\n",
              " ('front', 'stairs'),\n",
              " ('front', 'door'),\n",
              " ('front', ''),\n",
              " ('door', 'stairs'),\n",
              " ('door', 'front'),\n",
              " ('door', ''),\n",
              " ('', 'front'),\n",
              " ('', 'door'),\n",
              " ('report', 'first'),\n",
              " ('report', 'series'),\n",
              " ('first', 'report'),\n",
              " ('first', 'series'),\n",
              " ('first', 'issued'),\n",
              " ('series', 'report'),\n",
              " ('series', 'first'),\n",
              " ('series', 'issued'),\n",
              " ('series', 'regular'),\n",
              " ('issued', 'first'),\n",
              " ('issued', 'series'),\n",
              " ('issued', 'regular'),\n",
              " ('issued', 'intervals'),\n",
              " ('regular', 'series'),\n",
              " ('regular', 'issued'),\n",
              " ('regular', 'intervals'),\n",
              " ('regular', 'part'),\n",
              " ('intervals', 'issued'),\n",
              " ('intervals', 'regular'),\n",
              " ('intervals', 'part'),\n",
              " ('intervals', 'one'),\n",
              " ('part', 'regular'),\n",
              " ('part', 'intervals'),\n",
              " ('part', 'one'),\n",
              " ('part', 'hundred'),\n",
              " ('one', 'intervals'),\n",
              " ('one', 'part'),\n",
              " ('one', 'hundred'),\n",
              " ('one', 'year'),\n",
              " ('hundred', 'part'),\n",
              " ('hundred', 'one'),\n",
              " ('hundred', 'year'),\n",
              " ('hundred', 'study'),\n",
              " ('year', 'one'),\n",
              " ('year', 'hundred'),\n",
              " ('year', 'study'),\n",
              " ('year', 'artificial'),\n",
              " ('study', 'hundred'),\n",
              " ('study', 'year'),\n",
              " ('study', 'artificial'),\n",
              " ('study', 'intelligence'),\n",
              " ('artificial', 'year'),\n",
              " ('artificial', 'study'),\n",
              " ('artificial', 'intelligence'),\n",
              " ('artificial', 'ai'),\n",
              " ('intelligence', 'study'),\n",
              " ('intelligence', 'artificial'),\n",
              " ('intelligence', 'ai'),\n",
              " ('intelligence', ''),\n",
              " ('ai', 'artificial'),\n",
              " ('ai', 'intelligence'),\n",
              " ('ai', ''),\n",
              " ('', 'intelligence'),\n",
              " ('', 'ai'),\n",
              " ('starting', 'charge'),\n",
              " ('starting', 'given'),\n",
              " ('charge', 'starting'),\n",
              " ('charge', 'given'),\n",
              " ('charge', 'ai'),\n",
              " ('given', 'starting'),\n",
              " ('given', 'charge'),\n",
              " ('given', 'ai'),\n",
              " ('given', 'standing'),\n",
              " ('ai', 'charge'),\n",
              " ('ai', 'given'),\n",
              " ('ai', 'standing'),\n",
              " ('ai', 'committee'),\n",
              " ('standing', 'given'),\n",
              " ('standing', 'ai'),\n",
              " ('standing', 'committee'),\n",
              " ('standing', 'consider'),\n",
              " ('committee', 'ai'),\n",
              " ('committee', 'standing'),\n",
              " ('committee', 'consider'),\n",
              " ('committee', 'likely'),\n",
              " ('consider', 'standing'),\n",
              " ('consider', 'committee'),\n",
              " ('consider', 'likely'),\n",
              " ('consider', 'influences'),\n",
              " ('likely', 'committee'),\n",
              " ('likely', 'consider'),\n",
              " ('likely', 'influences'),\n",
              " ('likely', 'ai'),\n",
              " ('influences', 'consider'),\n",
              " ('influences', 'likely'),\n",
              " ('influences', 'ai'),\n",
              " ('influences', 'typical'),\n",
              " ('ai', 'likely'),\n",
              " ('ai', 'influences'),\n",
              " ('ai', 'typical'),\n",
              " ('ai', 'north'),\n",
              " ('typical', 'influences'),\n",
              " ('typical', 'ai'),\n",
              " ('typical', 'north'),\n",
              " ('typical', 'american'),\n",
              " ('north', 'ai'),\n",
              " ('north', 'typical'),\n",
              " ('north', 'american'),\n",
              " ('north', 'city'),\n",
              " ('american', 'typical'),\n",
              " ('american', 'north'),\n",
              " ('american', 'city'),\n",
              " ('american', 'year'),\n",
              " ('city', 'north'),\n",
              " ('city', 'american'),\n",
              " ('city', 'year'),\n",
              " ('city', 'study'),\n",
              " ('year', 'american'),\n",
              " ('year', 'city'),\n",
              " ('year', 'study'),\n",
              " ('year', 'panel'),\n",
              " ('study', 'city'),\n",
              " ('study', 'year'),\n",
              " ('study', 'panel'),\n",
              " ('study', 'comprising'),\n",
              " ('panel', 'year'),\n",
              " ('panel', 'study'),\n",
              " ('panel', 'comprising'),\n",
              " ('panel', 'experts'),\n",
              " ('comprising', 'study'),\n",
              " ('comprising', 'panel'),\n",
              " ('comprising', 'experts'),\n",
              " ('comprising', 'ai'),\n",
              " ('experts', 'panel'),\n",
              " ('experts', 'comprising'),\n",
              " ('experts', 'ai'),\n",
              " ('experts', 'relevant'),\n",
              " ('ai', 'comprising'),\n",
              " ('ai', 'experts'),\n",
              " ('ai', 'relevant'),\n",
              " ('ai', 'areas'),\n",
              " ('relevant', 'experts'),\n",
              " ('relevant', 'ai'),\n",
              " ('relevant', 'areas'),\n",
              " ('relevant', 'focused'),\n",
              " ('areas', 'ai'),\n",
              " ('areas', 'relevant'),\n",
              " ('areas', 'focused'),\n",
              " ('areas', 'attention'),\n",
              " ('focused', 'relevant'),\n",
              " ('focused', 'areas'),\n",
              " ('focused', 'attention'),\n",
              " ('focused', 'eight'),\n",
              " ('attention', 'areas'),\n",
              " ('attention', 'focused'),\n",
              " ('attention', 'eight'),\n",
              " ('attention', 'domains'),\n",
              " ('eight', 'focused'),\n",
              " ('eight', 'attention'),\n",
              " ('eight', 'domains'),\n",
              " ('eight', 'considered'),\n",
              " ('domains', 'attention'),\n",
              " ('domains', 'eight'),\n",
              " ('domains', 'considered'),\n",
              " ('domains', 'salient'),\n",
              " ('considered', 'eight'),\n",
              " ('considered', 'domains'),\n",
              " ('considered', 'salient'),\n",
              " ('considered', 'transportation'),\n",
              " ('salient', 'domains'),\n",
              " ('salient', 'considered'),\n",
              " ('salient', 'transportation'),\n",
              " ('salient', 'service'),\n",
              " ('transportation', 'considered'),\n",
              " ('transportation', 'salient'),\n",
              " ('transportation', 'service'),\n",
              " ('transportation', 'robots'),\n",
              " ('service', 'salient'),\n",
              " ('service', 'transportation'),\n",
              " ('service', 'robots'),\n",
              " ('service', 'healthcare'),\n",
              " ('robots', 'transportation'),\n",
              " ('robots', 'service'),\n",
              " ('robots', 'healthcare'),\n",
              " ('robots', 'education'),\n",
              " ('healthcare', 'service'),\n",
              " ('healthcare', 'robots'),\n",
              " ('healthcare', 'education'),\n",
              " ('healthcare', 'low'),\n",
              " ('education', 'robots'),\n",
              " ('education', 'healthcare'),\n",
              " ('education', 'low'),\n",
              " ('education', 'resource'),\n",
              " ('low', 'healthcare'),\n",
              " ('low', 'education'),\n",
              " ('low', 'resource'),\n",
              " ('low', 'communities'),\n",
              " ('resource', 'education'),\n",
              " ('resource', 'low'),\n",
              " ('resource', 'communities'),\n",
              " ('resource', 'public'),\n",
              " ('communities', 'low'),\n",
              " ('communities', 'resource'),\n",
              " ('communities', 'public'),\n",
              " ('communities', 'safety'),\n",
              " ('public', 'resource'),\n",
              " ('public', 'communities'),\n",
              " ('public', 'safety'),\n",
              " ('public', 'security'),\n",
              " ('safety', 'communities'),\n",
              " ('safety', 'public'),\n",
              " ('safety', 'security'),\n",
              " ('safety', 'employment'),\n",
              " ('security', 'public'),\n",
              " ('security', 'safety'),\n",
              " ('security', 'employment'),\n",
              " ('security', 'workplace'),\n",
              " ('employment', 'safety'),\n",
              " ('employment', 'security'),\n",
              " ('employment', 'workplace'),\n",
              " ('employment', 'entertainment'),\n",
              " ('workplace', 'security'),\n",
              " ('workplace', 'employment'),\n",
              " ('workplace', 'entertainment'),\n",
              " ('workplace', ''),\n",
              " ('entertainment', 'employment'),\n",
              " ('entertainment', 'workplace'),\n",
              " ('entertainment', ''),\n",
              " ('', 'workplace'),\n",
              " ('', 'entertainment'),\n",
              " ('domains', 'report'),\n",
              " ('domains', 'reflects'),\n",
              " ('report', 'domains'),\n",
              " ('report', 'reflects'),\n",
              " ('report', 'progress'),\n",
              " ('reflects', 'domains'),\n",
              " ('reflects', 'report'),\n",
              " ('reflects', 'progress'),\n",
              " ('reflects', 'past'),\n",
              " ('progress', 'report'),\n",
              " ('progress', 'reflects'),\n",
              " ('progress', 'past'),\n",
              " ('progress', 'fifteen'),\n",
              " ('past', 'reflects'),\n",
              " ('past', 'progress'),\n",
              " ('past', 'fifteen'),\n",
              " ('past', 'years'),\n",
              " ('fifteen', 'progress'),\n",
              " ('fifteen', 'past'),\n",
              " ('fifteen', 'years'),\n",
              " ('fifteen', 'anticipates'),\n",
              " ('years', 'past'),\n",
              " ('years', 'fifteen'),\n",
              " ('years', 'anticipates'),\n",
              " ('years', 'developments'),\n",
              " ('anticipates', 'fifteen'),\n",
              " ('anticipates', 'years'),\n",
              " ('anticipates', 'developments'),\n",
              " ('anticipates', 'coming'),\n",
              " ('developments', 'years'),\n",
              " ('developments', 'anticipates'),\n",
              " ('developments', 'coming'),\n",
              " ('developments', 'fifteen'),\n",
              " ('coming', 'anticipates'),\n",
              " ('coming', 'developments'),\n",
              " ('coming', 'fifteen'),\n",
              " ('coming', 'years'),\n",
              " ('fifteen', 'developments'),\n",
              " ('fifteen', 'coming'),\n",
              " ('fifteen', 'years'),\n",
              " ('fifteen', ''),\n",
              " ('years', 'coming'),\n",
              " ('years', 'fifteen'),\n",
              " ('years', ''),\n",
              " ('', 'fifteen'),\n",
              " ('', 'years'),\n",
              " ('though', 'drawing'),\n",
              " ('though', 'common'),\n",
              " ('drawing', 'though'),\n",
              " ('drawing', 'common'),\n",
              " ('drawing', 'source'),\n",
              " ('common', 'though'),\n",
              " ('common', 'drawing'),\n",
              " ('common', 'source'),\n",
              " ('common', 'research'),\n",
              " ('source', 'drawing'),\n",
              " ('source', 'common'),\n",
              " ('source', 'research'),\n",
              " ('source', 'domain'),\n",
              " ('research', 'common'),\n",
              " ('research', 'source'),\n",
              " ('research', 'domain'),\n",
              " ('research', 'reflects'),\n",
              " ('domain', 'source'),\n",
              " ('domain', 'research'),\n",
              " ('domain', 'reflects'),\n",
              " ('domain', 'different'),\n",
              " ('reflects', 'research'),\n",
              " ('reflects', 'domain'),\n",
              " ('reflects', 'different'),\n",
              " ('reflects', 'ai'),\n",
              " ('different', 'domain'),\n",
              " ('different', 'reflects'),\n",
              " ('different', 'ai'),\n",
              " ('different', 'influences'),\n",
              " ('ai', 'reflects'),\n",
              " ('ai', 'different'),\n",
              " ('ai', 'influences'),\n",
              " ('ai', 'challenges'),\n",
              " ('influences', 'different'),\n",
              " ('influences', 'ai'),\n",
              " ('influences', 'challenges'),\n",
              " ('influences', 'difficulty'),\n",
              " ('challenges', 'ai'),\n",
              " ('challenges', 'influences'),\n",
              " ('challenges', 'difficulty'),\n",
              " ('challenges', 'creating'),\n",
              " ('difficulty', 'influences'),\n",
              " ('difficulty', 'challenges'),\n",
              " ('difficulty', 'creating'),\n",
              " ('difficulty', 'safe'),\n",
              " ('creating', 'challenges'),\n",
              " ('creating', 'difficulty'),\n",
              " ('creating', 'safe'),\n",
              " ('creating', 'reliable'),\n",
              " ('safe', 'difficulty'),\n",
              " ('safe', 'creating'),\n",
              " ('safe', 'reliable'),\n",
              " ('safe', 'hardware'),\n",
              " ('reliable', 'creating'),\n",
              " ('reliable', 'safe'),\n",
              " ('reliable', 'hardware'),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyjvzky-klnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining a method for one-hot encoding\n",
        "def to_one_hot_encoding(data_point_index):\n",
        "   \n",
        "    one_hot_encoding=np.zeros(len(unique_words))\n",
        "    one_hot_encoding[data_point_index]=1\n",
        "    return one_hot_encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu2dWIlzkubN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#storing one hot encoded values of the data generated in X_train and Y_train where the index of the 1 is the value of the word in the dictionary\n",
        "def one_hot_for_skip_gram(word2int, data):\n",
        "    samples=len(data)\n",
        "    vocab=len(word2int.keys())\n",
        "    X=[]\n",
        "    Y=[]\n",
        "    for i in range(0,samples):\n",
        "      X+=[to_one_hot_encoding(word2int[data[i][0]])]\n",
        "      Y+=[to_one_hot_encoding(word2int[data[i][1]])]\n",
        "    X=np.array(X)\n",
        "    Y=np.array(Y)\n",
        "    return X, Y\n",
        "    \n",
        "X_train,Y_train = one_hot_for_skip_gram(word2int, data)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpCGPtfk1El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing  keras and all the required components for the model \n",
        "import keras\n",
        "\n",
        "from keras.layers import Input,Dense\n",
        "from keras.models import Model, Sequential\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiDjQl6mk9bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the model as we will find the word vectors of each word from the model. We define the model as such as that the length of the word vectors is the number of neurons in the last hidden layer.\n",
        "def create_model():\n",
        "    input_layer=Input(shape=(len(unique_words),))\n",
        "    hidden_layer=Dense(11)(input_layer)\n",
        "    output_layer=Dense(len(unique_words),activation='softmax')(hidden_layer)\n",
        "    model=Model(input=[input_layer],output=[output_layer])\n",
        "    model.compile(optimizer='Adam',loss='categorical_crossentropy')\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePREGkj3lCa8",
        "colab_type": "code",
        "outputId": "d900218b-d515-4b3f-a07a-1ef8a92d52ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#creating the model and naming it as 'model'\n",
        "model=create_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 1031)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 11)                11352     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1031)              12372     \n",
            "=================================================================\n",
            "Total params: 23,724\n",
            "Trainable params: 23,724\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9Zzl5A_lHnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keeping a copy of the model\n",
        "import copy\n",
        "model_before = copy.copy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NYwVcDElPUN",
        "colab_type": "code",
        "outputId": "8d84310d-6c50-4db7-dd25-a7ad53b87d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Model fitting is creating that simplified representation in a way that can generally be used successfully given new data.\n",
        "model.fit(X_train, Y_train, epochs = 1000, batch_size = 200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8418/8418 [==============================] - 1s 98us/step - loss: 6.9311\n",
            "Epoch 2/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 6.9050\n",
            "Epoch 3/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.8545\n",
            "Epoch 4/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 6.7717\n",
            "Epoch 5/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.6650\n",
            "Epoch 6/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.5564\n",
            "Epoch 7/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.4703\n",
            "Epoch 8/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 6.4172\n",
            "Epoch 9/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.3915\n",
            "Epoch 10/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.3780\n",
            "Epoch 11/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 6.3693\n",
            "Epoch 12/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.3614\n",
            "Epoch 13/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 6.3541\n",
            "Epoch 14/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 6.3470\n",
            "Epoch 15/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.3401\n",
            "Epoch 16/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 6.3330\n",
            "Epoch 17/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 6.3258\n",
            "Epoch 18/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 6.3181\n",
            "Epoch 19/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 6.3101\n",
            "Epoch 20/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.3020\n",
            "Epoch 21/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.2935\n",
            "Epoch 22/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.2841\n",
            "Epoch 23/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.2742\n",
            "Epoch 24/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.2637\n",
            "Epoch 25/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 6.2524\n",
            "Epoch 26/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.2408\n",
            "Epoch 27/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 6.2278\n",
            "Epoch 28/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 6.2146\n",
            "Epoch 29/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.2002\n",
            "Epoch 30/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 6.1849\n",
            "Epoch 31/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 6.1686\n",
            "Epoch 32/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 6.1513\n",
            "Epoch 33/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 6.1331\n",
            "Epoch 34/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.1137\n",
            "Epoch 35/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 6.0932\n",
            "Epoch 36/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.0719\n",
            "Epoch 37/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.0491\n",
            "Epoch 38/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 6.0255\n",
            "Epoch 39/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 6.0012\n",
            "Epoch 40/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 5.9754\n",
            "Epoch 41/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 5.9489\n",
            "Epoch 42/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 5.9212\n",
            "Epoch 43/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 5.8927\n",
            "Epoch 44/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 5.8634\n",
            "Epoch 45/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 5.8334\n",
            "Epoch 46/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 5.8026\n",
            "Epoch 47/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 5.7714\n",
            "Epoch 48/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 5.7394\n",
            "Epoch 49/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 5.7074\n",
            "Epoch 50/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 5.6743\n",
            "Epoch 51/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 5.6413\n",
            "Epoch 52/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.6082\n",
            "Epoch 53/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.5746\n",
            "Epoch 54/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 5.5415\n",
            "Epoch 55/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.5083\n",
            "Epoch 56/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.4752\n",
            "Epoch 57/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.4423\n",
            "Epoch 58/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 5.4095\n",
            "Epoch 59/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 5.3772\n",
            "Epoch 60/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.3455\n",
            "Epoch 61/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 5.3140\n",
            "Epoch 62/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.2828\n",
            "Epoch 63/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 5.2520\n",
            "Epoch 64/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 5.2216\n",
            "Epoch 65/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 5.1916\n",
            "Epoch 66/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 5.1616\n",
            "Epoch 67/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 5.1325\n",
            "Epoch 68/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 5.1035\n",
            "Epoch 69/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 5.0749\n",
            "Epoch 70/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 5.0468\n",
            "Epoch 71/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 5.0193\n",
            "Epoch 72/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.9920\n",
            "Epoch 73/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 4.9651\n",
            "Epoch 74/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.9385\n",
            "Epoch 75/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.9128\n",
            "Epoch 76/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.8871\n",
            "Epoch 77/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.8621\n",
            "Epoch 78/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.8372\n",
            "Epoch 79/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.8126\n",
            "Epoch 80/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.7888\n",
            "Epoch 81/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.7652\n",
            "Epoch 82/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.7420\n",
            "Epoch 83/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.7191\n",
            "Epoch 84/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.6968\n",
            "Epoch 85/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.6748\n",
            "Epoch 86/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.6532\n",
            "Epoch 87/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.6320\n",
            "Epoch 88/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.6112\n",
            "Epoch 89/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.5905\n",
            "Epoch 90/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 4.5709\n",
            "Epoch 91/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 4.5512\n",
            "Epoch 92/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 4.5319\n",
            "Epoch 93/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 4.5129\n",
            "Epoch 94/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 4.4948\n",
            "Epoch 95/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 4.4762\n",
            "Epoch 96/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 4.4583\n",
            "Epoch 97/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.4409\n",
            "Epoch 98/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 4.4235\n",
            "Epoch 99/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 4.4065\n",
            "Epoch 100/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.3899\n",
            "Epoch 101/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 4.3734\n",
            "Epoch 102/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.3574\n",
            "Epoch 103/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.3417\n",
            "Epoch 104/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 4.3264\n",
            "Epoch 105/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.3113\n",
            "Epoch 106/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 4.2965\n",
            "Epoch 107/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.2821\n",
            "Epoch 108/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.2677\n",
            "Epoch 109/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.2536\n",
            "Epoch 110/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.2398\n",
            "Epoch 111/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.2262\n",
            "Epoch 112/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.2129\n",
            "Epoch 113/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.1999\n",
            "Epoch 114/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 4.1870\n",
            "Epoch 115/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.1743\n",
            "Epoch 116/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.1621\n",
            "Epoch 117/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 4.1499\n",
            "Epoch 118/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 4.1380\n",
            "Epoch 119/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.1261\n",
            "Epoch 120/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.1147\n",
            "Epoch 121/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.1032\n",
            "Epoch 122/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.0921\n",
            "Epoch 123/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 4.0811\n",
            "Epoch 124/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 4.0702\n",
            "Epoch 125/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.0597\n",
            "Epoch 126/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 4.0494\n",
            "Epoch 127/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.0390\n",
            "Epoch 128/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.0289\n",
            "Epoch 129/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.0189\n",
            "Epoch 130/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 4.0091\n",
            "Epoch 131/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.9996\n",
            "Epoch 132/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.9903\n",
            "Epoch 133/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.9809\n",
            "Epoch 134/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.9719\n",
            "Epoch 135/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.9629\n",
            "Epoch 136/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.9542\n",
            "Epoch 137/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.9453\n",
            "Epoch 138/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.9367\n",
            "Epoch 139/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.9283\n",
            "Epoch 140/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.9200\n",
            "Epoch 141/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.9117\n",
            "Epoch 142/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.9038\n",
            "Epoch 143/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.8958\n",
            "Epoch 144/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.8880\n",
            "Epoch 145/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.8803\n",
            "Epoch 146/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.8727\n",
            "Epoch 147/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.8653\n",
            "Epoch 148/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.8580\n",
            "Epoch 149/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.8509\n",
            "Epoch 150/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.8435\n",
            "Epoch 151/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.8367\n",
            "Epoch 152/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.8297\n",
            "Epoch 153/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.8229\n",
            "Epoch 154/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.8160\n",
            "Epoch 155/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.8093\n",
            "Epoch 156/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.8027\n",
            "Epoch 157/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.7965\n",
            "Epoch 158/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.7900\n",
            "Epoch 159/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7836\n",
            "Epoch 160/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.7775\n",
            "Epoch 161/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.7713\n",
            "Epoch 162/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.7652\n",
            "Epoch 163/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7593\n",
            "Epoch 164/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7532\n",
            "Epoch 165/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.7473\n",
            "Epoch 166/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.7421\n",
            "Epoch 167/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7360\n",
            "Epoch 168/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.7305\n",
            "Epoch 169/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7252\n",
            "Epoch 170/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7195\n",
            "Epoch 171/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7141\n",
            "Epoch 172/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.7088\n",
            "Epoch 173/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.7036\n",
            "Epoch 174/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.6981\n",
            "Epoch 175/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6932\n",
            "Epoch 176/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6879\n",
            "Epoch 177/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.6828\n",
            "Epoch 178/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.6781\n",
            "Epoch 179/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6733\n",
            "Epoch 180/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.6684\n",
            "Epoch 181/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6637\n",
            "Epoch 182/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6587\n",
            "Epoch 183/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.6540\n",
            "Epoch 184/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 3.6494\n",
            "Epoch 185/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.6449\n",
            "Epoch 186/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.6403\n",
            "Epoch 187/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6356\n",
            "Epoch 188/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.6312\n",
            "Epoch 189/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.6272\n",
            "Epoch 190/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.6227\n",
            "Epoch 191/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6181\n",
            "Epoch 192/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.6141\n",
            "Epoch 193/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6101\n",
            "Epoch 194/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.6056\n",
            "Epoch 195/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.6017\n",
            "Epoch 196/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.5975\n",
            "Epoch 197/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5933\n",
            "Epoch 198/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5896\n",
            "Epoch 199/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.5856\n",
            "Epoch 200/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.5817\n",
            "Epoch 201/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.5776\n",
            "Epoch 202/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.5740\n",
            "Epoch 203/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5702\n",
            "Epoch 204/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5666\n",
            "Epoch 205/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.5627\n",
            "Epoch 206/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.5591\n",
            "Epoch 207/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.5552\n",
            "Epoch 208/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5517\n",
            "Epoch 209/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5484\n",
            "Epoch 210/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.5447\n",
            "Epoch 211/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.5412\n",
            "Epoch 212/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.5377\n",
            "Epoch 213/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 3.5341\n",
            "Epoch 214/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.5310\n",
            "Epoch 215/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5278\n",
            "Epoch 216/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.5245\n",
            "Epoch 217/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.5212\n",
            "Epoch 218/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.5176\n",
            "Epoch 219/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.5144\n",
            "Epoch 220/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.5110\n",
            "Epoch 221/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.5078\n",
            "Epoch 222/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.5048\n",
            "Epoch 223/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.5015\n",
            "Epoch 224/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4985\n",
            "Epoch 225/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4957\n",
            "Epoch 226/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.4927\n",
            "Epoch 227/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4895\n",
            "Epoch 228/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4864\n",
            "Epoch 229/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4832\n",
            "Epoch 230/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4805\n",
            "Epoch 231/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.4774\n",
            "Epoch 232/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4742\n",
            "Epoch 233/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4717\n",
            "Epoch 234/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4687\n",
            "Epoch 235/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4661\n",
            "Epoch 236/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4630\n",
            "Epoch 237/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.4604\n",
            "Epoch 238/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.4576\n",
            "Epoch 239/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4548\n",
            "Epoch 240/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4520\n",
            "Epoch 241/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.4496\n",
            "Epoch 242/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 3.4468\n",
            "Epoch 243/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.4440\n",
            "Epoch 244/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4414\n",
            "Epoch 245/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.4387\n",
            "Epoch 246/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4362\n",
            "Epoch 247/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.4335\n",
            "Epoch 248/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4311\n",
            "Epoch 249/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.4285\n",
            "Epoch 250/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.4259\n",
            "Epoch 251/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4235\n",
            "Epoch 252/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4210\n",
            "Epoch 253/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.4184\n",
            "Epoch 254/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4160\n",
            "Epoch 255/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4138\n",
            "Epoch 256/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.4115\n",
            "Epoch 257/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4090\n",
            "Epoch 258/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4067\n",
            "Epoch 259/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.4042\n",
            "Epoch 260/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.4018\n",
            "Epoch 261/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.3995\n",
            "Epoch 262/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.3973\n",
            "Epoch 263/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3952\n",
            "Epoch 264/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3929\n",
            "Epoch 265/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3906\n",
            "Epoch 266/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.3883\n",
            "Epoch 267/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3860\n",
            "Epoch 268/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.3841\n",
            "Epoch 269/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.3817\n",
            "Epoch 270/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.3797\n",
            "Epoch 271/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.3775\n",
            "Epoch 272/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3752\n",
            "Epoch 273/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.3730\n",
            "Epoch 274/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3712\n",
            "Epoch 275/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3687\n",
            "Epoch 276/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3671\n",
            "Epoch 277/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3646\n",
            "Epoch 278/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3627\n",
            "Epoch 279/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3609\n",
            "Epoch 280/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.3589\n",
            "Epoch 281/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3569\n",
            "Epoch 282/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.3547\n",
            "Epoch 283/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3530\n",
            "Epoch 284/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.3507\n",
            "Epoch 285/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.3492\n",
            "Epoch 286/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3470\n",
            "Epoch 287/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3451\n",
            "Epoch 288/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3433\n",
            "Epoch 289/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3414\n",
            "Epoch 290/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.3393\n",
            "Epoch 291/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3374\n",
            "Epoch 292/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3360\n",
            "Epoch 293/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3337\n",
            "Epoch 294/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.3317\n",
            "Epoch 295/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3303\n",
            "Epoch 296/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3284\n",
            "Epoch 297/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.3264\n",
            "Epoch 298/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3248\n",
            "Epoch 299/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.3228\n",
            "Epoch 300/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3211\n",
            "Epoch 301/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.3197\n",
            "Epoch 302/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3177\n",
            "Epoch 303/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3160\n",
            "Epoch 304/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3142\n",
            "Epoch 305/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.3124\n",
            "Epoch 306/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.3105\n",
            "Epoch 307/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3090\n",
            "Epoch 308/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.3073\n",
            "Epoch 309/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3058\n",
            "Epoch 310/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.3038\n",
            "Epoch 311/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.3023\n",
            "Epoch 312/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.3007\n",
            "Epoch 313/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.2992\n",
            "Epoch 314/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.2976\n",
            "Epoch 315/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 3.2960\n",
            "Epoch 316/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2946\n",
            "Epoch 317/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.2929\n",
            "Epoch 318/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2910\n",
            "Epoch 319/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2897\n",
            "Epoch 320/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2883\n",
            "Epoch 321/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2867\n",
            "Epoch 322/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2849\n",
            "Epoch 323/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2833\n",
            "Epoch 324/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2817\n",
            "Epoch 325/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2804\n",
            "Epoch 326/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2788\n",
            "Epoch 327/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2771\n",
            "Epoch 328/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2758\n",
            "Epoch 329/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2744\n",
            "Epoch 330/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2727\n",
            "Epoch 331/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2711\n",
            "Epoch 332/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2699\n",
            "Epoch 333/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2684\n",
            "Epoch 334/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.2670\n",
            "Epoch 335/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2655\n",
            "Epoch 336/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2644\n",
            "Epoch 337/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2626\n",
            "Epoch 338/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2614\n",
            "Epoch 339/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2600\n",
            "Epoch 340/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2583\n",
            "Epoch 341/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.2571\n",
            "Epoch 342/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2556\n",
            "Epoch 343/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2543\n",
            "Epoch 344/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2530\n",
            "Epoch 345/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2516\n",
            "Epoch 346/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.2503\n",
            "Epoch 347/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2489\n",
            "Epoch 348/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2475\n",
            "Epoch 349/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.2463\n",
            "Epoch 350/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2450\n",
            "Epoch 351/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2436\n",
            "Epoch 352/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.2421\n",
            "Epoch 353/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2410\n",
            "Epoch 354/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2399\n",
            "Epoch 355/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2385\n",
            "Epoch 356/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2371\n",
            "Epoch 357/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2360\n",
            "Epoch 358/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2347\n",
            "Epoch 359/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2332\n",
            "Epoch 360/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2318\n",
            "Epoch 361/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2309\n",
            "Epoch 362/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.2295\n",
            "Epoch 363/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2283\n",
            "Epoch 364/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.2273\n",
            "Epoch 365/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2255\n",
            "Epoch 366/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.2244\n",
            "Epoch 367/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2233\n",
            "Epoch 368/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2221\n",
            "Epoch 369/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.2212\n",
            "Epoch 370/1000\n",
            "8418/8418 [==============================] - 1s 80us/step - loss: 3.2197\n",
            "Epoch 371/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2184\n",
            "Epoch 372/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.2176\n",
            "Epoch 373/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.2163\n",
            "Epoch 374/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.2151\n",
            "Epoch 375/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.2139\n",
            "Epoch 376/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2129\n",
            "Epoch 377/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2113\n",
            "Epoch 378/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2103\n",
            "Epoch 379/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.2093\n",
            "Epoch 380/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2083\n",
            "Epoch 381/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2071\n",
            "Epoch 382/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.2062\n",
            "Epoch 383/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2046\n",
            "Epoch 384/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2035\n",
            "Epoch 385/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.2023\n",
            "Epoch 386/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.2014\n",
            "Epoch 387/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1998\n",
            "Epoch 388/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1990\n",
            "Epoch 389/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1979\n",
            "Epoch 390/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.1967\n",
            "Epoch 391/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1961\n",
            "Epoch 392/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1946\n",
            "Epoch 393/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1937\n",
            "Epoch 394/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1925\n",
            "Epoch 395/1000\n",
            "8418/8418 [==============================] - 1s 78us/step - loss: 3.1915\n",
            "Epoch 396/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1908\n",
            "Epoch 397/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1896\n",
            "Epoch 398/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1885\n",
            "Epoch 399/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1874\n",
            "Epoch 400/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1863\n",
            "Epoch 401/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1851\n",
            "Epoch 402/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1841\n",
            "Epoch 403/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1830\n",
            "Epoch 404/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.1822\n",
            "Epoch 405/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1814\n",
            "Epoch 406/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1802\n",
            "Epoch 407/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1791\n",
            "Epoch 408/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1782\n",
            "Epoch 409/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1773\n",
            "Epoch 410/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1759\n",
            "Epoch 411/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1751\n",
            "Epoch 412/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1741\n",
            "Epoch 413/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1731\n",
            "Epoch 414/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.1723\n",
            "Epoch 415/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1712\n",
            "Epoch 416/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1703\n",
            "Epoch 417/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.1694\n",
            "Epoch 418/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1683\n",
            "Epoch 419/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1671\n",
            "Epoch 420/1000\n",
            "8418/8418 [==============================] - 1s 80us/step - loss: 3.1665\n",
            "Epoch 421/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.1654\n",
            "Epoch 422/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1647\n",
            "Epoch 423/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1634\n",
            "Epoch 424/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1627\n",
            "Epoch 425/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1616\n",
            "Epoch 426/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1608\n",
            "Epoch 427/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1596\n",
            "Epoch 428/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1588\n",
            "Epoch 429/1000\n",
            "8418/8418 [==============================] - 1s 79us/step - loss: 3.1579\n",
            "Epoch 430/1000\n",
            "8418/8418 [==============================] - 1s 79us/step - loss: 3.1568\n",
            "Epoch 431/1000\n",
            "8418/8418 [==============================] - 1s 78us/step - loss: 3.1562\n",
            "Epoch 432/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.1550\n",
            "Epoch 433/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.1545\n",
            "Epoch 434/1000\n",
            "8418/8418 [==============================] - 1s 78us/step - loss: 3.1534\n",
            "Epoch 435/1000\n",
            "8418/8418 [==============================] - 1s 78us/step - loss: 3.1525\n",
            "Epoch 436/1000\n",
            "8418/8418 [==============================] - 1s 82us/step - loss: 3.1517\n",
            "Epoch 437/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1508\n",
            "Epoch 438/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1500\n",
            "Epoch 439/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1489\n",
            "Epoch 440/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1481\n",
            "Epoch 441/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1472\n",
            "Epoch 442/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1465\n",
            "Epoch 443/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1452\n",
            "Epoch 444/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1446\n",
            "Epoch 445/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1437\n",
            "Epoch 446/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1430\n",
            "Epoch 447/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1418\n",
            "Epoch 448/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1410\n",
            "Epoch 449/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1405\n",
            "Epoch 450/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1398\n",
            "Epoch 451/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1388\n",
            "Epoch 452/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1377\n",
            "Epoch 453/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.1369\n",
            "Epoch 454/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1362\n",
            "Epoch 455/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1356\n",
            "Epoch 456/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1344\n",
            "Epoch 457/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1337\n",
            "Epoch 458/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.1328\n",
            "Epoch 459/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1319\n",
            "Epoch 460/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1311\n",
            "Epoch 461/1000\n",
            "8418/8418 [==============================] - 1s 78us/step - loss: 3.1303\n",
            "Epoch 462/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1296\n",
            "Epoch 463/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1286\n",
            "Epoch 464/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1283\n",
            "Epoch 465/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.1270\n",
            "Epoch 466/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1262\n",
            "Epoch 467/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1254\n",
            "Epoch 468/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.1248\n",
            "Epoch 469/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1238\n",
            "Epoch 470/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.1232\n",
            "Epoch 471/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1224\n",
            "Epoch 472/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1214\n",
            "Epoch 473/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.1206\n",
            "Epoch 474/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.1197\n",
            "Epoch 475/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.1192\n",
            "Epoch 476/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.1186\n",
            "Epoch 477/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.1179\n",
            "Epoch 478/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.1168\n",
            "Epoch 479/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.1163\n",
            "Epoch 480/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1152\n",
            "Epoch 481/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.1144\n",
            "Epoch 482/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1139\n",
            "Epoch 483/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1131\n",
            "Epoch 484/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1125\n",
            "Epoch 485/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1115\n",
            "Epoch 486/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1109\n",
            "Epoch 487/1000\n",
            "8418/8418 [==============================] - 1s 79us/step - loss: 3.1101\n",
            "Epoch 488/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1093\n",
            "Epoch 489/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1086\n",
            "Epoch 490/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1081\n",
            "Epoch 491/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1074\n",
            "Epoch 492/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1064\n",
            "Epoch 493/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.1059\n",
            "Epoch 494/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1051\n",
            "Epoch 495/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.1043\n",
            "Epoch 496/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.1037\n",
            "Epoch 497/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1024\n",
            "Epoch 498/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.1023\n",
            "Epoch 499/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1017\n",
            "Epoch 500/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1008\n",
            "Epoch 501/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.1002\n",
            "Epoch 502/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0994\n",
            "Epoch 503/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0987\n",
            "Epoch 504/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.0980\n",
            "Epoch 505/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0974\n",
            "Epoch 506/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0966\n",
            "Epoch 507/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0958\n",
            "Epoch 508/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0953\n",
            "Epoch 509/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0944\n",
            "Epoch 510/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0940\n",
            "Epoch 511/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0931\n",
            "Epoch 512/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0922\n",
            "Epoch 513/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0916\n",
            "Epoch 514/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0910\n",
            "Epoch 515/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0906\n",
            "Epoch 516/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0900\n",
            "Epoch 517/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0891\n",
            "Epoch 518/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0882\n",
            "Epoch 519/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0877\n",
            "Epoch 520/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0872\n",
            "Epoch 521/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0865\n",
            "Epoch 522/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0857\n",
            "Epoch 523/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0852\n",
            "Epoch 524/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0845\n",
            "Epoch 525/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0837\n",
            "Epoch 526/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0829\n",
            "Epoch 527/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0821\n",
            "Epoch 528/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.0819\n",
            "Epoch 529/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0809\n",
            "Epoch 530/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0802\n",
            "Epoch 531/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0798\n",
            "Epoch 532/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0792\n",
            "Epoch 533/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.0786\n",
            "Epoch 534/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.0782\n",
            "Epoch 535/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.0769\n",
            "Epoch 536/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0765\n",
            "Epoch 537/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0756\n",
            "Epoch 538/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0755\n",
            "Epoch 539/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0746\n",
            "Epoch 540/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0738\n",
            "Epoch 541/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0734\n",
            "Epoch 542/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0729\n",
            "Epoch 543/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0723\n",
            "Epoch 544/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0718\n",
            "Epoch 545/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0709\n",
            "Epoch 546/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0702\n",
            "Epoch 547/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0696\n",
            "Epoch 548/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0687\n",
            "Epoch 549/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0683\n",
            "Epoch 550/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0679\n",
            "Epoch 551/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0672\n",
            "Epoch 552/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0668\n",
            "Epoch 553/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0661\n",
            "Epoch 554/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0655\n",
            "Epoch 555/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0648\n",
            "Epoch 556/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0642\n",
            "Epoch 557/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0633\n",
            "Epoch 558/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0629\n",
            "Epoch 559/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0621\n",
            "Epoch 560/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0618\n",
            "Epoch 561/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.0610\n",
            "Epoch 562/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0604\n",
            "Epoch 563/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0597\n",
            "Epoch 564/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0596\n",
            "Epoch 565/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0590\n",
            "Epoch 566/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0582\n",
            "Epoch 567/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0577\n",
            "Epoch 568/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0574\n",
            "Epoch 569/1000\n",
            "8418/8418 [==============================] - 1s 78us/step - loss: 3.0569\n",
            "Epoch 570/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0561\n",
            "Epoch 571/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0554\n",
            "Epoch 572/1000\n",
            "8418/8418 [==============================] - 1s 79us/step - loss: 3.0550\n",
            "Epoch 573/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0543\n",
            "Epoch 574/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0539\n",
            "Epoch 575/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0533\n",
            "Epoch 576/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0524\n",
            "Epoch 577/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0523\n",
            "Epoch 578/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0515\n",
            "Epoch 579/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0509\n",
            "Epoch 580/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0504\n",
            "Epoch 581/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0497\n",
            "Epoch 582/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0490\n",
            "Epoch 583/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0489\n",
            "Epoch 584/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0480\n",
            "Epoch 585/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0473\n",
            "Epoch 586/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0471\n",
            "Epoch 587/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0465\n",
            "Epoch 588/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0458\n",
            "Epoch 589/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 3.0454\n",
            "Epoch 590/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0446\n",
            "Epoch 591/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0442\n",
            "Epoch 592/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0438\n",
            "Epoch 593/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0434\n",
            "Epoch 594/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0426\n",
            "Epoch 595/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0419\n",
            "Epoch 596/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0414\n",
            "Epoch 597/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0413\n",
            "Epoch 598/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0405\n",
            "Epoch 599/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0403\n",
            "Epoch 600/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0396\n",
            "Epoch 601/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0391\n",
            "Epoch 602/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0386\n",
            "Epoch 603/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0378\n",
            "Epoch 604/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0374\n",
            "Epoch 605/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0368\n",
            "Epoch 606/1000\n",
            "8418/8418 [==============================] - 1s 78us/step - loss: 3.0362\n",
            "Epoch 607/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0356\n",
            "Epoch 608/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0352\n",
            "Epoch 609/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0344\n",
            "Epoch 610/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0342\n",
            "Epoch 611/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0341\n",
            "Epoch 612/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0331\n",
            "Epoch 613/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0327\n",
            "Epoch 614/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0324\n",
            "Epoch 615/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0316\n",
            "Epoch 616/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0313\n",
            "Epoch 617/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0303\n",
            "Epoch 618/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0303\n",
            "Epoch 619/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0297\n",
            "Epoch 620/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0291\n",
            "Epoch 621/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0290\n",
            "Epoch 622/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0285\n",
            "Epoch 623/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.0278\n",
            "Epoch 624/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0277\n",
            "Epoch 625/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0269\n",
            "Epoch 626/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0265\n",
            "Epoch 627/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0260\n",
            "Epoch 628/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0253\n",
            "Epoch 629/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0249\n",
            "Epoch 630/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0241\n",
            "Epoch 631/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0238\n",
            "Epoch 632/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0235\n",
            "Epoch 633/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0229\n",
            "Epoch 634/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0225\n",
            "Epoch 635/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.0221\n",
            "Epoch 636/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.0214\n",
            "Epoch 637/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 3.0209\n",
            "Epoch 638/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0203\n",
            "Epoch 639/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0202\n",
            "Epoch 640/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0197\n",
            "Epoch 641/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0189\n",
            "Epoch 642/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0182\n",
            "Epoch 643/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0183\n",
            "Epoch 644/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.0178\n",
            "Epoch 645/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 3.0171\n",
            "Epoch 646/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 3.0168\n",
            "Epoch 647/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 3.0162\n",
            "Epoch 648/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0154\n",
            "Epoch 649/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0154\n",
            "Epoch 650/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0149\n",
            "Epoch 651/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0143\n",
            "Epoch 652/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 3.0140\n",
            "Epoch 653/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0135\n",
            "Epoch 654/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0128\n",
            "Epoch 655/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0125\n",
            "Epoch 656/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0119\n",
            "Epoch 657/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0118\n",
            "Epoch 658/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0110\n",
            "Epoch 659/1000\n",
            "8418/8418 [==============================] - 1s 79us/step - loss: 3.0110\n",
            "Epoch 660/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0104\n",
            "Epoch 661/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0098\n",
            "Epoch 662/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0094\n",
            "Epoch 663/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0089\n",
            "Epoch 664/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0084\n",
            "Epoch 665/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0079\n",
            "Epoch 666/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0074\n",
            "Epoch 667/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0069\n",
            "Epoch 668/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0065\n",
            "Epoch 669/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0061\n",
            "Epoch 670/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0055\n",
            "Epoch 671/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0051\n",
            "Epoch 672/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 3.0049\n",
            "Epoch 673/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0044\n",
            "Epoch 674/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0040\n",
            "Epoch 675/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 3.0034\n",
            "Epoch 676/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 3.0028\n",
            "Epoch 677/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0029\n",
            "Epoch 678/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0020\n",
            "Epoch 679/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 3.0018\n",
            "Epoch 680/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 3.0011\n",
            "Epoch 681/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0007\n",
            "Epoch 682/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 3.0005\n",
            "Epoch 683/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9997\n",
            "Epoch 684/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9995\n",
            "Epoch 685/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9987\n",
            "Epoch 686/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9987\n",
            "Epoch 687/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9980\n",
            "Epoch 688/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9980\n",
            "Epoch 689/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9971\n",
            "Epoch 690/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9969\n",
            "Epoch 691/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9964\n",
            "Epoch 692/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9959\n",
            "Epoch 693/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9956\n",
            "Epoch 694/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9953\n",
            "Epoch 695/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9950\n",
            "Epoch 696/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9946\n",
            "Epoch 697/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9943\n",
            "Epoch 698/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9934\n",
            "Epoch 699/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9931\n",
            "Epoch 700/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9927\n",
            "Epoch 701/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9923\n",
            "Epoch 702/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9918\n",
            "Epoch 703/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9916\n",
            "Epoch 704/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9911\n",
            "Epoch 705/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9903\n",
            "Epoch 706/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9902\n",
            "Epoch 707/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9900\n",
            "Epoch 708/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9893\n",
            "Epoch 709/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9891\n",
            "Epoch 710/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9886\n",
            "Epoch 711/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9880\n",
            "Epoch 712/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9878\n",
            "Epoch 713/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9868\n",
            "Epoch 714/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9868\n",
            "Epoch 715/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9868\n",
            "Epoch 716/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9863\n",
            "Epoch 717/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9859\n",
            "Epoch 718/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9857\n",
            "Epoch 719/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9849\n",
            "Epoch 720/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9849\n",
            "Epoch 721/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9842\n",
            "Epoch 722/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9839\n",
            "Epoch 723/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9832\n",
            "Epoch 724/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9828\n",
            "Epoch 725/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9825\n",
            "Epoch 726/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9821\n",
            "Epoch 727/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9818\n",
            "Epoch 728/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9814\n",
            "Epoch 729/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9811\n",
            "Epoch 730/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9807\n",
            "Epoch 731/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9803\n",
            "Epoch 732/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9802\n",
            "Epoch 733/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9794\n",
            "Epoch 734/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9789\n",
            "Epoch 735/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9787\n",
            "Epoch 736/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9780\n",
            "Epoch 737/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9778\n",
            "Epoch 738/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9776\n",
            "Epoch 739/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9769\n",
            "Epoch 740/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9767\n",
            "Epoch 741/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9763\n",
            "Epoch 742/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9758\n",
            "Epoch 743/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9757\n",
            "Epoch 744/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9752\n",
            "Epoch 745/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9751\n",
            "Epoch 746/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9742\n",
            "Epoch 747/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9738\n",
            "Epoch 748/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9735\n",
            "Epoch 749/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9733\n",
            "Epoch 750/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9736\n",
            "Epoch 751/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9724\n",
            "Epoch 752/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9723\n",
            "Epoch 753/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9716\n",
            "Epoch 754/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9712\n",
            "Epoch 755/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9711\n",
            "Epoch 756/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9707\n",
            "Epoch 757/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9704\n",
            "Epoch 758/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9698\n",
            "Epoch 759/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9692\n",
            "Epoch 760/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9693\n",
            "Epoch 761/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9689\n",
            "Epoch 762/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9681\n",
            "Epoch 763/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 2.9682\n",
            "Epoch 764/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9674\n",
            "Epoch 765/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9671\n",
            "Epoch 766/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9670\n",
            "Epoch 767/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9667\n",
            "Epoch 768/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9662\n",
            "Epoch 769/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9657\n",
            "Epoch 770/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9656\n",
            "Epoch 771/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9651\n",
            "Epoch 772/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9650\n",
            "Epoch 773/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9642\n",
            "Epoch 774/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9642\n",
            "Epoch 775/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9638\n",
            "Epoch 776/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 2.9632\n",
            "Epoch 777/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9632\n",
            "Epoch 778/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9628\n",
            "Epoch 779/1000\n",
            "8418/8418 [==============================] - 1s 65us/step - loss: 2.9622\n",
            "Epoch 780/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9617\n",
            "Epoch 781/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9616\n",
            "Epoch 782/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9612\n",
            "Epoch 783/1000\n",
            "8418/8418 [==============================] - 1s 65us/step - loss: 2.9610\n",
            "Epoch 784/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 2.9607\n",
            "Epoch 785/1000\n",
            "8418/8418 [==============================] - 1s 65us/step - loss: 2.9602\n",
            "Epoch 786/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9603\n",
            "Epoch 787/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 2.9592\n",
            "Epoch 788/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9589\n",
            "Epoch 789/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9586\n",
            "Epoch 790/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9587\n",
            "Epoch 791/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9582\n",
            "Epoch 792/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9576\n",
            "Epoch 793/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9578\n",
            "Epoch 794/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9572\n",
            "Epoch 795/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9568\n",
            "Epoch 796/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9565\n",
            "Epoch 797/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9559\n",
            "Epoch 798/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9556\n",
            "Epoch 799/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9551\n",
            "Epoch 800/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9549\n",
            "Epoch 801/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9550\n",
            "Epoch 802/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9542\n",
            "Epoch 803/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9537\n",
            "Epoch 804/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9535\n",
            "Epoch 805/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9535\n",
            "Epoch 806/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9529\n",
            "Epoch 807/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9524\n",
            "Epoch 808/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9525\n",
            "Epoch 809/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9520\n",
            "Epoch 810/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9518\n",
            "Epoch 811/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9512\n",
            "Epoch 812/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9511\n",
            "Epoch 813/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9508\n",
            "Epoch 814/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9500\n",
            "Epoch 815/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9500\n",
            "Epoch 816/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9496\n",
            "Epoch 817/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9498\n",
            "Epoch 818/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9489\n",
            "Epoch 819/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9489\n",
            "Epoch 820/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9483\n",
            "Epoch 821/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9478\n",
            "Epoch 822/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9477\n",
            "Epoch 823/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9473\n",
            "Epoch 824/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9470\n",
            "Epoch 825/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9468\n",
            "Epoch 826/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9464\n",
            "Epoch 827/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9459\n",
            "Epoch 828/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9457\n",
            "Epoch 829/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9457\n",
            "Epoch 830/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9450\n",
            "Epoch 831/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9445\n",
            "Epoch 832/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9441\n",
            "Epoch 833/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9438\n",
            "Epoch 834/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9437\n",
            "Epoch 835/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9433\n",
            "Epoch 836/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9432\n",
            "Epoch 837/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9428\n",
            "Epoch 838/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9423\n",
            "Epoch 839/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9425\n",
            "Epoch 840/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9420\n",
            "Epoch 841/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9416\n",
            "Epoch 842/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9412\n",
            "Epoch 843/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9412\n",
            "Epoch 844/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9408\n",
            "Epoch 845/1000\n",
            "8418/8418 [==============================] - 1s 66us/step - loss: 2.9403\n",
            "Epoch 846/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9402\n",
            "Epoch 847/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9399\n",
            "Epoch 848/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9393\n",
            "Epoch 849/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9391\n",
            "Epoch 850/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9386\n",
            "Epoch 851/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9386\n",
            "Epoch 852/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9381\n",
            "Epoch 853/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9376\n",
            "Epoch 854/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9373\n",
            "Epoch 855/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9370\n",
            "Epoch 856/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9370\n",
            "Epoch 857/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9369\n",
            "Epoch 858/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9363\n",
            "Epoch 859/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9361\n",
            "Epoch 860/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9355\n",
            "Epoch 861/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9351\n",
            "Epoch 862/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9351\n",
            "Epoch 863/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9345\n",
            "Epoch 864/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9344\n",
            "Epoch 865/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9342\n",
            "Epoch 866/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9335\n",
            "Epoch 867/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9336\n",
            "Epoch 868/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9328\n",
            "Epoch 869/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9329\n",
            "Epoch 870/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 2.9326\n",
            "Epoch 871/1000\n",
            "8418/8418 [==============================] - 1s 79us/step - loss: 2.9328\n",
            "Epoch 872/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9322\n",
            "Epoch 873/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9319\n",
            "Epoch 874/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9312\n",
            "Epoch 875/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9309\n",
            "Epoch 876/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9306\n",
            "Epoch 877/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9309\n",
            "Epoch 878/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9301\n",
            "Epoch 879/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9301\n",
            "Epoch 880/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9296\n",
            "Epoch 881/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9296\n",
            "Epoch 882/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9292\n",
            "Epoch 883/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9289\n",
            "Epoch 884/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9285\n",
            "Epoch 885/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9281\n",
            "Epoch 886/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9280\n",
            "Epoch 887/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9278\n",
            "Epoch 888/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 2.9274\n",
            "Epoch 889/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9272\n",
            "Epoch 890/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9263\n",
            "Epoch 891/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9266\n",
            "Epoch 892/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9260\n",
            "Epoch 893/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9259\n",
            "Epoch 894/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9256\n",
            "Epoch 895/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9249\n",
            "Epoch 896/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9245\n",
            "Epoch 897/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9245\n",
            "Epoch 898/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9244\n",
            "Epoch 899/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9237\n",
            "Epoch 900/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9241\n",
            "Epoch 901/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9234\n",
            "Epoch 902/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9232\n",
            "Epoch 903/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9231\n",
            "Epoch 904/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9228\n",
            "Epoch 905/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9221\n",
            "Epoch 906/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9223\n",
            "Epoch 907/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9221\n",
            "Epoch 908/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9217\n",
            "Epoch 909/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9214\n",
            "Epoch 910/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9209\n",
            "Epoch 911/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9207\n",
            "Epoch 912/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9208\n",
            "Epoch 913/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9203\n",
            "Epoch 914/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9196\n",
            "Epoch 915/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9198\n",
            "Epoch 916/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9194\n",
            "Epoch 917/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9192\n",
            "Epoch 918/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9191\n",
            "Epoch 919/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9179\n",
            "Epoch 920/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9184\n",
            "Epoch 921/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9178\n",
            "Epoch 922/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9176\n",
            "Epoch 923/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9173\n",
            "Epoch 924/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9172\n",
            "Epoch 925/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9166\n",
            "Epoch 926/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9170\n",
            "Epoch 927/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9163\n",
            "Epoch 928/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9159\n",
            "Epoch 929/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9158\n",
            "Epoch 930/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9157\n",
            "Epoch 931/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9155\n",
            "Epoch 932/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9149\n",
            "Epoch 933/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9150\n",
            "Epoch 934/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9144\n",
            "Epoch 935/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9140\n",
            "Epoch 936/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9138\n",
            "Epoch 937/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9134\n",
            "Epoch 938/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9131\n",
            "Epoch 939/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 2.9134\n",
            "Epoch 940/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9129\n",
            "Epoch 941/1000\n",
            "8418/8418 [==============================] - 1s 77us/step - loss: 2.9128\n",
            "Epoch 942/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 2.9120\n",
            "Epoch 943/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9120\n",
            "Epoch 944/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9118\n",
            "Epoch 945/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9115\n",
            "Epoch 946/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9111\n",
            "Epoch 947/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9110\n",
            "Epoch 948/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9110\n",
            "Epoch 949/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9106\n",
            "Epoch 950/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9102\n",
            "Epoch 951/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9100\n",
            "Epoch 952/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9096\n",
            "Epoch 953/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9096\n",
            "Epoch 954/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9088\n",
            "Epoch 955/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9088\n",
            "Epoch 956/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9085\n",
            "Epoch 957/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9085\n",
            "Epoch 958/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9078\n",
            "Epoch 959/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9076\n",
            "Epoch 960/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9075\n",
            "Epoch 961/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9073\n",
            "Epoch 962/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9070\n",
            "Epoch 963/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9067\n",
            "Epoch 964/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9067\n",
            "Epoch 965/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9064\n",
            "Epoch 966/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9057\n",
            "Epoch 967/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9054\n",
            "Epoch 968/1000\n",
            "8418/8418 [==============================] - 1s 75us/step - loss: 2.9053\n",
            "Epoch 969/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9050\n",
            "Epoch 970/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 2.9047\n",
            "Epoch 971/1000\n",
            "8418/8418 [==============================] - 1s 74us/step - loss: 2.9042\n",
            "Epoch 972/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9041\n",
            "Epoch 973/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.9042\n",
            "Epoch 974/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9039\n",
            "Epoch 975/1000\n",
            "8418/8418 [==============================] - 1s 76us/step - loss: 2.9037\n",
            "Epoch 976/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9033\n",
            "Epoch 977/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9033\n",
            "Epoch 978/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.9030\n",
            "Epoch 979/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9023\n",
            "Epoch 980/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9025\n",
            "Epoch 981/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.9024\n",
            "Epoch 982/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.9019\n",
            "Epoch 983/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9014\n",
            "Epoch 984/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9012\n",
            "Epoch 985/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9009\n",
            "Epoch 986/1000\n",
            "8418/8418 [==============================] - 1s 67us/step - loss: 2.9008\n",
            "Epoch 987/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9004\n",
            "Epoch 988/1000\n",
            "8418/8418 [==============================] - 1s 68us/step - loss: 2.9008\n",
            "Epoch 989/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9003\n",
            "Epoch 990/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.9001\n",
            "Epoch 991/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.8998\n",
            "Epoch 992/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.8995\n",
            "Epoch 993/1000\n",
            "8418/8418 [==============================] - 1s 72us/step - loss: 2.8994\n",
            "Epoch 994/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.8991\n",
            "Epoch 995/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.8987\n",
            "Epoch 996/1000\n",
            "8418/8418 [==============================] - 1s 70us/step - loss: 2.8983\n",
            "Epoch 997/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.8977\n",
            "Epoch 998/1000\n",
            "8418/8418 [==============================] - 1s 69us/step - loss: 2.8975\n",
            "Epoch 999/1000\n",
            "8418/8418 [==============================] - 1s 71us/step - loss: 2.8972\n",
            "Epoch 1000/1000\n",
            "8418/8418 [==============================] - 1s 73us/step - loss: 2.8973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f624dde3b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzFSVmGulaxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining a method to get the enbeddings which is basically the list of the weights of connections of each neuron of the word output from the last hidden layer.\n",
        "def get_embeddings(model, flag):\n",
        "    embeddings=model.layers[flag+1].get_weights()[0]\n",
        "    embeddings.reshape((len(unique_words),11))\n",
        "    return embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL3fqG1hnsax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gettig the embeddings by calling the method\n",
        "embeddingst = get_embeddings(model, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2sXTpGjnx39",
        "colab_type": "code",
        "outputId": "c415f29c-c12d-41a4-b008-1399fae8a40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#saving the word embeddings and visualising it as a table\n",
        "w2v_df = pd.DataFrame(embeddingst, columns = ['X1','X2','X3','X4','X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11'] )\n",
        "w2v_df['word'] = unique_words\n",
        "w2v_df = w2v_df[['word', 'X1', 'X2','X3','X4','X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11']]\n",
        "w2v_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>-0.030510</td>\n",
              "      <td>0.794130</td>\n",
              "      <td>-1.061649</td>\n",
              "      <td>-0.083442</td>\n",
              "      <td>-0.130550</td>\n",
              "      <td>-0.352269</td>\n",
              "      <td>0.181860</td>\n",
              "      <td>-0.089650</td>\n",
              "      <td>0.719598</td>\n",
              "      <td>0.729324</td>\n",
              "      <td>0.032105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>high</td>\n",
              "      <td>-2.015454</td>\n",
              "      <td>0.884868</td>\n",
              "      <td>4.533864</td>\n",
              "      <td>0.341083</td>\n",
              "      <td>1.308593</td>\n",
              "      <td>0.774415</td>\n",
              "      <td>0.596743</td>\n",
              "      <td>-5.877708</td>\n",
              "      <td>-0.906213</td>\n",
              "      <td>1.543818</td>\n",
              "      <td>0.609791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>protect</td>\n",
              "      <td>-0.487714</td>\n",
              "      <td>2.816028</td>\n",
              "      <td>-0.131617</td>\n",
              "      <td>-0.185775</td>\n",
              "      <td>-1.269962</td>\n",
              "      <td>0.442647</td>\n",
              "      <td>-1.234280</td>\n",
              "      <td>4.166347</td>\n",
              "      <td>1.736702</td>\n",
              "      <td>0.618867</td>\n",
              "      <td>0.986666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>systems</td>\n",
              "      <td>0.292698</td>\n",
              "      <td>0.728003</td>\n",
              "      <td>1.879227</td>\n",
              "      <td>-0.000530</td>\n",
              "      <td>0.182456</td>\n",
              "      <td>-0.554824</td>\n",
              "      <td>0.675264</td>\n",
              "      <td>-0.770940</td>\n",
              "      <td>0.881297</td>\n",
              "      <td>0.236392</td>\n",
              "      <td>0.138573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>closely</td>\n",
              "      <td>1.435934</td>\n",
              "      <td>0.594579</td>\n",
              "      <td>2.651418</td>\n",
              "      <td>-0.135553</td>\n",
              "      <td>-1.534516</td>\n",
              "      <td>0.055792</td>\n",
              "      <td>2.358037</td>\n",
              "      <td>0.954199</td>\n",
              "      <td>3.507608</td>\n",
              "      <td>0.667975</td>\n",
              "      <td>0.923649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fewer</td>\n",
              "      <td>-0.452418</td>\n",
              "      <td>1.659052</td>\n",
              "      <td>2.633829</td>\n",
              "      <td>-0.745144</td>\n",
              "      <td>3.918916</td>\n",
              "      <td>-2.328767</td>\n",
              "      <td>-1.142608</td>\n",
              "      <td>1.593076</td>\n",
              "      <td>-2.217718</td>\n",
              "      <td>0.309800</td>\n",
              "      <td>1.525806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>within</td>\n",
              "      <td>-2.960756</td>\n",
              "      <td>-4.321366</td>\n",
              "      <td>-0.751060</td>\n",
              "      <td>0.267510</td>\n",
              "      <td>0.057799</td>\n",
              "      <td>-0.745357</td>\n",
              "      <td>0.974449</td>\n",
              "      <td>-2.248575</td>\n",
              "      <td>-3.089024</td>\n",
              "      <td>-1.595938</td>\n",
              "      <td>2.551947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>collaboratively</td>\n",
              "      <td>1.194172</td>\n",
              "      <td>-0.755379</td>\n",
              "      <td>5.680677</td>\n",
              "      <td>-0.535311</td>\n",
              "      <td>-2.665900</td>\n",
              "      <td>-0.734639</td>\n",
              "      <td>1.185942</td>\n",
              "      <td>-0.941296</td>\n",
              "      <td>1.630548</td>\n",
              "      <td>2.094877</td>\n",
              "      <td>1.108514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>california</td>\n",
              "      <td>2.510731</td>\n",
              "      <td>-0.982859</td>\n",
              "      <td>0.435630</td>\n",
              "      <td>3.191416</td>\n",
              "      <td>3.641332</td>\n",
              "      <td>-0.052642</td>\n",
              "      <td>-1.321754</td>\n",
              "      <td>-0.641195</td>\n",
              "      <td>0.131931</td>\n",
              "      <td>1.613738</td>\n",
              "      <td>-3.311498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>science</td>\n",
              "      <td>-0.551139</td>\n",
              "      <td>-1.448377</td>\n",
              "      <td>-1.615890</td>\n",
              "      <td>0.856164</td>\n",
              "      <td>-1.522292</td>\n",
              "      <td>-0.753807</td>\n",
              "      <td>2.777269</td>\n",
              "      <td>0.226023</td>\n",
              "      <td>2.236964</td>\n",
              "      <td>-0.210313</td>\n",
              "      <td>-1.917423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>basic</td>\n",
              "      <td>-0.909066</td>\n",
              "      <td>-2.990848</td>\n",
              "      <td>1.317745</td>\n",
              "      <td>2.683186</td>\n",
              "      <td>0.562220</td>\n",
              "      <td>-1.092166</td>\n",
              "      <td>-3.212826</td>\n",
              "      <td>0.840820</td>\n",
              "      <td>-2.277616</td>\n",
              "      <td>0.961267</td>\n",
              "      <td>0.142223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>array</td>\n",
              "      <td>0.582021</td>\n",
              "      <td>-0.087088</td>\n",
              "      <td>2.279439</td>\n",
              "      <td>3.433734</td>\n",
              "      <td>0.428754</td>\n",
              "      <td>0.796281</td>\n",
              "      <td>-1.130210</td>\n",
              "      <td>-0.969612</td>\n",
              "      <td>-0.140981</td>\n",
              "      <td>-2.696630</td>\n",
              "      <td>1.332681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>report</td>\n",
              "      <td>-2.258520</td>\n",
              "      <td>0.012439</td>\n",
              "      <td>0.632437</td>\n",
              "      <td>0.900421</td>\n",
              "      <td>0.310458</td>\n",
              "      <td>-1.732836</td>\n",
              "      <td>-0.442726</td>\n",
              "      <td>-0.859527</td>\n",
              "      <td>-1.892546</td>\n",
              "      <td>-0.320359</td>\n",
              "      <td>-0.455522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>emphasis</td>\n",
              "      <td>2.039919</td>\n",
              "      <td>1.628837</td>\n",
              "      <td>-1.075701</td>\n",
              "      <td>3.286407</td>\n",
              "      <td>-2.728633</td>\n",
              "      <td>-0.350052</td>\n",
              "      <td>1.796655</td>\n",
              "      <td>-1.404498</td>\n",
              "      <td>0.700287</td>\n",
              "      <td>3.458518</td>\n",
              "      <td>-1.334956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>jobs</td>\n",
              "      <td>-5.421380</td>\n",
              "      <td>0.999904</td>\n",
              "      <td>-0.049857</td>\n",
              "      <td>-0.393037</td>\n",
              "      <td>-0.908295</td>\n",
              "      <td>2.045257</td>\n",
              "      <td>-1.449659</td>\n",
              "      <td>0.672499</td>\n",
              "      <td>0.555225</td>\n",
              "      <td>-0.600967</td>\n",
              "      <td>-0.664459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>dwellers</td>\n",
              "      <td>-0.590797</td>\n",
              "      <td>-0.612070</td>\n",
              "      <td>3.054773</td>\n",
              "      <td>-0.524081</td>\n",
              "      <td>1.945417</td>\n",
              "      <td>-2.918891</td>\n",
              "      <td>-3.591648</td>\n",
              "      <td>3.111043</td>\n",
              "      <td>-1.004840</td>\n",
              "      <td>0.336542</td>\n",
              "      <td>1.002935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>kinds</td>\n",
              "      <td>-0.306280</td>\n",
              "      <td>1.217430</td>\n",
              "      <td>0.140168</td>\n",
              "      <td>1.427476</td>\n",
              "      <td>-0.673760</td>\n",
              "      <td>0.266294</td>\n",
              "      <td>-2.738298</td>\n",
              "      <td>2.238429</td>\n",
              "      <td>0.947521</td>\n",
              "      <td>-2.817619</td>\n",
              "      <td>0.259863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>related</td>\n",
              "      <td>-1.263490</td>\n",
              "      <td>0.090258</td>\n",
              "      <td>0.050840</td>\n",
              "      <td>0.898262</td>\n",
              "      <td>1.053396</td>\n",
              "      <td>-0.643448</td>\n",
              "      <td>0.508116</td>\n",
              "      <td>-0.320027</td>\n",
              "      <td>0.632642</td>\n",
              "      <td>-3.355846</td>\n",
              "      <td>0.517253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>series</td>\n",
              "      <td>-5.240580</td>\n",
              "      <td>-2.059596</td>\n",
              "      <td>0.242666</td>\n",
              "      <td>0.744884</td>\n",
              "      <td>-1.102636</td>\n",
              "      <td>-1.914464</td>\n",
              "      <td>-0.051091</td>\n",
              "      <td>2.903068</td>\n",
              "      <td>-2.928806</td>\n",
              "      <td>0.989769</td>\n",
              "      <td>-2.178857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>children</td>\n",
              "      <td>0.936614</td>\n",
              "      <td>-0.406109</td>\n",
              "      <td>1.159183</td>\n",
              "      <td>-0.559885</td>\n",
              "      <td>-0.569739</td>\n",
              "      <td>1.684381</td>\n",
              "      <td>-0.135495</td>\n",
              "      <td>4.244633</td>\n",
              "      <td>-2.087314</td>\n",
              "      <td>3.371822</td>\n",
              "      <td>0.206031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>perform</td>\n",
              "      <td>-2.981269</td>\n",
              "      <td>-0.258639</td>\n",
              "      <td>-0.259092</td>\n",
              "      <td>0.046852</td>\n",
              "      <td>-0.367801</td>\n",
              "      <td>-0.963906</td>\n",
              "      <td>1.753918</td>\n",
              "      <td>1.385706</td>\n",
              "      <td>3.300816</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>-0.773896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>intent</td>\n",
              "      <td>-1.434528</td>\n",
              "      <td>-1.046121</td>\n",
              "      <td>-0.882730</td>\n",
              "      <td>1.479108</td>\n",
              "      <td>-2.655175</td>\n",
              "      <td>2.283927</td>\n",
              "      <td>-4.234534</td>\n",
              "      <td>3.046739</td>\n",
              "      <td>0.012831</td>\n",
              "      <td>1.286609</td>\n",
              "      <td>-1.638112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>particular</td>\n",
              "      <td>-4.007369</td>\n",
              "      <td>1.641919</td>\n",
              "      <td>1.370438</td>\n",
              "      <td>-1.940596</td>\n",
              "      <td>1.527619</td>\n",
              "      <td>-0.983398</td>\n",
              "      <td>0.580717</td>\n",
              "      <td>-1.234668</td>\n",
              "      <td>2.231275</td>\n",
              "      <td>-3.551228</td>\n",
              "      <td>1.591439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>inception</td>\n",
              "      <td>0.104651</td>\n",
              "      <td>-2.164328</td>\n",
              "      <td>0.082052</td>\n",
              "      <td>-1.151966</td>\n",
              "      <td>2.893062</td>\n",
              "      <td>-4.089683</td>\n",
              "      <td>0.639129</td>\n",
              "      <td>-2.442200</td>\n",
              "      <td>1.805703</td>\n",
              "      <td>-0.637064</td>\n",
              "      <td>1.393364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>surgical</td>\n",
              "      <td>0.301149</td>\n",
              "      <td>0.712686</td>\n",
              "      <td>1.796554</td>\n",
              "      <td>0.234692</td>\n",
              "      <td>0.204631</td>\n",
              "      <td>-0.480412</td>\n",
              "      <td>-5.286329</td>\n",
              "      <td>1.985793</td>\n",
              "      <td>-1.946841</td>\n",
              "      <td>3.723568</td>\n",
              "      <td>-0.444537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>interaction</td>\n",
              "      <td>0.206737</td>\n",
              "      <td>-2.824313</td>\n",
              "      <td>-1.160092</td>\n",
              "      <td>-3.654775</td>\n",
              "      <td>-3.087504</td>\n",
              "      <td>-1.458389</td>\n",
              "      <td>-1.890706</td>\n",
              "      <td>2.471283</td>\n",
              "      <td>-1.093212</td>\n",
              "      <td>1.638046</td>\n",
              "      <td>0.879077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>areas</td>\n",
              "      <td>-0.987216</td>\n",
              "      <td>-1.548787</td>\n",
              "      <td>0.907590</td>\n",
              "      <td>1.415211</td>\n",
              "      <td>-0.886186</td>\n",
              "      <td>-1.194531</td>\n",
              "      <td>1.165091</td>\n",
              "      <td>-0.516618</td>\n",
              "      <td>0.091924</td>\n",
              "      <td>-0.152280</td>\n",
              "      <td>3.195221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>markets</td>\n",
              "      <td>-0.298847</td>\n",
              "      <td>-0.741626</td>\n",
              "      <td>-2.038061</td>\n",
              "      <td>1.322611</td>\n",
              "      <td>-2.803915</td>\n",
              "      <td>0.414941</td>\n",
              "      <td>-1.651908</td>\n",
              "      <td>0.872670</td>\n",
              "      <td>-1.517872</td>\n",
              "      <td>-3.794070</td>\n",
              "      <td>0.492849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>investigates</td>\n",
              "      <td>2.374478</td>\n",
              "      <td>-1.847623</td>\n",
              "      <td>3.357887</td>\n",
              "      <td>-0.179234</td>\n",
              "      <td>-0.463340</td>\n",
              "      <td>-0.957171</td>\n",
              "      <td>1.160333</td>\n",
              "      <td>0.466338</td>\n",
              "      <td>1.512953</td>\n",
              "      <td>-1.543327</td>\n",
              "      <td>2.307041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>learning</td>\n",
              "      <td>0.584265</td>\n",
              "      <td>-0.535348</td>\n",
              "      <td>-1.192148</td>\n",
              "      <td>-0.453188</td>\n",
              "      <td>0.731243</td>\n",
              "      <td>1.098688</td>\n",
              "      <td>0.103071</td>\n",
              "      <td>0.613705</td>\n",
              "      <td>-0.842558</td>\n",
              "      <td>-0.542797</td>\n",
              "      <td>0.979189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>accustomed</td>\n",
              "      <td>-1.492105</td>\n",
              "      <td>1.734001</td>\n",
              "      <td>-1.160462</td>\n",
              "      <td>-5.401177</td>\n",
              "      <td>-4.600907</td>\n",
              "      <td>0.137100</td>\n",
              "      <td>1.290076</td>\n",
              "      <td>0.974223</td>\n",
              "      <td>-0.720087</td>\n",
              "      <td>-0.370197</td>\n",
              "      <td>-2.363230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>indian</td>\n",
              "      <td>2.522615</td>\n",
              "      <td>-0.143327</td>\n",
              "      <td>-0.395750</td>\n",
              "      <td>-0.666042</td>\n",
              "      <td>3.794597</td>\n",
              "      <td>-1.254263</td>\n",
              "      <td>-1.226389</td>\n",
              "      <td>-0.175451</td>\n",
              "      <td>-3.916353</td>\n",
              "      <td>-1.939659</td>\n",
              "      <td>-2.677902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>avoid</td>\n",
              "      <td>0.799362</td>\n",
              "      <td>1.186835</td>\n",
              "      <td>-0.026967</td>\n",
              "      <td>-0.792382</td>\n",
              "      <td>-1.017167</td>\n",
              "      <td>5.158607</td>\n",
              "      <td>1.146910</td>\n",
              "      <td>0.361582</td>\n",
              "      <td>6.195185</td>\n",
              "      <td>-0.006817</td>\n",
              "      <td>0.395418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>fantasies</td>\n",
              "      <td>-1.823676</td>\n",
              "      <td>-0.201644</td>\n",
              "      <td>-0.369052</td>\n",
              "      <td>-2.084759</td>\n",
              "      <td>-1.335514</td>\n",
              "      <td>-0.546094</td>\n",
              "      <td>1.204107</td>\n",
              "      <td>-1.307884</td>\n",
              "      <td>1.236073</td>\n",
              "      <td>-4.191468</td>\n",
              "      <td>-1.227603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>mere</td>\n",
              "      <td>0.020670</td>\n",
              "      <td>-4.314106</td>\n",
              "      <td>1.472602</td>\n",
              "      <td>-1.260163</td>\n",
              "      <td>1.858813</td>\n",
              "      <td>-1.919627</td>\n",
              "      <td>-0.802453</td>\n",
              "      <td>-1.774072</td>\n",
              "      <td>0.896891</td>\n",
              "      <td>1.209154</td>\n",
              "      <td>3.020351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>transformed</td>\n",
              "      <td>-0.758719</td>\n",
              "      <td>-4.562911</td>\n",
              "      <td>-1.045491</td>\n",
              "      <td>-1.320612</td>\n",
              "      <td>-1.445722</td>\n",
              "      <td>0.593815</td>\n",
              "      <td>-0.496694</td>\n",
              "      <td>0.248594</td>\n",
              "      <td>-1.172577</td>\n",
              "      <td>0.764768</td>\n",
              "      <td>-0.495048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>constitutes</td>\n",
              "      <td>-2.607455</td>\n",
              "      <td>1.210496</td>\n",
              "      <td>-0.034629</td>\n",
              "      <td>0.458879</td>\n",
              "      <td>-0.124961</td>\n",
              "      <td>-1.976712</td>\n",
              "      <td>2.840545</td>\n",
              "      <td>-1.502271</td>\n",
              "      <td>-2.871768</td>\n",
              "      <td>-0.119759</td>\n",
              "      <td>-3.155386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>framework</td>\n",
              "      <td>-0.540254</td>\n",
              "      <td>-2.542849</td>\n",
              "      <td>-1.557305</td>\n",
              "      <td>-1.235886</td>\n",
              "      <td>1.863991</td>\n",
              "      <td>0.860988</td>\n",
              "      <td>-0.850409</td>\n",
              "      <td>2.179594</td>\n",
              "      <td>-3.496694</td>\n",
              "      <td>-2.143968</td>\n",
              "      <td>3.714683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>currently</td>\n",
              "      <td>-0.364884</td>\n",
              "      <td>-4.202911</td>\n",
              "      <td>-1.008039</td>\n",
              "      <td>0.299645</td>\n",
              "      <td>1.608164</td>\n",
              "      <td>-0.485524</td>\n",
              "      <td>0.636712</td>\n",
              "      <td>-0.289095</td>\n",
              "      <td>-0.070719</td>\n",
              "      <td>0.001268</td>\n",
              "      <td>0.759781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>addressing</td>\n",
              "      <td>4.116459</td>\n",
              "      <td>1.621028</td>\n",
              "      <td>-3.880038</td>\n",
              "      <td>-0.428251</td>\n",
              "      <td>-0.800806</td>\n",
              "      <td>1.669281</td>\n",
              "      <td>-1.017861</td>\n",
              "      <td>1.943067</td>\n",
              "      <td>-1.018434</td>\n",
              "      <td>-1.317527</td>\n",
              "      <td>0.492480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>forms</td>\n",
              "      <td>-0.503340</td>\n",
              "      <td>-6.595904</td>\n",
              "      <td>-1.044964</td>\n",
              "      <td>0.946706</td>\n",
              "      <td>-0.127387</td>\n",
              "      <td>0.477499</td>\n",
              "      <td>0.652823</td>\n",
              "      <td>2.175205</td>\n",
              "      <td>1.912181</td>\n",
              "      <td>-0.266938</td>\n",
              "      <td>1.187348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>labeling</td>\n",
              "      <td>3.349973</td>\n",
              "      <td>-2.003524</td>\n",
              "      <td>-0.881265</td>\n",
              "      <td>1.886145</td>\n",
              "      <td>0.947203</td>\n",
              "      <td>-1.246059</td>\n",
              "      <td>1.401883</td>\n",
              "      <td>1.305416</td>\n",
              "      <td>1.906543</td>\n",
              "      <td>0.098351</td>\n",
              "      <td>3.732025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>time</td>\n",
              "      <td>-1.906205</td>\n",
              "      <td>0.364989</td>\n",
              "      <td>1.815584</td>\n",
              "      <td>0.061055</td>\n",
              "      <td>0.487777</td>\n",
              "      <td>-0.454773</td>\n",
              "      <td>1.247999</td>\n",
              "      <td>-0.194764</td>\n",
              "      <td>-1.226973</td>\n",
              "      <td>0.680141</td>\n",
              "      <td>0.070321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>teach</td>\n",
              "      <td>-5.403559</td>\n",
              "      <td>0.857080</td>\n",
              "      <td>2.295503</td>\n",
              "      <td>-1.550107</td>\n",
              "      <td>1.292950</td>\n",
              "      <td>-0.263922</td>\n",
              "      <td>-1.335896</td>\n",
              "      <td>2.114068</td>\n",
              "      <td>2.270699</td>\n",
              "      <td>0.935154</td>\n",
              "      <td>1.445499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>nervous</td>\n",
              "      <td>0.521350</td>\n",
              "      <td>1.199469</td>\n",
              "      <td>4.643741</td>\n",
              "      <td>-3.406666</td>\n",
              "      <td>0.407515</td>\n",
              "      <td>-2.886500</td>\n",
              "      <td>-2.481126</td>\n",
              "      <td>0.774942</td>\n",
              "      <td>1.454482</td>\n",
              "      <td>1.103422</td>\n",
              "      <td>-1.750612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>greg</td>\n",
              "      <td>1.160068</td>\n",
              "      <td>-1.211616</td>\n",
              "      <td>0.946144</td>\n",
              "      <td>1.773170</td>\n",
              "      <td>0.063965</td>\n",
              "      <td>-4.757325</td>\n",
              "      <td>-3.460662</td>\n",
              "      <td>-2.573623</td>\n",
              "      <td>0.049873</td>\n",
              "      <td>-2.547289</td>\n",
              "      <td>-2.007923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>recommendations</td>\n",
              "      <td>-5.778338</td>\n",
              "      <td>0.559813</td>\n",
              "      <td>1.599625</td>\n",
              "      <td>-0.544097</td>\n",
              "      <td>-0.232724</td>\n",
              "      <td>-1.422657</td>\n",
              "      <td>0.513721</td>\n",
              "      <td>-2.878134</td>\n",
              "      <td>-0.688992</td>\n",
              "      <td>-1.671984</td>\n",
              "      <td>-2.439376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1018</th>\n",
              "      <td>generality</td>\n",
              "      <td>-1.609791</td>\n",
              "      <td>-4.216568</td>\n",
              "      <td>2.364270</td>\n",
              "      <td>1.449657</td>\n",
              "      <td>0.880447</td>\n",
              "      <td>-1.024882</td>\n",
              "      <td>2.065055</td>\n",
              "      <td>2.391632</td>\n",
              "      <td>1.380363</td>\n",
              "      <td>0.207342</td>\n",
              "      <td>-0.729879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1019</th>\n",
              "      <td>j</td>\n",
              "      <td>-0.415475</td>\n",
              "      <td>2.580332</td>\n",
              "      <td>-2.811994</td>\n",
              "      <td>0.789329</td>\n",
              "      <td>-0.288739</td>\n",
              "      <td>-3.365663</td>\n",
              "      <td>0.541177</td>\n",
              "      <td>-1.526636</td>\n",
              "      <td>-0.409209</td>\n",
              "      <td>2.178269</td>\n",
              "      <td>-3.107017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>facebook</td>\n",
              "      <td>2.042774</td>\n",
              "      <td>1.544387</td>\n",
              "      <td>2.351853</td>\n",
              "      <td>2.198567</td>\n",
              "      <td>0.275521</td>\n",
              "      <td>0.552238</td>\n",
              "      <td>2.066918</td>\n",
              "      <td>-1.693731</td>\n",
              "      <td>-2.612621</td>\n",
              "      <td>-1.638212</td>\n",
              "      <td>-2.026200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>already</td>\n",
              "      <td>-1.813016</td>\n",
              "      <td>0.058271</td>\n",
              "      <td>0.173425</td>\n",
              "      <td>-0.437495</td>\n",
              "      <td>-0.773097</td>\n",
              "      <td>-0.577098</td>\n",
              "      <td>-1.071727</td>\n",
              "      <td>-0.373906</td>\n",
              "      <td>1.750095</td>\n",
              "      <td>2.148396</td>\n",
              "      <td>-2.358278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022</th>\n",
              "      <td>improve</td>\n",
              "      <td>-0.209605</td>\n",
              "      <td>-0.684662</td>\n",
              "      <td>-0.164761</td>\n",
              "      <td>0.189808</td>\n",
              "      <td>0.592968</td>\n",
              "      <td>0.333698</td>\n",
              "      <td>0.677973</td>\n",
              "      <td>0.131737</td>\n",
              "      <td>1.139203</td>\n",
              "      <td>0.693647</td>\n",
              "      <td>0.339563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>reason</td>\n",
              "      <td>3.280705</td>\n",
              "      <td>2.438143</td>\n",
              "      <td>0.306607</td>\n",
              "      <td>-3.869768</td>\n",
              "      <td>1.105916</td>\n",
              "      <td>-0.451461</td>\n",
              "      <td>-2.695379</td>\n",
              "      <td>-0.179215</td>\n",
              "      <td>0.691698</td>\n",
              "      <td>2.612891</td>\n",
              "      <td>-0.737790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>constraints</td>\n",
              "      <td>-1.685513</td>\n",
              "      <td>1.430068</td>\n",
              "      <td>4.266109</td>\n",
              "      <td>-0.032281</td>\n",
              "      <td>0.429928</td>\n",
              "      <td>1.482554</td>\n",
              "      <td>0.675563</td>\n",
              "      <td>-2.913542</td>\n",
              "      <td>-3.453462</td>\n",
              "      <td>0.536071</td>\n",
              "      <td>1.284666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>prominent</td>\n",
              "      <td>-2.247478</td>\n",
              "      <td>-6.255657</td>\n",
              "      <td>-1.936173</td>\n",
              "      <td>-0.110402</td>\n",
              "      <td>1.497671</td>\n",
              "      <td>-0.438810</td>\n",
              "      <td>-0.235632</td>\n",
              "      <td>1.540921</td>\n",
              "      <td>0.309007</td>\n",
              "      <td>-1.011861</td>\n",
              "      <td>1.114514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>caregivers</td>\n",
              "      <td>0.846105</td>\n",
              "      <td>0.711858</td>\n",
              "      <td>-0.566384</td>\n",
              "      <td>-1.534437</td>\n",
              "      <td>1.982070</td>\n",
              "      <td>-3.113210</td>\n",
              "      <td>1.800421</td>\n",
              "      <td>5.948302</td>\n",
              "      <td>2.971969</td>\n",
              "      <td>-0.778027</td>\n",
              "      <td>-0.709916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>kalyanakrishnan</td>\n",
              "      <td>5.113711</td>\n",
              "      <td>-0.045879</td>\n",
              "      <td>0.071106</td>\n",
              "      <td>1.541493</td>\n",
              "      <td>2.611017</td>\n",
              "      <td>-2.224080</td>\n",
              "      <td>-1.416454</td>\n",
              "      <td>0.342786</td>\n",
              "      <td>-1.085765</td>\n",
              "      <td>-2.639759</td>\n",
              "      <td>-1.907140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>critical</td>\n",
              "      <td>1.415863</td>\n",
              "      <td>1.352313</td>\n",
              "      <td>3.606753</td>\n",
              "      <td>-2.538007</td>\n",
              "      <td>-1.019799</td>\n",
              "      <td>-0.414112</td>\n",
              "      <td>-1.758153</td>\n",
              "      <td>0.191282</td>\n",
              "      <td>-0.048384</td>\n",
              "      <td>-3.747708</td>\n",
              "      <td>0.160896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>mulligan</td>\n",
              "      <td>1.670050</td>\n",
              "      <td>0.924418</td>\n",
              "      <td>-1.046460</td>\n",
              "      <td>-0.030355</td>\n",
              "      <td>2.275670</td>\n",
              "      <td>2.777074</td>\n",
              "      <td>3.657496</td>\n",
              "      <td>-3.091417</td>\n",
              "      <td>-0.971728</td>\n",
              "      <td>1.507587</td>\n",
              "      <td>3.067374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030</th>\n",
              "      <td>pinning</td>\n",
              "      <td>-1.601588</td>\n",
              "      <td>3.103243</td>\n",
              "      <td>-1.436457</td>\n",
              "      <td>0.147545</td>\n",
              "      <td>-2.684123</td>\n",
              "      <td>-3.436940</td>\n",
              "      <td>-1.520255</td>\n",
              "      <td>-2.624556</td>\n",
              "      <td>-1.208644</td>\n",
              "      <td>-0.638629</td>\n",
              "      <td>-0.855989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1031 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 word        X1        X2  ...        X9       X10       X11\n",
              "0                     -0.030510  0.794130  ...  0.719598  0.729324  0.032105\n",
              "1                high -2.015454  0.884868  ... -0.906213  1.543818  0.609791\n",
              "2             protect -0.487714  2.816028  ...  1.736702  0.618867  0.986666\n",
              "3             systems  0.292698  0.728003  ...  0.881297  0.236392  0.138573\n",
              "4             closely  1.435934  0.594579  ...  3.507608  0.667975  0.923649\n",
              "5               fewer -0.452418  1.659052  ... -2.217718  0.309800  1.525806\n",
              "6              within -2.960756 -4.321366  ... -3.089024 -1.595938  2.551947\n",
              "7     collaboratively  1.194172 -0.755379  ...  1.630548  2.094877  1.108514\n",
              "8          california  2.510731 -0.982859  ...  0.131931  1.613738 -3.311498\n",
              "9             science -0.551139 -1.448377  ...  2.236964 -0.210313 -1.917423\n",
              "10              basic -0.909066 -2.990848  ... -2.277616  0.961267  0.142223\n",
              "11              array  0.582021 -0.087088  ... -0.140981 -2.696630  1.332681\n",
              "12             report -2.258520  0.012439  ... -1.892546 -0.320359 -0.455522\n",
              "13           emphasis  2.039919  1.628837  ...  0.700287  3.458518 -1.334956\n",
              "14               jobs -5.421380  0.999904  ...  0.555225 -0.600967 -0.664459\n",
              "15           dwellers -0.590797 -0.612070  ... -1.004840  0.336542  1.002935\n",
              "16              kinds -0.306280  1.217430  ...  0.947521 -2.817619  0.259863\n",
              "17            related -1.263490  0.090258  ...  0.632642 -3.355846  0.517253\n",
              "18             series -5.240580 -2.059596  ... -2.928806  0.989769 -2.178857\n",
              "19           children  0.936614 -0.406109  ... -2.087314  3.371822  0.206031\n",
              "20            perform -2.981269 -0.258639  ...  3.300816  0.110123 -0.773896\n",
              "21             intent -1.434528 -1.046121  ...  0.012831  1.286609 -1.638112\n",
              "22         particular -4.007369  1.641919  ...  2.231275 -3.551228  1.591439\n",
              "23          inception  0.104651 -2.164328  ...  1.805703 -0.637064  1.393364\n",
              "24           surgical  0.301149  0.712686  ... -1.946841  3.723568 -0.444537\n",
              "25        interaction  0.206737 -2.824313  ... -1.093212  1.638046  0.879077\n",
              "26              areas -0.987216 -1.548787  ...  0.091924 -0.152280  3.195221\n",
              "27            markets -0.298847 -0.741626  ... -1.517872 -3.794070  0.492849\n",
              "28       investigates  2.374478 -1.847623  ...  1.512953 -1.543327  2.307041\n",
              "29           learning  0.584265 -0.535348  ... -0.842558 -0.542797  0.979189\n",
              "...               ...       ...       ...  ...       ...       ...       ...\n",
              "1001       accustomed -1.492105  1.734001  ... -0.720087 -0.370197 -2.363230\n",
              "1002           indian  2.522615 -0.143327  ... -3.916353 -1.939659 -2.677902\n",
              "1003            avoid  0.799362  1.186835  ...  6.195185 -0.006817  0.395418\n",
              "1004        fantasies -1.823676 -0.201644  ...  1.236073 -4.191468 -1.227603\n",
              "1005             mere  0.020670 -4.314106  ...  0.896891  1.209154  3.020351\n",
              "1006      transformed -0.758719 -4.562911  ... -1.172577  0.764768 -0.495048\n",
              "1007      constitutes -2.607455  1.210496  ... -2.871768 -0.119759 -3.155386\n",
              "1008        framework -0.540254 -2.542849  ... -3.496694 -2.143968  3.714683\n",
              "1009        currently -0.364884 -4.202911  ... -0.070719  0.001268  0.759781\n",
              "1010       addressing  4.116459  1.621028  ... -1.018434 -1.317527  0.492480\n",
              "1011            forms -0.503340 -6.595904  ...  1.912181 -0.266938  1.187348\n",
              "1012         labeling  3.349973 -2.003524  ...  1.906543  0.098351  3.732025\n",
              "1013             time -1.906205  0.364989  ... -1.226973  0.680141  0.070321\n",
              "1014            teach -5.403559  0.857080  ...  2.270699  0.935154  1.445499\n",
              "1015          nervous  0.521350  1.199469  ...  1.454482  1.103422 -1.750612\n",
              "1016             greg  1.160068 -1.211616  ...  0.049873 -2.547289 -2.007923\n",
              "1017  recommendations -5.778338  0.559813  ... -0.688992 -1.671984 -2.439376\n",
              "1018       generality -1.609791 -4.216568  ...  1.380363  0.207342 -0.729879\n",
              "1019                j -0.415475  2.580332  ... -0.409209  2.178269 -3.107017\n",
              "1020         facebook  2.042774  1.544387  ... -2.612621 -1.638212 -2.026200\n",
              "1021          already -1.813016  0.058271  ...  1.750095  2.148396 -2.358278\n",
              "1022          improve -0.209605 -0.684662  ...  1.139203  0.693647  0.339563\n",
              "1023           reason  3.280705  2.438143  ...  0.691698  2.612891 -0.737790\n",
              "1024      constraints -1.685513  1.430068  ... -3.453462  0.536071  1.284666\n",
              "1025        prominent -2.247478 -6.255657  ...  0.309007 -1.011861  1.114514\n",
              "1026       caregivers  0.846105  0.711858  ...  2.971969 -0.778027 -0.709916\n",
              "1027  kalyanakrishnan  5.113711 -0.045879  ... -1.085765 -2.639759 -1.907140\n",
              "1028         critical  1.415863  1.352313  ... -0.048384 -3.747708  0.160896\n",
              "1029         mulligan  1.670050  0.924418  ... -0.971728  1.507587  3.067374\n",
              "1030          pinning -1.601588  3.103243  ... -1.208644 -0.638629 -0.855989\n",
              "\n",
              "[1031 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gblT1Grwn1j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving the word embeddings a dictionary of arrays where key is the word and the value is the wordvector in the form of an array\n",
        "wordembeddings={}\n",
        "for i in w2v_df['word']:\n",
        "  vec=[]\n",
        "  j=0\n",
        "  vec.append(w2v_df['X1'][j])\n",
        "  vec.append(w2v_df['X2'][j])\n",
        "  vec.append(w2v_df['X3'][j])\n",
        "  vec.append(w2v_df['X4'][j])\n",
        "  vec.append(w2v_df['X5'][j])\n",
        "  vec.append(w2v_df['X6'][j])\n",
        "  vec.append(w2v_df['X7'][j])\n",
        "  vec.append(w2v_df['X8'][j])\n",
        "  vec.append(w2v_df['X9'][j])\n",
        "  vec.append(w2v_df['X10'][j])\n",
        "  vec.append(w2v_df['X11'][j])\n",
        "  j+=1\n",
        "  wordembeddings[i]= np.asarray(vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toZPOpVBn6Y9",
        "colab_type": "code",
        "outputId": "8ef35bb1-026c-427f-c329-246acdf29971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wordembeddings"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'high': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'protect': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'systems': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'closely': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fewer': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'within': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'collaboratively': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'california': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'science': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'basic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'array': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'report': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'emphasis': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'jobs': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'dwellers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'kinds': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'related': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'series': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'children': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'perform': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'intent': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'particular': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'inception': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'surgical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interaction': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'areas': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'markets': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'investigates': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'learning': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lab': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'spend': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lead': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'none': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'typically': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'strides': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'advance': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'stone': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'creating': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mobile': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'leverages': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mining': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'traffic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'since': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'constellation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'allen': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'overview': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'beneficial': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reliability': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'astro': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'border': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'remove': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'confined': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'prime': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'carry': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'great': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interested': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'institute': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'navigation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'approaches': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'talking': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'definition': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'collecting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'north': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'scalable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'purchases': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'replaced': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'centers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'universities': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'priorities': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'limit': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'clean': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'radically': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'economy': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ai': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'anno': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'particularly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'future': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'seen': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'translation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'films': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'projected': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'regard': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'accelerated': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'perception': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'entered': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'robotics': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hundred': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'face': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'parking': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'medical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'styles': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'kitchens': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interact': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'rely': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'trust': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'example': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'commercial': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'screen': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cities': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'services': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'productivity': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'among': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'techniques': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fictional': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'driving': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'leap': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'signs': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mechanisms': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'goods': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reflects': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'bring': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'movies': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'instead': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'transparency': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'personalities': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'developments': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'nets': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'privacy': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'efforts': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'start': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'specter': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'collaborate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'extremely': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'agencies': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'benefits': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enforcement': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'milind': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'objects': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'home': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'widespread': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'marginalizing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sense': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shivaram': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'changes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'similarly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'russ': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'predictive': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'spoken': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'records': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'computer': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'potentially': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ensuring': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'century': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'physical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'almost': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'solve': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'include': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'even': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'studies': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'treatment': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'smart': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sub': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'typical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cleaners': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'gain': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ways': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hampered': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'force': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'william': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'online': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hardware': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'portrayal': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'remains': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'futurist': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'deep': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'concludes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'superhuman': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'seeing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'understanding': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'intelligent': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'exchanges': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'imagine': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'altman': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'frameworks': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'packages': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fundamental': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'personalized': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'part': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'taken': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'increases': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'considerable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'web': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'math': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'work': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'johns': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'things': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'replacing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'effectively': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'charge': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'offices': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'often': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ever': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'development': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'social': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'liberties': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'impacts': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'large': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'impediments': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'approach': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'harder': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shoham': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'devoting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'seek': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lacking': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'bias': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sequential': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'referred': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'machines': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'eight': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'texas': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'british': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'scenes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mackworth': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'providing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'landscape': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'learn': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mitchell': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'teachers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'targeted': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'take': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'crucial': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'federal': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interacting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'probably': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'directed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'portion': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'trained': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'concurrent': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'extend': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'entertainment': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'personal': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'construction': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'general': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hot': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'scaling': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'technologies': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sensors': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'professionals': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'economic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'attributes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'devices': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'devote': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'everyone': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'capable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'personalization': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'current': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'retrieval': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'responded': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'theory': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'power': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'treasures': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'demand': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'drivers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'rethink': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reconfigure': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'vehicles': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'images': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'needs': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'horvitz': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'years': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'erik': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'issues': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'supporting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'rather': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'taxis': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'becoming': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'engagement': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'revolution': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'academia': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'raises': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'widely': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'one': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'pickup': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'gaining': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'new': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'care': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'underground': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'action': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'phones': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'safe': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'columbia': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'may': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'consumer': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'decision': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'given': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'monitored': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'handle': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'budding': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'grosz': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'automated': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'unpredictable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'organization': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'narrowly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'considers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'separate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'monitoring': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'inferences': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'platforms': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mechanical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'transportation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'higher': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'computing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'generally': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'meant': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'workers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'specific': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'study': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'technical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'taking': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'around': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'set': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'amounts': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'applications': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sixty': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'output': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'promoted': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mechanism': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'students': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ece': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'game': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fulfillment': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'dialog': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'daily': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sectors': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fruits': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fields': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'bar': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'society': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'longer': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'year': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'gradually': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'houses': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hinder': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'alan': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'faces': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'profoundly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'costs': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'possible': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'picture': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'creative': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'tasks': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'front': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'obsolete': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'consumers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'assistance': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'expected': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'touching': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'narrowed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fuels': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'requests': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'oriented': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'press': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'inspired': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fantastic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'facilitated': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'political': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'diagnostics': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'slow': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'academic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'heavily': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'starting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'generalizable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'committee': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'domains': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'automatic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'younger': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'addressed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'machine': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'operate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'likely': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fairness': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ilan': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'models': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'predictable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'health': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hirschberg': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'significant': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'dystopian': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lost': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'google': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'precise': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'real': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'contrary': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'kevin': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'boosted': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'traditionally': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'person': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'provided': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'purposes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'deidre': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'useful': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'field': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'food': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'standing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'labor': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'yoav': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'administration': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'adapt': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'tools': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'nature': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'embodied': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'opportunities': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'empirical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'able': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'especially': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'jams': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'broadly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'competes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'homes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'area': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sustaining': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'coupled': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'improvements': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'make': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'matched': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'provides': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'catalyzed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'stylized': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mind': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'valued': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'astonishing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'dramatically': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'algorithms': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'policy': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'deploy': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'treatments': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'goals': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'become': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'largely': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'begun': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'annalee': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cloud': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hopkins': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'highlight': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'innovation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'find': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'applied': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'strongly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'compose': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'incentives': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'intelligence': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'develop': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'policymakers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cameras': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cause': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'intervals': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'impact': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'alert': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'appliances': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'societal': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'comprising': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'engaging': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'juncture': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'safety': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'impeding': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'must': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'address': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'resource': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'drones': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'iot': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'low': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'scale': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'improved': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reinforcing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'information': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'uneven': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'aware': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'affecting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'distribution': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'react': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'delivery': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'driven': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'nlp': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'help': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'champion': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'also': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'x': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'berkeley': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'etzioni': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enables': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'bringing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hospitals': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'families': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'multiply': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'civil': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'replace': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'variables': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'natural': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'emerging': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'defined': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'known': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'actions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'removing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'forward': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'get': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'underinvested': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'latter': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'networks': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'extent': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'source': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'communities': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lasting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'engage': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fluid': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'weighed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'use': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'building': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'industries': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'apple': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'freedom': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'prevention': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'algorithmic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'financial': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'purpose': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'robots': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shifting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'unlike': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'artificial': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'kraus': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fact': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'developed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'chips': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'propelled': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'teaching': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'inhabit': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'flying': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'dominate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mitigations': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'poisoning': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'computation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enabling': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'produced': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'rapid': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'language': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'done': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'activity': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'prediction': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'potential': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'globe': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'commonplace': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'beyond': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'funders': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enabled': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'next': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'made': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'leverage': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'languages': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'well': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'individual': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'wealth': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'julia': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'tom': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enhance': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'consider': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'result': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'robot': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'effecting': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'outcomes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'representations': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'better': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'attention': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'funding': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'systematizing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'imminent': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'devoted': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fears': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enthusiasm': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'elder': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'emerge': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'impressive': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'certain': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'products': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'imperative': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'wanted': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'speed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sarit': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'immense': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'layered': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'many': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'crowdsourcing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'progress': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'efficiently': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'novels': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'surveillance': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'practical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fifteen': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'brynjolfsson': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'trucks': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'profound': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'always': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'older': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'train': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'memory': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'focused': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'searches': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'build': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'existing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'robustness': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'human': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'period': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'saxenian': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'speech': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'employment': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mimic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'needed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reliable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'julie': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'overcoming': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'entitled': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'different': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sensory': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'everyday': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reduce': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'access': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interconnected': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'continues': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'foreseeable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'apps': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'calo': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'disciplines': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'promote': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'deliver': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'horizon': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'captioning': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'classroom': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hand': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'processing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'tambe': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'text': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'nuanced': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'limited': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'methods': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'facilitate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'buildings': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'environments': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'kamar': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'accomplish': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'scientific': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'influences': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ongoing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'begins': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'concerns': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'concern': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'anticipates': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ensure': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'clinical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'continue': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shared': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'autonomous': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'bigger': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'stairs': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'urban': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'disruptions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'researchers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'settings': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'support': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'internet': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'careful': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'design': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'accruing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ryan': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'monitor': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'firms': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interactive': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'choice': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'differently': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'pattern': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'frightening': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'stimulated': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'near': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'wide': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'american': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'advances': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'values': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'input': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lives': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'suggest': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'spread': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'detect': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'promising': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'commensurate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'deployed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'brooks': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'data': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'modules': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'missteps': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'domain': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hopeful': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'unjustifiably': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'peter': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'active': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'central': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'experts': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'explore': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'scientists': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'move': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'problems': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'threat': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'greater': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'poised': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'concerned': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'providers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'coming': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'safer': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'challenge': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'salient': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mostly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'david': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'companies': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sociability': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cannot': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'term': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'blogs': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cost': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'democratic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'parkes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'popular': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'growing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cut': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'long': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'brown': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'others': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'futures': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'stage': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'drawing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shift': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'suspicion': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'relying': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'computers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'resources': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'harvard': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'imagination': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'procedures': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'require': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'image': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'biological': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'physically': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'requires': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'expertise': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ibm': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ago': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'vacuum': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'agriculture': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'knowledge': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'door': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'influenced': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'important': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'augmented': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'computational': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'drive': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shape': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'thought': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'specialized': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'workplace': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interactions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'patchy': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'abuse': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'play': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'variety': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'expand': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'challenges': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'beat': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sharing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'security': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'government': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'integrated': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'draw': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'vision': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'structural': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'upon': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'performance': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'generate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fraud': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'common': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'increasingly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'markedly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'music': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'developers': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'issued': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'neural': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'manipulation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'research': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'major': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'digital': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'several': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'share': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'found': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'create': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'electronic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'used': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'humans': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'portrayals': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'policing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'patients': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'technological': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'equality': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'fear': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'barbara': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'object': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'eric': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'foremost': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'neuromorphic': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'aspects': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reflection': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'twenty': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'recognition': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'tutors': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enhances': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'people': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'predictions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'spur': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'oren': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'inquiry': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'special': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hospital': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'balance': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'open': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'factories': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'industry': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'videos': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'pace': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'adoption': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'austin': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'calls': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'enable': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'innovate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'live': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'difficulty': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'life': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'collect': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'overbearing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'quite': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'mainstream': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'departments': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'quickly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'innovations': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reinforcement': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'photos': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shifts': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'abundant': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'race': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'business': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'regular': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'chair': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'alone': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'leyton': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'bombay': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'organizations': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'maturation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'augment': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'past': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'determining': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'risks': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'class': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'solutions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'relationships': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'rodney': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'uses': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'successes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'refined': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'education': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'much': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'panel': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'influence': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'city': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'changing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'representing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ethical': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'actively': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'regulatory': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'rise': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'surprising': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'representation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'microsoft': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'debate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'operations': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'scope': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'huge': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'decades': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'service': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'likewise': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'factors': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sets': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'accompanied': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'audio': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'traditional': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'university': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'concerning': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'participants': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'assist': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'significantly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'games': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'realms': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'focus': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'naturally': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'misaligned': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'grown': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'browsing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'quality': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'performances': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'innocent': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'tailored': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'efficiency': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'law': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'struggling': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'interpersonal': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'obstacles': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'decisions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'schools': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'benefit': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'creation': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'directions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'displace': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'public': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'bodies': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'positive': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'classrooms': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'washington': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'relevant': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'based': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'highly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'becomes': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'world': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'massachussets': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'deliberate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'trends': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'exist': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'inroads': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'key': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'promises': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'across': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'video': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hager': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'acknowledged': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'varied': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'first': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'smoothly': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'replaces': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'accurate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'embraced': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'healthcare': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'rate': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'jeopardy': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'attract': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'however': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'cars': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'hollywood': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'levels': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'application': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'commodity': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'though': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lower': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'greatest': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'teller': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'idea': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'agents': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'considered': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'substantial': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reasoning': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'using': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'toward': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'dimensions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'via': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'shah': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sensing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'meaningfully': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sources': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'come': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'making': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'reality': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'entirely': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'self': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'collaborative': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'soon': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'including': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'contributions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'designed': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'size': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'frame': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'risk': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'technology': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'sophisticated': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'lesser': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'millions': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'leading': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'instruction': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'unique': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'transform': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'could': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ehr': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'ahead': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'humankind': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'southern': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'planning': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'experience': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'primarily': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'diminishing': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'provide': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " 'form': array([-0.03050997,  0.79413   , -1.061649  , -0.08344233, -0.13054961,\n",
              "        -0.35226867,  0.18186016, -0.0896504 ,  0.7195977 ,  0.729324  ,\n",
              "         0.03210484], dtype=float32),\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcKvIuqKoX8T",
        "colab_type": "code",
        "outputId": "098dbf04-796a-4a5e-eebf-caa178524772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "#finding the sentence vectors by adding the word vectors of the words in the sentence after cleaning them and dividing by the number of words in that sentence\n",
        "sentence_vect=[]\n",
        "for i in cleaned:\n",
        "  if len(i)!=0:\n",
        "    v = sum([wordembeddings.get(w, np.zeros((11,))) for w in i.split()])/(len(i.split())+0.000001)\n",
        "  else:\n",
        "    v=np.zeros((11,))\n",
        "  sentence_vect.append(v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-21f445032664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwordembeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDgnw0EOodPP",
        "colab_type": "code",
        "outputId": "2ca6e5e7-bc90-4c35-c199-135542300358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence_vect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uec_F0Ogn9ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the similarity matrix\n",
        "sim_mat=np.zeros([len(cleaned),len(cleaned)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9BbAqPsoHrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defing a method for finding out cosine similarity\n",
        "def cossim(g,h):\n",
        "  l=len(g)\n",
        "  x,y,z=0,0,0\n",
        "  for i in range(0,l):\n",
        "    x=x+g[i]*h[i]\n",
        "    y=y+g[i]**2\n",
        "    z=z+h[i]**2\n",
        "  x=x/(y*z)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqrFK58NoK59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filling up the similarity matrix by finding out the similarity between sentences using cossim method\n",
        "for i in range(0, len(cleaned)):\n",
        "  for j in range(0, len(cleaned)):\n",
        "    if i!=j:\n",
        "      g=sentence_vect[i]\n",
        "      h=sentence_vect[j]\n",
        "      sim_mat[i][j]=cossim(g,h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnYcQnKioO_E",
        "colab_type": "code",
        "outputId": "a0ab9793-1b33-40af-b999-a8cda90cf414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#similarity matrix\n",
        "sim_mat"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.23189048, 0.23189049, ..., 0.23189046, 0.23189047,\n",
              "        0.23189056],\n",
              "       [0.23189048, 0.        , 0.2318905 , ..., 0.23189047, 0.23189049,\n",
              "        0.23189058],\n",
              "       [0.23189049, 0.2318905 , 0.        , ..., 0.23189049, 0.2318905 ,\n",
              "        0.23189059],\n",
              "       ...,\n",
              "       [0.23189046, 0.23189047, 0.23189049, ..., 0.        , 0.23189047,\n",
              "        0.23189055],\n",
              "       [0.23189047, 0.23189049, 0.2318905 , ..., 0.23189047, 0.        ,\n",
              "        0.23189057],\n",
              "       [0.23189056, 0.23189058, 0.23189059, ..., 0.23189055, 0.23189057,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AsrkgU0or6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding the edge values ,that is by how much each sentence is similar to other sentences\n",
        "edge=[]\n",
        "for i in range(0,len(cleaned)):\n",
        "  for j in range(i+1,len(cleaned)):\n",
        "    dict={}\n",
        "    dict['weight']=sim_mat[i][j]\n",
        "    edge=edge+[(i,j,dict)]\n",
        "edge=(edge)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nAHBCjhtyI_",
        "colab_type": "code",
        "outputId": "f0cb322a-6be3-4b0f-a271-787548ef7cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "edge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1, {'weight': 0.23189047727328801}),\n",
              " (0, 2, {'weight': 0.23189049459967517}),\n",
              " (0, 3, {'weight': 0.23189047839817792}),\n",
              " (0, 4, {'weight': 0.23189045900924846}),\n",
              " (0, 5, {'weight': 0.23189049457186542}),\n",
              " (0, 6, {'weight': 0.23189048887947641}),\n",
              " (0, 7, {'weight': 0.23189048420026342}),\n",
              " (0, 8, {'weight': 0.23189047396457385}),\n",
              " (0, 9, {'weight': 0.23189049457186542}),\n",
              " (0, 10, {'weight': 0.23189047802240662}),\n",
              " (0, 11, {'weight': 0.23189047802240662}),\n",
              " (0, 12, {'weight': 0.23189043542913357}),\n",
              " (0, 13, {'weight': 0.23189047839817792}),\n",
              " (0, 14, {'weight': 0.23189044609665405}),\n",
              " (0, 15, {'weight': 0.23189047839817792}),\n",
              " (0, 16, {'weight': 0.23189048627175754}),\n",
              " (0, 17, {'weight': 0.23189048046625046}),\n",
              " (0, 18, {'weight': 0.23189047839817792}),\n",
              " (0, 19, {'weight': 0.23189049459967517}),\n",
              " (0, 20, {'weight': 0.23189046298773172}),\n",
              " (0, 21, {'weight': 0.23189048617699695}),\n",
              " (0, 22, {'weight': 0.23189042793582193}),\n",
              " (0, 23, {'weight': 0.2318904780183713}),\n",
              " (0, 24, {'weight': 0.23189049459967517}),\n",
              " (0, 25, {'weight': 0.23189044609665405}),\n",
              " (0, 26, {'weight': 0.23189042668152415}),\n",
              " (0, 27, {'weight': 0.23189048604076734}),\n",
              " (0, 28, {'weight': 0.23189047727328801}),\n",
              " (0, 29, {'weight': 0.23189047802240662}),\n",
              " (0, 30, {'weight': 0.23189048420026342}),\n",
              " (0, 31, {'weight': 0.2318904780183713}),\n",
              " (0, 32, {'weight': 0.23189048617699695}),\n",
              " (0, 33, {'weight': 0.23189047396457385}),\n",
              " (0, 34, {'weight': 0.2318904847924553}),\n",
              " (0, 35, {'weight': 0.23189049134778228}),\n",
              " (0, 36, {'weight': 0.23189048887947641}),\n",
              " (0, 37, {'weight': 0.23189048420026342}),\n",
              " (0, 38, {'weight': 0.23189049459967517}),\n",
              " (0, 39, {'weight': 0.23189047727328801}),\n",
              " (0, 40, {'weight': 0.23189045900924846}),\n",
              " (0, 41, {'weight': 0.2318904847924553}),\n",
              " (0, 42, {'weight': 0.23189049457186542}),\n",
              " (0, 43, {'weight': 0.23189045900924846}),\n",
              " (0, 44, {'weight': 0.23189047839817792}),\n",
              " (0, 45, {'weight': 0.23189044255370855}),\n",
              " (0, 46, {'weight': 0.23189047727328801}),\n",
              " (0, 47, {'weight': 0.23189048604076734}),\n",
              " (0, 48, {'weight': 0.23189049459967517}),\n",
              " (0, 49, {'weight': 0.23189048604076734}),\n",
              " (0, 50, {'weight': 0.23189049459967517}),\n",
              " (0, 51, {'weight': 0.2318904847924553}),\n",
              " (0, 52, {'weight': 0.23189048627175754}),\n",
              " (0, 53, {'weight': 0.23189048604076734}),\n",
              " (0, 54, {'weight': 0.23189048420026342}),\n",
              " (0, 55, {'weight': 0.23189049459967517}),\n",
              " (0, 56, {'weight': 0.2318904847924553}),\n",
              " (0, 57, {'weight': 0.23189049134778228}),\n",
              " (0, 58, {'weight': 0.23189048604076734}),\n",
              " (0, 59, {'weight': 0.23189048617699695}),\n",
              " (0, 60, {'weight': 0.23189049459967517}),\n",
              " (0, 61, {'weight': 0.23189048627175754}),\n",
              " (0, 62, {'weight': 0.23189049457186542}),\n",
              " (0, 63, {'weight': 0.23189047324390755}),\n",
              " (0, 64, {'weight': 0.23189049134778228}),\n",
              " (0, 65, {'weight': 0.23189048420026342}),\n",
              " (0, 66, {'weight': 0.23189049459967517}),\n",
              " (0, 67, {'weight': 0.23189044333228961}),\n",
              " (0, 68, {'weight': 0.23189047727328801}),\n",
              " (0, 69, {'weight': 0.23189048046625046}),\n",
              " (0, 70, {'weight': 0.23189048046625046}),\n",
              " (0, 71, {'weight': 0.23189048617699695}),\n",
              " (0, 72, {'weight': 0.2318904847924553}),\n",
              " (0, 73, {'weight': 0.23189049459967517}),\n",
              " (0, 74, {'weight': 0.23189049134778228}),\n",
              " (0, 75, {'weight': 0.2318904847924553}),\n",
              " (0, 76, {'weight': 0.23189047396457385}),\n",
              " (0, 77, {'weight': 0.23189047324390755}),\n",
              " (0, 78, {'weight': 0.23189049457186542}),\n",
              " (0, 79, {'weight': 0.23189048604076734}),\n",
              " (0, 80, {'weight': 0.2318904780183713}),\n",
              " (0, 81, {'weight': 0.23189047839817792}),\n",
              " (0, 82, {'weight': 0.23189046298773172}),\n",
              " (0, 83, {'weight': 0.23189047839817792}),\n",
              " (0, 84, {'weight': 0.23189048617699695}),\n",
              " (0, 85, {'weight': 0.23189047802240662}),\n",
              " (0, 86, {'weight': 0.23189047802240662}),\n",
              " (0, 87, {'weight': 0.23189049457186542}),\n",
              " (0, 88, {'weight': 0.2318904780183713}),\n",
              " (0, 89, {'weight': 0.23189049134778228}),\n",
              " (0, 90, {'weight': 0.2318904847924553}),\n",
              " (0, 91, {'weight': 0.23189049459967517}),\n",
              " (0, 92, {'weight': 0.2318904847924553}),\n",
              " (0, 93, {'weight': 0.23189048617699695}),\n",
              " (0, 94, {'weight': 0.23189049457186542}),\n",
              " (0, 95, {'weight': 0.23189048604076734}),\n",
              " (0, 96, {'weight': 0.23189047396457385}),\n",
              " (0, 97, {'weight': 0.23189049457186542}),\n",
              " (0, 98, {'weight': 0.23189048604076734}),\n",
              " (0, 99, {'weight': 0.2318904847924553}),\n",
              " (0, 100, {'weight': 0.23189048604076734}),\n",
              " (0, 101, {'weight': 0.23189048420026342}),\n",
              " (0, 102, {'weight': 0.2318905303555726}),\n",
              " (0, 103, {'weight': 0.23189048604076734}),\n",
              " (0, 104, {'weight': 0.23189048046625046}),\n",
              " (0, 105, {'weight': 0.23189048046625046}),\n",
              " (0, 106, {'weight': 0.23189049134778228}),\n",
              " (0, 107, {'weight': 0.2318904780183713}),\n",
              " (0, 108, {'weight': 0.23189048627175754}),\n",
              " (0, 109, {'weight': 0.23189047802240662}),\n",
              " (0, 110, {'weight': 0.2318904574298416}),\n",
              " (0, 111, {'weight': 0.23189045482533416}),\n",
              " (0, 112, {'weight': 0.2318904639036663}),\n",
              " (0, 113, {'weight': 0.23189047802240662}),\n",
              " (0, 114, {'weight': 0.2318904847924553}),\n",
              " (0, 115, {'weight': 0.23189048617699695}),\n",
              " (0, 116, {'weight': 0.23189049134778228}),\n",
              " (0, 117, {'weight': 0.23189047727328801}),\n",
              " (0, 118, {'weight': 0.23189048604076734}),\n",
              " (0, 119, {'weight': 0.23189048604076734}),\n",
              " (0, 120, {'weight': 0.23189048420026342}),\n",
              " (0, 121, {'weight': 0.23189048604076734}),\n",
              " (0, 122, {'weight': 0.23189049457186542}),\n",
              " (0, 123, {'weight': 0.23189047727328801}),\n",
              " (0, 124, {'weight': 0.23189049459967517}),\n",
              " (0, 125, {'weight': 0.23189047802240662}),\n",
              " (0, 126, {'weight': 0.2318904780183713}),\n",
              " (0, 127, {'weight': 0.23189045482533416}),\n",
              " (0, 128, {'weight': 0.2318904639036663}),\n",
              " (0, 129, {'weight': 0.23189045900924846}),\n",
              " (0, 130, {'weight': 0.23189047324390755}),\n",
              " (0, 131, {'weight': 0.23189055839874806}),\n",
              " (1, 2, {'weight': 0.23189050476416476}),\n",
              " (1, 3, {'weight': 0.23189049036555448}),\n",
              " (1, 4, {'weight': 0.2318904725791909}),\n",
              " (1, 5, {'weight': 0.2318905041353926}),\n",
              " (1, 6, {'weight': 0.23189050084685314}),\n",
              " (1, 7, {'weight': 0.23189049436475304}),\n",
              " (1, 8, {'weight': 0.23189048813547886}),\n",
              " (1, 9, {'weight': 0.2318905041353926}),\n",
              " (1, 10, {'weight': 0.2318904899897833}),\n",
              " (1, 11, {'weight': 0.2318904899897833}),\n",
              " (1, 12, {'weight': 0.23189045120260346}),\n",
              " (1, 13, {'weight': 0.23189049036555448}),\n",
              " (1, 14, {'weight': 0.23189046187012438}),\n",
              " (1, 15, {'weight': 0.23189049036555448}),\n",
              " (1, 16, {'weight': 0.23189049663656808}),\n",
              " (1, 17, {'weight': 0.23189049002977788}),\n",
              " (1, 18, {'weight': 0.23189049036555448}),\n",
              " (1, 19, {'weight': 0.23189050476416476}),\n",
              " (1, 20, {'weight': 0.23189047655767414}),\n",
              " (1, 21, {'weight': 0.23189049714276966}),\n",
              " (1, 22, {'weight': 0.23189044390961228}),\n",
              " (1, 23, {'weight': 0.23189049299055944}),\n",
              " (1, 24, {'weight': 0.23189050476416476}),\n",
              " (1, 25, {'weight': 0.23189046187012438}),\n",
              " (1, 26, {'weight': 0.23189043704633555}),\n",
              " (1, 27, {'weight': 0.2318904964055777}),\n",
              " (1, 28, {'weight': 0.23189048924066466}),\n",
              " (1, 29, {'weight': 0.2318904899897833}),\n",
              " (1, 30, {'weight': 0.23189049436475304}),\n",
              " (1, 31, {'weight': 0.23189049299055944}),\n",
              " (1, 32, {'weight': 0.23189049714276966}),\n",
              " (1, 33, {'weight': 0.23189048813547886}),\n",
              " (1, 34, {'weight': 0.23189049495694491}),\n",
              " (1, 35, {'weight': 0.23189050091130958}),\n",
              " (1, 36, {'weight': 0.23189050084685314}),\n",
              " (1, 37, {'weight': 0.23189049436475304}),\n",
              " (1, 38, {'weight': 0.23189050476416476}),\n",
              " (1, 39, {'weight': 0.23189048924066466}),\n",
              " (1, 40, {'weight': 0.2318904725791909}),\n",
              " (1, 41, {'weight': 0.23189049495694491}),\n",
              " (1, 42, {'weight': 0.2318905041353926}),\n",
              " (1, 43, {'weight': 0.2318904725791909}),\n",
              " (1, 44, {'weight': 0.23189049036555448}),\n",
              " (1, 45, {'weight': 0.2318904593287823}),\n",
              " (1, 46, {'weight': 0.23189048924066466}),\n",
              " (1, 47, {'weight': 0.2318904964055777}),\n",
              " (1, 48, {'weight': 0.23189050476416476}),\n",
              " (1, 49, {'weight': 0.2318904964055777}),\n",
              " (1, 50, {'weight': 0.23189050476416476}),\n",
              " (1, 51, {'weight': 0.23189049495694491}),\n",
              " (1, 52, {'weight': 0.23189049663656808}),\n",
              " (1, 53, {'weight': 0.2318904964055777}),\n",
              " (1, 54, {'weight': 0.23189049436475304}),\n",
              " (1, 55, {'weight': 0.23189050476416476}),\n",
              " (1, 56, {'weight': 0.23189049495694491}),\n",
              " (1, 57, {'weight': 0.23189050091130958}),\n",
              " (1, 58, {'weight': 0.2318904964055777}),\n",
              " (1, 59, {'weight': 0.23189049714276966}),\n",
              " (1, 60, {'weight': 0.23189050476416476}),\n",
              " (1, 61, {'weight': 0.23189049663656808}),\n",
              " (1, 62, {'weight': 0.2318905041353926}),\n",
              " (1, 63, {'weight': 0.23189048661352946}),\n",
              " (1, 64, {'weight': 0.23189050091130958}),\n",
              " (1, 65, {'weight': 0.23189049436475304}),\n",
              " (1, 66, {'weight': 0.23189050476416476}),\n",
              " (1, 67, {'weight': 0.2318904601073634}),\n",
              " (1, 68, {'weight': 0.23189048924066466}),\n",
              " (1, 69, {'weight': 0.23189049002977788}),\n",
              " (1, 70, {'weight': 0.23189049002977788}),\n",
              " (1, 71, {'weight': 0.23189049714276966}),\n",
              " (1, 72, {'weight': 0.23189049495694491}),\n",
              " (1, 73, {'weight': 0.23189050476416476}),\n",
              " (1, 74, {'weight': 0.23189050091130958}),\n",
              " (1, 75, {'weight': 0.23189049495694491}),\n",
              " (1, 76, {'weight': 0.23189048813547886}),\n",
              " (1, 77, {'weight': 0.23189048661352946}),\n",
              " (1, 78, {'weight': 0.2318905041353926}),\n",
              " (1, 79, {'weight': 0.2318904964055777}),\n",
              " (1, 80, {'weight': 0.23189049299055944}),\n",
              " (1, 81, {'weight': 0.23189049036555448}),\n",
              " (1, 82, {'weight': 0.23189047655767414}),\n",
              " (1, 83, {'weight': 0.23189049036555448}),\n",
              " (1, 84, {'weight': 0.23189049714276966}),\n",
              " (1, 85, {'weight': 0.2318904899897833}),\n",
              " (1, 86, {'weight': 0.2318904899897833}),\n",
              " (1, 87, {'weight': 0.2318905041353926}),\n",
              " (1, 88, {'weight': 0.23189049299055944}),\n",
              " (1, 89, {'weight': 0.23189050091130958}),\n",
              " (1, 90, {'weight': 0.23189049495694491}),\n",
              " (1, 91, {'weight': 0.23189050476416476}),\n",
              " (1, 92, {'weight': 0.23189049495694491}),\n",
              " (1, 93, {'weight': 0.23189049714276966}),\n",
              " (1, 94, {'weight': 0.2318905041353926}),\n",
              " (1, 95, {'weight': 0.2318904964055777}),\n",
              " (1, 96, {'weight': 0.23189048813547886}),\n",
              " (1, 97, {'weight': 0.2318905041353926}),\n",
              " (1, 98, {'weight': 0.2318904964055777}),\n",
              " (1, 99, {'weight': 0.23189049495694491}),\n",
              " (1, 100, {'weight': 0.2318904964055777}),\n",
              " (1, 101, {'weight': 0.23189049436475304}),\n",
              " (1, 102, {'weight': 0.23189054693032923}),\n",
              " (1, 103, {'weight': 0.2318904964055777}),\n",
              " (1, 104, {'weight': 0.23189049002977788}),\n",
              " (1, 105, {'weight': 0.23189049002977788}),\n",
              " (1, 106, {'weight': 0.23189050091130958}),\n",
              " (1, 107, {'weight': 0.23189049299055944}),\n",
              " (1, 108, {'weight': 0.23189049663656808}),\n",
              " (1, 109, {'weight': 0.2318904899897833}),\n",
              " (1, 110, {'weight': 0.2318904774100479}),\n",
              " (1, 111, {'weight': 0.2318904716004084}),\n",
              " (1, 112, {'weight': 0.23189047727328801}),\n",
              " (1, 113, {'weight': 0.2318904899897833}),\n",
              " (1, 114, {'weight': 0.23189049495694491}),\n",
              " (1, 115, {'weight': 0.23189049714276966}),\n",
              " (1, 116, {'weight': 0.23189050091130958}),\n",
              " (1, 117, {'weight': 0.23189048924066466}),\n",
              " (1, 118, {'weight': 0.2318904964055777}),\n",
              " (1, 119, {'weight': 0.2318904964055777}),\n",
              " (1, 120, {'weight': 0.23189049436475304}),\n",
              " (1, 121, {'weight': 0.2318904964055777}),\n",
              " (1, 122, {'weight': 0.2318905041353926}),\n",
              " (1, 123, {'weight': 0.23189048924066466}),\n",
              " (1, 124, {'weight': 0.23189050476416476}),\n",
              " (1, 125, {'weight': 0.2318904899897833}),\n",
              " (1, 126, {'weight': 0.23189049299055944}),\n",
              " (1, 127, {'weight': 0.2318904716004084}),\n",
              " (1, 128, {'weight': 0.23189047727328801}),\n",
              " (1, 129, {'weight': 0.2318904725791909}),\n",
              " (1, 130, {'weight': 0.23189048661352946}),\n",
              " (1, 131, {'weight': 0.23189057517382672}),\n",
              " (2, 3, {'weight': 0.23189050588905458}),\n",
              " (2, 4, {'weight': 0.23189048970525727}),\n",
              " (2, 5, {'weight': 0.23189051965889257}),\n",
              " (2, 6, {'weight': 0.23189051637035324}),\n",
              " (2, 7, {'weight': 0.23189051169114036}),\n",
              " (2, 8, {'weight': 0.23189050466058309}),\n",
              " (2, 9, {'weight': 0.23189051965889257}),\n",
              " (2, 10, {'weight': 0.23189050551328338}),\n",
              " (2, 11, {'weight': 0.23189050551328338}),\n",
              " (2, 12, {'weight': 0.23189046131744434}),\n",
              " (2, 13, {'weight': 0.23189050588905458}),\n",
              " (2, 14, {'weight': 0.23189047198496496}),\n",
              " (2, 15, {'weight': 0.23189050588905458}),\n",
              " (2, 16, {'weight': 0.23189051216006823}),\n",
              " (2, 17, {'weight': 0.2318905055532779}),\n",
              " (2, 18, {'weight': 0.23189050588905458}),\n",
              " (2, 19, {'weight': 0.23189052048798567}),\n",
              " (2, 20, {'weight': 0.23189049368374054}),\n",
              " (2, 21, {'weight': 0.23189051366787378}),\n",
              " (2, 22, {'weight': 0.23189045943311296}),\n",
              " (2, 23, {'weight': 0.23189050871438047}),\n",
              " (2, 24, {'weight': 0.23189052048798567}),\n",
              " (2, 25, {'weight': 0.23189047198496496}),\n",
              " (2, 26, {'weight': 0.23189045337111888}),\n",
              " (2, 27, {'weight': 0.23189051353164422}),\n",
              " (2, 28, {'weight': 0.23189050476416476}),\n",
              " (2, 29, {'weight': 0.23189050551328338}),\n",
              " (2, 30, {'weight': 0.23189051169114036}),\n",
              " (2, 31, {'weight': 0.23189050871438047}),\n",
              " (2, 32, {'weight': 0.23189051366787378}),\n",
              " (2, 33, {'weight': 0.23189050466058309}),\n",
              " (2, 34, {'weight': 0.23189051228333224}),\n",
              " (2, 35, {'weight': 0.23189051643480962}),\n",
              " (2, 36, {'weight': 0.23189051637035324}),\n",
              " (2, 37, {'weight': 0.23189051169114036}),\n",
              " (2, 38, {'weight': 0.23189052048798567}),\n",
              " (2, 39, {'weight': 0.23189050476416476}),\n",
              " (2, 40, {'weight': 0.23189048970525727}),\n",
              " (2, 41, {'weight': 0.23189051228333224}),\n",
              " (2, 42, {'weight': 0.23189051965889257}),\n",
              " (2, 43, {'weight': 0.23189048970525727}),\n",
              " (2, 44, {'weight': 0.23189050588905458}),\n",
              " (2, 45, {'weight': 0.2318904692433022}),\n",
              " (2, 46, {'weight': 0.23189050476416476}),\n",
              " (2, 47, {'weight': 0.23189051353164422}),\n",
              " (2, 48, {'weight': 0.23189052048798567}),\n",
              " (2, 49, {'weight': 0.23189051353164422}),\n",
              " (2, 50, {'weight': 0.23189052048798567}),\n",
              " (2, 51, {'weight': 0.23189051228333224}),\n",
              " (2, 52, {'weight': 0.23189051216006823}),\n",
              " (2, 53, {'weight': 0.23189051353164422}),\n",
              " (2, 54, {'weight': 0.23189051169114036}),\n",
              " (2, 55, {'weight': 0.23189052048798567}),\n",
              " (2, 56, {'weight': 0.23189051228333224}),\n",
              " (2, 57, {'weight': 0.23189051643480962}),\n",
              " (2, 58, {'weight': 0.23189051353164422}),\n",
              " (2, 59, {'weight': 0.23189051366787378}),\n",
              " (2, 60, {'weight': 0.23189052048798567}),\n",
              " (2, 61, {'weight': 0.23189051216006823}),\n",
              " (2, 62, {'weight': 0.23189051965889257}),\n",
              " (2, 63, {'weight': 0.23189050233735037}),\n",
              " (2, 64, {'weight': 0.23189051643480962}),\n",
              " (2, 65, {'weight': 0.23189051169114036}),\n",
              " (2, 66, {'weight': 0.23189052048798567}),\n",
              " (2, 67, {'weight': 0.23189047563086407}),\n",
              " (2, 68, {'weight': 0.23189050476416476}),\n",
              " (2, 69, {'weight': 0.2318905055532779}),\n",
              " (2, 70, {'weight': 0.2318905055532779}),\n",
              " (2, 71, {'weight': 0.23189051366787378}),\n",
              " (2, 72, {'weight': 0.23189051228333224}),\n",
              " (2, 73, {'weight': 0.23189052048798567}),\n",
              " (2, 74, {'weight': 0.23189051643480962}),\n",
              " (2, 75, {'weight': 0.23189051228333224}),\n",
              " (2, 76, {'weight': 0.23189050466058309}),\n",
              " (2, 77, {'weight': 0.23189050233735037}),\n",
              " (2, 78, {'weight': 0.23189051965889257}),\n",
              " (2, 79, {'weight': 0.23189051353164422}),\n",
              " (2, 80, {'weight': 0.23189050871438047}),\n",
              " (2, 81, {'weight': 0.23189050588905458}),\n",
              " (2, 82, {'weight': 0.23189049368374054}),\n",
              " (2, 83, {'weight': 0.23189050588905458}),\n",
              " (2, 84, {'weight': 0.23189051366787378}),\n",
              " (2, 85, {'weight': 0.23189050551328338}),\n",
              " (2, 86, {'weight': 0.23189050551328338}),\n",
              " (2, 87, {'weight': 0.23189051965889257}),\n",
              " (2, 88, {'weight': 0.23189050871438047}),\n",
              " (2, 89, {'weight': 0.23189051643480962}),\n",
              " (2, 90, {'weight': 0.23189051228333224}),\n",
              " (2, 91, {'weight': 0.23189052048798567}),\n",
              " (2, 92, {'weight': 0.23189051228333224}),\n",
              " (2, 93, {'weight': 0.23189051366787378}),\n",
              " (2, 94, {'weight': 0.23189051965889257}),\n",
              " (2, 95, {'weight': 0.23189051353164422}),\n",
              " (2, 96, {'weight': 0.23189050466058309}),\n",
              " (2, 97, {'weight': 0.23189051965889257}),\n",
              " (2, 98, {'weight': 0.23189051353164422}),\n",
              " (2, 99, {'weight': 0.23189051228333224}),\n",
              " (2, 100, {'weight': 0.23189051353164422}),\n",
              " (2, 101, {'weight': 0.23189051169114036}),\n",
              " (2, 102, {'weight': 0.2318905626541504}),\n",
              " (2, 103, {'weight': 0.23189051353164422}),\n",
              " (2, 104, {'weight': 0.2318905055532779}),\n",
              " (2, 105, {'weight': 0.2318905055532779}),\n",
              " (2, 106, {'weight': 0.23189051643480962}),\n",
              " (2, 107, {'weight': 0.23189050871438047}),\n",
              " (2, 108, {'weight': 0.23189051216006823}),\n",
              " (2, 109, {'weight': 0.23189050551328338}),\n",
              " (2, 110, {'weight': 0.2318904865232843}),\n",
              " (2, 111, {'weight': 0.23189048391877684}),\n",
              " (2, 112, {'weight': 0.23189049459967517}),\n",
              " (2, 113, {'weight': 0.23189050551328338}),\n",
              " (2, 114, {'weight': 0.23189051228333224}),\n",
              " (2, 115, {'weight': 0.23189051366787378}),\n",
              " (2, 116, {'weight': 0.23189051643480962}),\n",
              " (2, 117, {'weight': 0.23189050476416476}),\n",
              " (2, 118, {'weight': 0.23189051353164422}),\n",
              " (2, 119, {'weight': 0.23189051353164422}),\n",
              " (2, 120, {'weight': 0.23189051169114036}),\n",
              " (2, 121, {'weight': 0.23189051353164422}),\n",
              " (2, 122, {'weight': 0.23189051965889257}),\n",
              " (2, 123, {'weight': 0.23189050476416476}),\n",
              " (2, 124, {'weight': 0.23189052048798567}),\n",
              " (2, 125, {'weight': 0.23189050551328338}),\n",
              " (2, 126, {'weight': 0.23189050871438047}),\n",
              " (2, 127, {'weight': 0.23189048391877684}),\n",
              " (2, 128, {'weight': 0.23189049459967517}),\n",
              " (2, 129, {'weight': 0.23189048970525727}),\n",
              " (2, 130, {'weight': 0.23189050233735037}),\n",
              " (2, 131, {'weight': 0.23189058749219169}),\n",
              " (3, 4, {'weight': 0.23189047370408078}),\n",
              " (3, 5, {'weight': 0.23189050606156564}),\n",
              " (3, 6, {'weight': 0.23189050197174296}),\n",
              " (3, 7, {'weight': 0.2318904954896429}),\n",
              " (3, 8, {'weight': 0.2318904892603687}),\n",
              " (3, 9, {'weight': 0.23189050606156564}),\n",
              " (3, 10, {'weight': 0.23189049111467314}),\n",
              " (3, 11, {'weight': 0.23189049111467314}),\n",
              " (3, 12, {'weight': 0.23189045232749347}),\n",
              " (3, 13, {'weight': 0.23189049149044436}),\n",
              " (3, 14, {'weight': 0.23189046379629727}),\n",
              " (3, 15, {'weight': 0.23189049149044436}),\n",
              " (3, 16, {'weight': 0.23189049776145793}),\n",
              " (3, 17, {'weight': 0.23189049195595085}),\n",
              " (3, 18, {'weight': 0.23189049149044436}),\n",
              " (3, 19, {'weight': 0.23189050588905458}),\n",
              " (3, 20, {'weight': 0.23189047768256407}),\n",
              " (3, 21, {'weight': 0.2318904982676595}),\n",
              " (3, 22, {'weight': 0.23189044583578503}),\n",
              " (3, 23, {'weight': 0.23189049411544932}),\n",
              " (3, 24, {'weight': 0.23189050588905458}),\n",
              " (3, 25, {'weight': 0.23189046379629727}),\n",
              " (3, 26, {'weight': 0.23189043817122554}),\n",
              " (3, 27, {'weight': 0.23189049753046756}),\n",
              " (3, 28, {'weight': 0.23189049036555448}),\n",
              " (3, 29, {'weight': 0.23189049111467314}),\n",
              " (3, 30, {'weight': 0.2318904954896429}),\n",
              " (3, 31, {'weight': 0.23189049411544932}),\n",
              " (3, 32, {'weight': 0.2318904982676595}),\n",
              " (3, 33, {'weight': 0.2318904892603687}),\n",
              " (3, 34, {'weight': 0.23189049608183473}),\n",
              " (3, 35, {'weight': 0.23189050283748264}),\n",
              " (3, 36, {'weight': 0.23189050197174296}),\n",
              " (3, 37, {'weight': 0.2318904954896429}),\n",
              " (3, 38, {'weight': 0.23189050588905458}),\n",
              " (3, 39, {'weight': 0.23189049036555448}),\n",
              " (3, 40, {'weight': 0.23189047370408078}),\n",
              " (3, 41, {'weight': 0.23189049608183473}),\n",
              " (3, 42, {'weight': 0.23189050606156564}),\n",
              " (3, 43, {'weight': 0.23189047370408078}),\n",
              " (3, 44, {'weight': 0.23189049149044436}),\n",
              " (3, 45, {'weight': 0.2318904604536723}),\n",
              " (3, 46, {'weight': 0.23189049036555448}),\n",
              " (3, 47, {'weight': 0.23189049753046756}),\n",
              " (3, 48, {'weight': 0.23189050588905458}),\n",
              " (3, 49, {'weight': 0.23189049753046756}),\n",
              " (3, 50, {'weight': 0.23189050588905458}),\n",
              " (3, 51, {'weight': 0.23189049608183473}),\n",
              " (3, 52, {'weight': 0.23189049776145793}),\n",
              " (3, 53, {'weight': 0.23189049753046756}),\n",
              " (3, 54, {'weight': 0.2318904954896429}),\n",
              " (3, 55, {'weight': 0.23189050588905458}),\n",
              " (3, 56, {'weight': 0.23189049608183473}),\n",
              " (3, 57, {'weight': 0.23189050283748264}),\n",
              " (3, 58, {'weight': 0.23189049753046756}),\n",
              " (3, 59, {'weight': 0.2318904982676595}),\n",
              " (3, 60, {'weight': 0.23189050588905458}),\n",
              " (3, 61, {'weight': 0.23189049776145793}),\n",
              " (3, 62, {'weight': 0.23189050606156564}),\n",
              " (3, 63, {'weight': 0.23189048773841933}),\n",
              " (3, 64, {'weight': 0.23189050283748264}),\n",
              " (3, 65, {'weight': 0.2318904954896429}),\n",
              " (3, 66, {'weight': 0.23189050588905458}),\n",
              " (3, 67, {'weight': 0.23189046123225335}),\n",
              " (3, 68, {'weight': 0.23189049036555448}),\n",
              " (3, 69, {'weight': 0.23189049195595085}),\n",
              " (3, 70, {'weight': 0.23189049195595085}),\n",
              " (3, 71, {'weight': 0.2318904982676595}),\n",
              " (3, 72, {'weight': 0.23189049608183473}),\n",
              " (3, 73, {'weight': 0.23189050588905458}),\n",
              " (3, 74, {'weight': 0.23189050283748264}),\n",
              " (3, 75, {'weight': 0.23189049608183473}),\n",
              " (3, 76, {'weight': 0.2318904892603687}),\n",
              " (3, 77, {'weight': 0.23189048773841933}),\n",
              " (3, 78, {'weight': 0.23189050606156564}),\n",
              " (3, 79, {'weight': 0.23189049753046756}),\n",
              " (3, 80, {'weight': 0.23189049411544932}),\n",
              " (3, 81, {'weight': 0.23189049149044436}),\n",
              " (3, 82, {'weight': 0.23189047768256407}),\n",
              " (3, 83, {'weight': 0.23189049149044436}),\n",
              " (3, 84, {'weight': 0.2318904982676595}),\n",
              " (3, 85, {'weight': 0.23189049111467314}),\n",
              " (3, 86, {'weight': 0.23189049111467314}),\n",
              " (3, 87, {'weight': 0.23189050606156564}),\n",
              " (3, 88, {'weight': 0.23189049411544932}),\n",
              " (3, 89, {'weight': 0.23189050283748264}),\n",
              " (3, 90, {'weight': 0.23189049608183473}),\n",
              " (3, 91, {'weight': 0.23189050588905458}),\n",
              " (3, 92, {'weight': 0.23189049608183473}),\n",
              " (3, 93, {'weight': 0.2318904982676595}),\n",
              " (3, 94, {'weight': 0.23189050606156564}),\n",
              " (3, 95, {'weight': 0.23189049753046756}),\n",
              " (3, 96, {'weight': 0.2318904892603687}),\n",
              " (3, 97, {'weight': 0.23189050606156564}),\n",
              " (3, 98, {'weight': 0.23189049753046756}),\n",
              " (3, 99, {'weight': 0.23189049608183473}),\n",
              " (3, 100, {'weight': 0.23189049753046756}),\n",
              " (3, 101, {'weight': 0.2318904954896429}),\n",
              " (3, 102, {'weight': 0.231890548055219}),\n",
              " (3, 103, {'weight': 0.23189049753046756}),\n",
              " (3, 104, {'weight': 0.23189049195595085}),\n",
              " (3, 105, {'weight': 0.23189049195595085}),\n",
              " (3, 106, {'weight': 0.23189050283748264}),\n",
              " (3, 107, {'weight': 0.23189049411544932}),\n",
              " (3, 108, {'weight': 0.23189049776145793}),\n",
              " (3, 109, {'weight': 0.23189049111467314}),\n",
              " (3, 110, {'weight': 0.2318904785349379}),\n",
              " (3, 111, {'weight': 0.23189047272529836}),\n",
              " (3, 112, {'weight': 0.23189047839817792}),\n",
              " (3, 113, {'weight': 0.23189049111467314}),\n",
              " (3, 114, {'weight': 0.23189049608183473}),\n",
              " (3, 115, {'weight': 0.2318904982676595}),\n",
              " (3, 116, {'weight': 0.23189050283748264}),\n",
              " (3, 117, {'weight': 0.23189049036555448}),\n",
              " (3, 118, {'weight': 0.23189049753046756}),\n",
              " (3, 119, {'weight': 0.23189049753046756}),\n",
              " (3, 120, {'weight': 0.2318904954896429}),\n",
              " (3, 121, {'weight': 0.23189049753046756}),\n",
              " (3, 122, {'weight': 0.23189050606156564}),\n",
              " (3, 123, {'weight': 0.23189049036555448}),\n",
              " (3, 124, {'weight': 0.23189050588905458}),\n",
              " (3, 125, {'weight': 0.23189049111467314}),\n",
              " (3, 126, {'weight': 0.23189049411544932}),\n",
              " (3, 127, {'weight': 0.23189047272529836}),\n",
              " (3, 128, {'weight': 0.23189047839817792}),\n",
              " (3, 129, {'weight': 0.23189047370408078}),\n",
              " (3, 130, {'weight': 0.23189048773841933}),\n",
              " (3, 131, {'weight': 0.23189057629871643}),\n",
              " (4, 5, {'weight': 0.2318904898777683}),\n",
              " (4, 6, {'weight': 0.2318904841853794}),\n",
              " (4, 7, {'weight': 0.23189047930584553}),\n",
              " (4, 8, {'weight': 0.23189046907015606}),\n",
              " (4, 9, {'weight': 0.2318904898777683}),\n",
              " (4, 10, {'weight': 0.23189047332830953}),\n",
              " (4, 11, {'weight': 0.23189047332830953}),\n",
              " (4, 12, {'weight': 0.23189043053471559}),\n",
              " (4, 13, {'weight': 0.23189047370408078}),\n",
              " (4, 14, {'weight': 0.2318904395996705}),\n",
              " (4, 15, {'weight': 0.23189047370408078}),\n",
              " (4, 16, {'weight': 0.2318904767699621}),\n",
              " (4, 17, {'weight': 0.23189047416958727}),\n",
              " (4, 18, {'weight': 0.23189047370408078}),\n",
              " (4, 19, {'weight': 0.23189048970525727}),\n",
              " (4, 20, {'weight': 0.2318904582936346}),\n",
              " (4, 21, {'weight': 0.23189048128257908}),\n",
              " (4, 22, {'weight': 0.23189042244044195}),\n",
              " (4, 23, {'weight': 0.23189047312395356}),\n",
              " (4, 24, {'weight': 0.23189048970525727}),\n",
              " (4, 25, {'weight': 0.2318904395996705}),\n",
              " (4, 26, {'weight': 0.23189041878229616}),\n",
              " (4, 27, {'weight': 0.23189048134667023}),\n",
              " (4, 28, {'weight': 0.2318904725791909}),\n",
              " (4, 29, {'weight': 0.23189047332830953}),\n",
              " (4, 30, {'weight': 0.23189047930584553}),\n",
              " (4, 31, {'weight': 0.23189047312395356}),\n",
              " (4, 32, {'weight': 0.23189048128257908}),\n",
              " (4, 33, {'weight': 0.23189046907015606}),\n",
              " (4, 34, {'weight': 0.23189047989803743}),\n",
              " (4, 35, {'weight': 0.23189048665368517}),\n",
              " (4, 36, {'weight': 0.2318904841853794}),\n",
              " (4, 37, {'weight': 0.23189047930584553}),\n",
              " (4, 38, {'weight': 0.23189048970525727}),\n",
              " (4, 39, {'weight': 0.2318904725791909}),\n",
              " (4, 40, {'weight': 0.23189045431515135}),\n",
              " (4, 41, {'weight': 0.23189047989803743}),\n",
              " (4, 42, {'weight': 0.2318904898777683}),\n",
              " (4, 43, {'weight': 0.23189045431515135}),\n",
              " (4, 44, {'weight': 0.23189047370408078}),\n",
              " (4, 45, {'weight': 0.23189043705832857}),\n",
              " (4, 46, {'weight': 0.2318904725791909}),\n",
              " (4, 47, {'weight': 0.23189048134667023}),\n",
              " (4, 48, {'weight': 0.23189048970525727}),\n",
              " (4, 49, {'weight': 0.23189048134667023}),\n",
              " (4, 50, {'weight': 0.23189048970525727}),\n",
              " (4, 51, {'weight': 0.23189047989803743}),\n",
              " (4, 52, {'weight': 0.2318904767699621}),\n",
              " (4, 53, {'weight': 0.23189048134667023}),\n",
              " (4, 54, {'weight': 0.23189047930584553}),\n",
              " (4, 55, {'weight': 0.23189048970525727}),\n",
              " (4, 56, {'weight': 0.23189047989803743}),\n",
              " (4, 57, {'weight': 0.23189048665368517}),\n",
              " (4, 58, {'weight': 0.23189048134667023}),\n",
              " (4, 59, {'weight': 0.23189048128257908}),\n",
              " (4, 60, {'weight': 0.23189048970525727}),\n",
              " (4, 61, {'weight': 0.2318904767699621}),\n",
              " (4, 62, {'weight': 0.2318904898777683}),\n",
              " (4, 63, {'weight': 0.23189046674692382}),\n",
              " (4, 64, {'weight': 0.23189048665368517}),\n",
              " (4, 65, {'weight': 0.23189047930584553}),\n",
              " (4, 66, {'weight': 0.23189048970525727}),\n",
              " (4, 67, {'weight': 0.23189043863819236}),\n",
              " (4, 68, {'weight': 0.2318904725791909}),\n",
              " (4, 69, {'weight': 0.23189047416958727}),\n",
              " (4, 70, {'weight': 0.23189047416958727}),\n",
              " (4, 71, {'weight': 0.23189048128257908}),\n",
              " (4, 72, {'weight': 0.23189047989803743}),\n",
              " (4, 73, {'weight': 0.23189048970525727}),\n",
              " (4, 74, {'weight': 0.23189048665368517}),\n",
              " (4, 75, {'weight': 0.23189047989803743}),\n",
              " (4, 76, {'weight': 0.23189046907015606}),\n",
              " (4, 77, {'weight': 0.23189046674692382}),\n",
              " (4, 78, {'weight': 0.2318904898777683}),\n",
              " (4, 79, {'weight': 0.23189048134667023}),\n",
              " (4, 80, {'weight': 0.23189047312395356}),\n",
              " (4, 81, {'weight': 0.23189047370408078}),\n",
              " (4, 82, {'weight': 0.2318904582936346}),\n",
              " (4, 83, {'weight': 0.23189047370408078}),\n",
              " (4, 84, {'weight': 0.23189048128257908}),\n",
              " (4, 85, {'weight': 0.23189047332830953}),\n",
              " (4, 86, {'weight': 0.23189047332830953}),\n",
              " (4, 87, {'weight': 0.2318904898777683}),\n",
              " (4, 88, {'weight': 0.23189047312395356}),\n",
              " (4, 89, {'weight': 0.23189048665368517}),\n",
              " (4, 90, {'weight': 0.23189047989803743}),\n",
              " (4, 91, {'weight': 0.23189048970525727}),\n",
              " (4, 92, {'weight': 0.23189047989803743}),\n",
              " (4, 93, {'weight': 0.23189048128257908}),\n",
              " (4, 94, {'weight': 0.2318904898777683}),\n",
              " (4, 95, {'weight': 0.23189048134667023}),\n",
              " (4, 96, {'weight': 0.23189046907015606}),\n",
              " (4, 97, {'weight': 0.2318904898777683}),\n",
              " (4, 98, {'weight': 0.23189048134667023}),\n",
              " (4, 99, {'weight': 0.23189047989803743}),\n",
              " (4, 100, {'weight': 0.23189048134667023}),\n",
              " (4, 101, {'weight': 0.23189047930584553}),\n",
              " (4, 102, {'weight': 0.23189052546115507}),\n",
              " (4, 103, {'weight': 0.23189048134667023}),\n",
              " (4, 104, {'weight': 0.23189047416958727}),\n",
              " (4, 105, {'weight': 0.23189047416958727}),\n",
              " (4, 106, {'weight': 0.23189048665368517}),\n",
              " (4, 107, {'weight': 0.23189047312395356}),\n",
              " (4, 108, {'weight': 0.2318904767699621}),\n",
              " (4, 109, {'weight': 0.23189047332830953}),\n",
              " (4, 110, {'weight': 0.2318904527357445}),\n",
              " (4, 111, {'weight': 0.231890450131237}),\n",
              " (4, 112, {'weight': 0.23189045900924846}),\n",
              " (4, 113, {'weight': 0.23189047332830953}),\n",
              " (4, 114, {'weight': 0.23189047989803743}),\n",
              " (4, 115, {'weight': 0.23189048128257908}),\n",
              " (4, 116, {'weight': 0.23189048665368517}),\n",
              " (4, 117, {'weight': 0.2318904725791909}),\n",
              " (4, 118, {'weight': 0.23189048134667023}),\n",
              " (4, 119, {'weight': 0.23189048134667023}),\n",
              " (4, 120, {'weight': 0.23189047930584553}),\n",
              " (4, 121, {'weight': 0.23189048134667023}),\n",
              " (4, 122, {'weight': 0.2318904898777683}),\n",
              " (4, 123, {'weight': 0.2318904725791909}),\n",
              " (4, 124, {'weight': 0.23189048970525727}),\n",
              " (4, 125, {'weight': 0.23189047332830953}),\n",
              " (4, 126, {'weight': 0.23189047312395356}),\n",
              " (4, 127, {'weight': 0.231890450131237}),\n",
              " (4, 128, {'weight': 0.23189045900924846}),\n",
              " (4, 129, {'weight': 0.23189045431515135}),\n",
              " (4, 130, {'weight': 0.23189046674692382}),\n",
              " (4, 131, {'weight': 0.2318905537046515}),\n",
              " (5, 6, {'weight': 0.23189051654286433}),\n",
              " (5, 7, {'weight': 0.2318905116633306}),\n",
              " (5, 8, {'weight': 0.23189050463277328}),\n",
              " (5, 9, {'weight': 0.23189051983140363}),\n",
              " (5, 10, {'weight': 0.2318905048845112}),\n",
              " (5, 11, {'weight': 0.2318905048845112}),\n",
              " (5, 12, {'weight': 0.2318904612896346}),\n",
              " (5, 13, {'weight': 0.23189050606156564}),\n",
              " (5, 14, {'weight': 0.2318904719571552}),\n",
              " (5, 15, {'weight': 0.23189050606156564}),\n",
              " (5, 16, {'weight': 0.2318905123325793}),\n",
              " (5, 17, {'weight': 0.2318905057257889}),\n",
              " (5, 18, {'weight': 0.23189050606156564}),\n",
              " (5, 19, {'weight': 0.23189051965889257}),\n",
              " (5, 20, {'weight': 0.23189049385625152}),\n",
              " (5, 21, {'weight': 0.231890513640064}),\n",
              " (5, 22, {'weight': 0.23189045960562393}),\n",
              " (5, 23, {'weight': 0.2318905086865707}),\n",
              " (5, 24, {'weight': 0.23189051965889257}),\n",
              " (5, 25, {'weight': 0.2318904719571552}),\n",
              " (5, 26, {'weight': 0.23189045354362983}),\n",
              " (5, 27, {'weight': 0.23189051370415525}),\n",
              " (5, 28, {'weight': 0.2318905041353926}),\n",
              " (5, 29, {'weight': 0.2318905048845112}),\n",
              " (5, 30, {'weight': 0.2318905116633306}),\n",
              " (5, 31, {'weight': 0.2318905086865707}),\n",
              " (5, 32, {'weight': 0.231890513640064}),\n",
              " (5, 33, {'weight': 0.23189050463277328}),\n",
              " (5, 34, {'weight': 0.23189051225552249}),\n",
              " (5, 35, {'weight': 0.23189051660732068}),\n",
              " (5, 36, {'weight': 0.23189051654286433}),\n",
              " (5, 37, {'weight': 0.2318905116633306}),\n",
              " (5, 38, {'weight': 0.23189051965889257}),\n",
              " (5, 39, {'weight': 0.2318905041353926}),\n",
              " (5, 40, {'weight': 0.2318904898777683}),\n",
              " (5, 41, {'weight': 0.23189051225552249}),\n",
              " (5, 42, {'weight': 0.23189051983140363}),\n",
              " (5, 43, {'weight': 0.2318904898777683}),\n",
              " (5, 44, {'weight': 0.23189050606156564}),\n",
              " (5, 45, {'weight': 0.23189046861453022}),\n",
              " (5, 46, {'weight': 0.2318905041353926}),\n",
              " (5, 47, {'weight': 0.23189051370415525}),\n",
              " (5, 48, {'weight': 0.23189051965889257}),\n",
              " (5, 49, {'weight': 0.23189051370415525}),\n",
              " (5, 50, {'weight': 0.23189051965889257}),\n",
              " (5, 51, {'weight': 0.23189051225552249}),\n",
              " (5, 52, {'weight': 0.2318905123325793}),\n",
              " (5, 53, {'weight': 0.23189051370415525}),\n",
              " (5, 54, {'weight': 0.2318905116633306}),\n",
              " (5, 55, {'weight': 0.23189051965889257}),\n",
              " (5, 56, {'weight': 0.23189051225552249}),\n",
              " (5, 57, {'weight': 0.23189051660732068}),\n",
              " (5, 58, {'weight': 0.23189051370415525}),\n",
              " (5, 59, {'weight': 0.231890513640064}),\n",
              " (5, 60, {'weight': 0.23189051965889257}),\n",
              " (5, 61, {'weight': 0.2318905123325793}),\n",
              " (5, 62, {'weight': 0.23189051983140363}),\n",
              " (5, 63, {'weight': 0.2318905023095406}),\n",
              " (5, 64, {'weight': 0.23189051660732068}),\n",
              " (5, 65, {'weight': 0.2318905116633306}),\n",
              " (5, 66, {'weight': 0.23189051965889257}),\n",
              " (5, 67, {'weight': 0.23189047500209206}),\n",
              " (5, 68, {'weight': 0.2318905041353926}),\n",
              " (5, 69, {'weight': 0.2318905057257889}),\n",
              " (5, 70, {'weight': 0.2318905057257889}),\n",
              " (5, 71, {'weight': 0.231890513640064}),\n",
              " (5, 72, {'weight': 0.23189051225552249}),\n",
              " (5, 73, {'weight': 0.23189051965889257}),\n",
              " (5, 74, {'weight': 0.23189051660732068}),\n",
              " (5, 75, {'weight': 0.23189051225552249}),\n",
              " (5, 76, {'weight': 0.23189050463277328}),\n",
              " (5, 77, {'weight': 0.2318905023095406}),\n",
              " (5, 78, {'weight': 0.23189051983140363}),\n",
              " (5, 79, {'weight': 0.23189051370415525}),\n",
              " (5, 80, {'weight': 0.2318905086865707}),\n",
              " (5, 81, {'weight': 0.23189050606156564}),\n",
              " (5, 82, {'weight': 0.23189049385625152}),\n",
              " (5, 83, {'weight': 0.23189050606156564}),\n",
              " (5, 84, {'weight': 0.231890513640064}),\n",
              " (5, 85, {'weight': 0.2318905048845112}),\n",
              " (5, 86, {'weight': 0.2318905048845112}),\n",
              " (5, 87, {'weight': 0.23189051983140363}),\n",
              " (5, 88, {'weight': 0.2318905086865707}),\n",
              " (5, 89, {'weight': 0.23189051660732068}),\n",
              " (5, 90, {'weight': 0.23189051225552249}),\n",
              " (5, 91, {'weight': 0.23189051965889257}),\n",
              " (5, 92, {'weight': 0.23189051225552249}),\n",
              " (5, 93, {'weight': 0.231890513640064}),\n",
              " (5, 94, {'weight': 0.23189051983140363}),\n",
              " (5, 95, {'weight': 0.23189051370415525}),\n",
              " (5, 96, {'weight': 0.23189050463277328}),\n",
              " (5, 97, {'weight': 0.23189051983140363}),\n",
              " (5, 98, {'weight': 0.23189051370415525}),\n",
              " (5, 99, {'weight': 0.23189051225552249}),\n",
              " (5, 100, {'weight': 0.23189051370415525}),\n",
              " (5, 101, {'weight': 0.2318905116633306}),\n",
              " (5, 102, {'weight': 0.23189056182505702}),\n",
              " (5, 103, {'weight': 0.23189051370415525}),\n",
              " (5, 104, {'weight': 0.2318905057257889}),\n",
              " (5, 105, {'weight': 0.2318905057257889}),\n",
              " (5, 106, {'weight': 0.23189051660732068}),\n",
              " (5, 107, {'weight': 0.2318905086865707}),\n",
              " (5, 108, {'weight': 0.2318905123325793}),\n",
              " (5, 109, {'weight': 0.2318905048845112}),\n",
              " (5, 110, {'weight': 0.2318904858945122}),\n",
              " (5, 111, {'weight': 0.2318904832900048}),\n",
              " (5, 112, {'weight': 0.23189049457186542}),\n",
              " (5, 113, {'weight': 0.2318905048845112}),\n",
              " (5, 114, {'weight': 0.23189051225552249}),\n",
              " (5, 115, {'weight': 0.231890513640064}),\n",
              " (5, 116, {'weight': 0.23189051660732068}),\n",
              " (5, 117, {'weight': 0.2318905041353926}),\n",
              " (5, 118, {'weight': 0.23189051370415525}),\n",
              " (5, 119, {'weight': 0.23189051370415525}),\n",
              " (5, 120, {'weight': 0.2318905116633306}),\n",
              " (5, 121, {'weight': 0.23189051370415525}),\n",
              " (5, 122, {'weight': 0.23189051983140363}),\n",
              " (5, 123, {'weight': 0.2318905041353926}),\n",
              " (5, 124, {'weight': 0.23189051965889257}),\n",
              " (5, 125, {'weight': 0.2318905048845112}),\n",
              " (5, 126, {'weight': 0.2318905086865707}),\n",
              " (5, 127, {'weight': 0.2318904832900048}),\n",
              " (5, 128, {'weight': 0.23189049457186542}),\n",
              " (5, 129, {'weight': 0.2318904898777683}),\n",
              " (5, 130, {'weight': 0.2318905023095406}),\n",
              " (5, 131, {'weight': 0.23189058846598665}),\n",
              " (6, 7, {'weight': 0.23189050597094146}),\n",
              " (6, 8, {'weight': 0.23189049974166742}),\n",
              " (6, 9, {'weight': 0.23189051654286433}),\n",
              " (6, 10, {'weight': 0.23189050159597174}),\n",
              " (6, 11, {'weight': 0.23189050159597174}),\n",
              " (6, 12, {'weight': 0.23189045719981194}),\n",
              " (6, 13, {'weight': 0.23189050197174296}),\n",
              " (6, 14, {'weight': 0.23189046866861548}),\n",
              " (6, 15, {'weight': 0.23189050197174296}),\n",
              " (6, 16, {'weight': 0.23189050904403985}),\n",
              " (6, 17, {'weight': 0.23189050243724948}),\n",
              " (6, 18, {'weight': 0.23189050197174296}),\n",
              " (6, 19, {'weight': 0.23189051637035324}),\n",
              " (6, 20, {'weight': 0.2318904881638626}),\n",
              " (6, 21, {'weight': 0.23189050955024135}),\n",
              " (6, 22, {'weight': 0.23189045631708388}),\n",
              " (6, 23, {'weight': 0.23189050539803124}),\n",
              " (6, 24, {'weight': 0.23189051637035324}),\n",
              " (6, 25, {'weight': 0.23189046866861548}),\n",
              " (6, 26, {'weight': 0.23189044845220347}),\n",
              " (6, 27, {'weight': 0.23189050861272853}),\n",
              " (6, 28, {'weight': 0.23189050084685314}),\n",
              " (6, 29, {'weight': 0.23189050159597174}),\n",
              " (6, 30, {'weight': 0.23189050597094146}),\n",
              " (6, 31, {'weight': 0.23189050539803124}),\n",
              " (6, 32, {'weight': 0.23189050955024135}),\n",
              " (6, 33, {'weight': 0.23189049974166742}),\n",
              " (6, 34, {'weight': 0.23189050656313331}),\n",
              " (6, 35, {'weight': 0.2318905133187813}),\n",
              " (6, 36, {'weight': 0.2318905130540041}),\n",
              " (6, 37, {'weight': 0.23189050597094146}),\n",
              " (6, 38, {'weight': 0.23189051637035324}),\n",
              " (6, 39, {'weight': 0.23189050084685314}),\n",
              " (6, 40, {'weight': 0.2318904841853794}),\n",
              " (6, 41, {'weight': 0.23189050656313331}),\n",
              " (6, 42, {'weight': 0.23189051654286433}),\n",
              " (6, 43, {'weight': 0.2318904841853794}),\n",
              " (6, 44, {'weight': 0.23189050197174296}),\n",
              " (6, 45, {'weight': 0.23189046532599053}),\n",
              " (6, 46, {'weight': 0.23189050084685314}),\n",
              " (6, 47, {'weight': 0.23189050861272853}),\n",
              " (6, 48, {'weight': 0.23189051637035324}),\n",
              " (6, 49, {'weight': 0.23189050861272853}),\n",
              " (6, 50, {'weight': 0.23189051637035324}),\n",
              " (6, 51, {'weight': 0.23189050656313331}),\n",
              " (6, 52, {'weight': 0.23189050904403985}),\n",
              " (6, 53, {'weight': 0.23189050861272853}),\n",
              " (6, 54, {'weight': 0.23189050597094146}),\n",
              " (6, 55, {'weight': 0.23189051637035324}),\n",
              " (6, 56, {'weight': 0.23189050656313331}),\n",
              " (6, 57, {'weight': 0.2318905133187813}),\n",
              " (6, 58, {'weight': 0.23189050861272853}),\n",
              " (6, 59, {'weight': 0.23189050955024135}),\n",
              " (6, 60, {'weight': 0.23189051637035324}),\n",
              " (6, 61, {'weight': 0.23189050904403985}),\n",
              " (6, 62, {'weight': 0.23189051654286433}),\n",
              " (6, 63, {'weight': 0.23189049902100112}),\n",
              " (6, 64, {'weight': 0.2318905133187813}),\n",
              " (6, 65, {'weight': 0.23189050597094146}),\n",
              " (6, 66, {'weight': 0.23189051637035324}),\n",
              " (6, 67, {'weight': 0.23189047171355218}),\n",
              " (6, 68, {'weight': 0.23189050084685314}),\n",
              " (6, 69, {'weight': 0.23189050243724948}),\n",
              " (6, 70, {'weight': 0.23189050243724948}),\n",
              " (6, 71, {'weight': 0.23189050955024135}),\n",
              " (6, 72, {'weight': 0.23189050656313331}),\n",
              " (6, 73, {'weight': 0.23189051637035324}),\n",
              " (6, 74, {'weight': 0.2318905133187813}),\n",
              " (6, 75, {'weight': 0.23189050656313331}),\n",
              " (6, 76, {'weight': 0.23189049974166742}),\n",
              " (6, 77, {'weight': 0.23189049902100112}),\n",
              " (6, 78, {'weight': 0.23189051654286433}),\n",
              " (6, 79, {'weight': 0.23189050861272853}),\n",
              " (6, 80, {'weight': 0.23189050539803124}),\n",
              " (6, 81, {'weight': 0.23189050197174296}),\n",
              " (6, 82, {'weight': 0.2318904881638626}),\n",
              " (6, 83, {'weight': 0.23189050197174296}),\n",
              " (6, 84, {'weight': 0.23189050955024135}),\n",
              " (6, 85, {'weight': 0.23189050159597174}),\n",
              " (6, 86, {'weight': 0.23189050159597174}),\n",
              " (6, 87, {'weight': 0.23189051654286433}),\n",
              " (6, 88, {'weight': 0.23189050539803124}),\n",
              " (6, 89, {'weight': 0.2318905133187813}),\n",
              " (6, 90, {'weight': 0.23189050656313331}),\n",
              " (6, 91, {'weight': 0.23189051637035324}),\n",
              " (6, 92, {'weight': 0.23189050656313331}),\n",
              " (6, 93, {'weight': 0.23189050955024135}),\n",
              " (6, 94, {'weight': 0.23189051654286433}),\n",
              " (6, 95, {'weight': 0.23189050861272853}),\n",
              " (6, 96, {'weight': 0.23189049974166742}),\n",
              " (6, 97, {'weight': 0.23189051654286433}),\n",
              " (6, 98, {'weight': 0.23189050861272853}),\n",
              " (6, 99, {'weight': 0.23189050656313331}),\n",
              " (6, 100, {'weight': 0.23189050861272853}),\n",
              " (6, 101, {'weight': 0.23189050597094146}),\n",
              " (6, 102, {'weight': 0.23189055853651797}),\n",
              " (6, 103, {'weight': 0.23189050861272853}),\n",
              " (6, 104, {'weight': 0.23189050243724948}),\n",
              " (6, 105, {'weight': 0.23189050243724948}),\n",
              " (6, 106, {'weight': 0.2318905133187813}),\n",
              " (6, 107, {'weight': 0.23189050539803124}),\n",
              " (6, 108, {'weight': 0.23189050904403985}),\n",
              " (6, 109, {'weight': 0.23189050159597174}),\n",
              " (6, 110, {'weight': 0.2318904826059726}),\n",
              " (6, 111, {'weight': 0.23189047679633298}),\n",
              " (6, 112, {'weight': 0.23189048887947641}),\n",
              " (6, 113, {'weight': 0.23189050159597174}),\n",
              " (6, 114, {'weight': 0.23189050656313331}),\n",
              " (6, 115, {'weight': 0.23189050955024135}),\n",
              " (6, 116, {'weight': 0.2318905133187813}),\n",
              " (6, 117, {'weight': 0.23189050084685314}),\n",
              " (6, 118, {'weight': 0.23189050861272853}),\n",
              " (6, 119, {'weight': 0.23189050861272853}),\n",
              " (6, 120, {'weight': 0.23189050597094146}),\n",
              " (6, 121, {'weight': 0.23189050861272853}),\n",
              " (6, 122, {'weight': 0.23189051654286433}),\n",
              " (6, 123, {'weight': 0.23189050084685314}),\n",
              " (6, 124, {'weight': 0.23189051637035324}),\n",
              " (6, 125, {'weight': 0.23189050159597174}),\n",
              " (6, 126, {'weight': 0.23189050539803124}),\n",
              " (6, 127, {'weight': 0.23189047679633298}),\n",
              " (6, 128, {'weight': 0.23189048887947641}),\n",
              " (6, 129, {'weight': 0.2318904841853794}),\n",
              " (6, 130, {'weight': 0.23189049902100112}),\n",
              " (6, 131, {'weight': 0.23189058177199187}),\n",
              " (7, 8, {'weight': 0.23189049426117125}),\n",
              " (7, 9, {'weight': 0.2318905116633306}),\n",
              " (7, 10, {'weight': 0.23189049511387166}),\n",
              " (7, 11, {'weight': 0.23189049511387166}),\n",
              " (7, 12, {'weight': 0.23189045171931594}),\n",
              " (7, 13, {'weight': 0.2318904954896429}),\n",
              " (7, 14, {'weight': 0.2318904623868365}),\n",
              " (7, 15, {'weight': 0.2318904954896429}),\n",
              " (7, 16, {'weight': 0.23189050256193966}),\n",
              " (7, 17, {'weight': 0.23189049675643256}),\n",
              " (7, 18, {'weight': 0.2318904954896429}),\n",
              " (7, 19, {'weight': 0.23189051169114036}),\n",
              " (7, 20, {'weight': 0.2318904832843288}),\n",
              " (7, 21, {'weight': 0.231890503268462}),\n",
              " (7, 22, {'weight': 0.2318904506362669}),\n",
              " (7, 23, {'weight': 0.2318904983149687}),\n",
              " (7, 24, {'weight': 0.23189051169114036}),\n",
              " (7, 25, {'weight': 0.2318904623868365}),\n",
              " (7, 26, {'weight': 0.23189044377299006}),\n",
              " (7, 27, {'weight': 0.23189050313223245}),\n",
              " (7, 28, {'weight': 0.23189049436475304}),\n",
              " (7, 29, {'weight': 0.23189049511387166}),\n",
              " (7, 30, {'weight': 0.23189050129172856}),\n",
              " (7, 31, {'weight': 0.2318904983149687}),\n",
              " (7, 32, {'weight': 0.231890503268462}),\n",
              " (7, 33, {'weight': 0.23189049426117125}),\n",
              " (7, 34, {'weight': 0.23189050188392044}),\n",
              " (7, 35, {'weight': 0.2318905084392476}),\n",
              " (7, 36, {'weight': 0.23189050597094146}),\n",
              " (7, 37, {'weight': 0.23189050129172856}),\n",
              " (7, 38, {'weight': 0.23189051169114036}),\n",
              " (7, 39, {'weight': 0.23189049436475304}),\n",
              " (7, 40, {'weight': 0.23189047930584553}),\n",
              " (7, 41, {'weight': 0.23189050188392044}),\n",
              " (7, 42, {'weight': 0.2318905116633306}),\n",
              " (7, 43, {'weight': 0.23189047930584553}),\n",
              " (7, 44, {'weight': 0.2318904954896429}),\n",
              " (7, 45, {'weight': 0.23189045964517377}),\n",
              " (7, 46, {'weight': 0.23189049436475304}),\n",
              " (7, 47, {'weight': 0.23189050313223245}),\n",
              " (7, 48, {'weight': 0.23189051169114036}),\n",
              " (7, 49, {'weight': 0.23189050313223245}),\n",
              " (7, 50, {'weight': 0.23189051169114036}),\n",
              " (7, 51, {'weight': 0.23189050188392044}),\n",
              " (7, 52, {'weight': 0.23189050256193966}),\n",
              " (7, 53, {'weight': 0.23189050313223245}),\n",
              " (7, 54, {'weight': 0.23189050129172856}),\n",
              " (7, 55, {'weight': 0.23189051169114036}),\n",
              " (7, 56, {'weight': 0.23189050188392044}),\n",
              " (7, 57, {'weight': 0.2318905084392476}),\n",
              " (7, 58, {'weight': 0.23189050313223245}),\n",
              " (7, 59, {'weight': 0.231890503268462}),\n",
              " (7, 60, {'weight': 0.23189051169114036}),\n",
              " (7, 61, {'weight': 0.23189050256193966}),\n",
              " (7, 62, {'weight': 0.2318905116633306}),\n",
              " (7, 63, {'weight': 0.23189049273922183}),\n",
              " (7, 64, {'weight': 0.2318905084392476}),\n",
              " (7, 65, {'weight': 0.23189050129172856}),\n",
              " (7, 66, {'weight': 0.23189051169114036}),\n",
              " (7, 67, {'weight': 0.23189046683401812}),\n",
              " (7, 68, {'weight': 0.23189049436475304}),\n",
              " (7, 69, {'weight': 0.23189049675643256}),\n",
              " (7, 70, {'weight': 0.23189049675643256}),\n",
              " (7, 71, {'weight': 0.231890503268462}),\n",
              " (7, 72, {'weight': 0.23189050188392044}),\n",
              " (7, 73, {'weight': 0.23189051169114036}),\n",
              " (7, 74, {'weight': 0.2318905084392476}),\n",
              " (7, 75, {'weight': 0.23189050188392044}),\n",
              " (7, 76, {'weight': 0.23189049426117125}),\n",
              " (7, 77, {'weight': 0.23189049273922183}),\n",
              " (7, 78, {'weight': 0.2318905116633306}),\n",
              " (7, 79, {'weight': 0.23189050313223245}),\n",
              " (7, 80, {'weight': 0.2318904983149687}),\n",
              " (7, 81, {'weight': 0.2318904954896429}),\n",
              " (7, 82, {'weight': 0.2318904832843288}),\n",
              " (7, 83, {'weight': 0.2318904954896429}),\n",
              " (7, 84, {'weight': 0.231890503268462}),\n",
              " (7, 85, {'weight': 0.23189049511387166}),\n",
              " (7, 86, {'weight': 0.23189049511387166}),\n",
              " (7, 87, {'weight': 0.2318905116633306}),\n",
              " (7, 88, {'weight': 0.2318904983149687}),\n",
              " (7, 89, {'weight': 0.2318905084392476}),\n",
              " (7, 90, {'weight': 0.23189050188392044}),\n",
              " (7, 91, {'weight': 0.23189051169114036}),\n",
              " (7, 92, {'weight': 0.23189050188392044}),\n",
              " (7, 93, {'weight': 0.231890503268462}),\n",
              " (7, 94, {'weight': 0.2318905116633306}),\n",
              " (7, 95, {'weight': 0.23189050313223245}),\n",
              " (7, 96, {'weight': 0.23189049426117125}),\n",
              " (7, 97, {'weight': 0.2318905116633306}),\n",
              " (7, 98, {'weight': 0.23189050313223245}),\n",
              " (7, 99, {'weight': 0.23189050188392044}),\n",
              " (7, 100, {'weight': 0.23189050313223245}),\n",
              " (7, 101, {'weight': 0.23189050129172856}),\n",
              " (7, 102, {'weight': 0.23189055385730523}),\n",
              " (7, 103, {'weight': 0.23189050313223245}),\n",
              " (7, 104, {'weight': 0.23189049675643256}),\n",
              " (7, 105, {'weight': 0.23189049675643256}),\n",
              " (7, 106, {'weight': 0.2318905084392476}),\n",
              " (7, 107, {'weight': 0.2318904983149687}),\n",
              " (7, 108, {'weight': 0.23189050256193966}),\n",
              " (7, 109, {'weight': 0.23189049511387166}),\n",
              " (7, 110, {'weight': 0.2318904777264387}),\n",
              " (7, 111, {'weight': 0.23189047191679923}),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXkqltM6ow-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding the score of each sentence and storing it in a dictionary. the score is the mean of the edge values for each sentence with every other sentence.\n",
        "scores1={}\n",
        "k=0\n",
        "while(k<len(cor)):\n",
        "  sum=0\n",
        "  for i in edge:\n",
        "    if i[0] == k:\n",
        "      sum+=i[2]['weight']\n",
        "    elif i[1] == k:\n",
        "      sum+=i[2]['weight']\n",
        "  sum=sum/len(cor)\n",
        "  scores1[k]=sum \n",
        "  k+=1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iLyFLfCuHzt",
        "colab_type": "code",
        "outputId": "8851cfbc-b765-45bb-e81c-6624ad0e72f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "scores1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.23013373501068285,\n",
              " 1: 0.23013374647045537,\n",
              " 2: 0.23013376209717185,\n",
              " 3: 0.2301337477239893,\n",
              " 4: 0.23013373000072523,\n",
              " 5: 0.23013376199542174,\n",
              " 6: 0.23013375787651108,\n",
              " 7: 0.23013375242593756,\n",
              " 8: 0.23013374484630839,\n",
              " 9: 0.23013376199542174,\n",
              " 10: 0.23013374720822374,\n",
              " 11: 0.23013374720822374,\n",
              " 12: 0.23013370502204278,\n",
              " 13: 0.2301337477239893,\n",
              " 14: 0.23013371557042667,\n",
              " 15: 0.2301337477239893,\n",
              " 16: 0.23013375343864292,\n",
              " 17: 0.23013374829170852,\n",
              " 18: 0.2301337477239893,\n",
              " 19: 0.23013376209717185,\n",
              " 20: 0.23013373413138938,\n",
              " 21: 0.2301337549372611,\n",
              " 22: 0.23013370043006298,\n",
              " 23: 0.23013374931217023,\n",
              " 24: 0.23013376209717185,\n",
              " 25: 0.23013371557042667,\n",
              " 26: 0.2301336954220636,\n",
              " 27: 0.2301337546528548,\n",
              " 28: 0.23013374647045537,\n",
              " 29: 0.23013374720822374,\n",
              " 30: 0.23013375242593756,\n",
              " 31: 0.23013374931217023,\n",
              " 32: 0.2301337549372611,\n",
              " 33: 0.23013374484630839,\n",
              " 34: 0.23013375310021184,\n",
              " 35: 0.23013375810996023,\n",
              " 36: 0.23013375787651105,\n",
              " 37: 0.23013375242593756,\n",
              " 38: 0.23013376209717185,\n",
              " 39: 0.23013374647045537,\n",
              " 40: 0.2301337300007252,\n",
              " 41: 0.23013375310021184,\n",
              " 42: 0.23013376199542174,\n",
              " 43: 0.2301337300007252,\n",
              " 44: 0.2301337477239893,\n",
              " 45: 0.23013371243475847,\n",
              " 46: 0.23013374647045537,\n",
              " 47: 0.23013375465285482,\n",
              " 48: 0.23013376209717185,\n",
              " 49: 0.23013375465285482,\n",
              " 50: 0.23013376209717185,\n",
              " 51: 0.23013375310021184,\n",
              " 52: 0.23013375343864292,\n",
              " 53: 0.23013375465285482,\n",
              " 54: 0.23013375242593756,\n",
              " 55: 0.23013376209717185,\n",
              " 56: 0.23013375310021184,\n",
              " 57: 0.23013375810996023,\n",
              " 58: 0.23013375465285482,\n",
              " 59: 0.2301337549372611,\n",
              " 60: 0.23013376209717185,\n",
              " 61: 0.23013375343864292,\n",
              " 62: 0.23013376199542174,\n",
              " 63: 0.23013374411228013,\n",
              " 64: 0.23013375810996023,\n",
              " 65: 0.23013375242593756,\n",
              " 66: 0.23013376209717185,\n",
              " 67: 0.23013371590890805,\n",
              " 68: 0.23013374647045537,\n",
              " 69: 0.23013374829170852,\n",
              " 70: 0.23013374829170852,\n",
              " 71: 0.2301337549372611,\n",
              " 72: 0.23013375310021184,\n",
              " 73: 0.23013376209717182,\n",
              " 74: 0.23013375810996023,\n",
              " 75: 0.23013375310021184,\n",
              " 76: 0.23013374484630839,\n",
              " 77: 0.2301337441122801,\n",
              " 78: 0.23013376199542174,\n",
              " 79: 0.23013375465285482,\n",
              " 80: 0.2301337493121702,\n",
              " 81: 0.23013374772398934,\n",
              " 82: 0.23013373413138935,\n",
              " 83: 0.23013374772398934,\n",
              " 84: 0.2301337549372611,\n",
              " 85: 0.23013374720822372,\n",
              " 86: 0.23013374720822372,\n",
              " 87: 0.23013376199542174,\n",
              " 88: 0.2301337493121702,\n",
              " 89: 0.23013375810996023,\n",
              " 90: 0.23013375310021184,\n",
              " 91: 0.23013376209717182,\n",
              " 92: 0.23013375310021184,\n",
              " 93: 0.2301337549372611,\n",
              " 94: 0.23013376199542174,\n",
              " 95: 0.23013375465285482,\n",
              " 96: 0.23013374484630839,\n",
              " 97: 0.23013376199542174,\n",
              " 98: 0.23013375465285482,\n",
              " 99: 0.23013375310021184,\n",
              " 100: 0.23013375465285482,\n",
              " 101: 0.23013375242593753,\n",
              " 102: 0.23013380172444206,\n",
              " 103: 0.23013375465285482,\n",
              " 104: 0.23013374829170852,\n",
              " 105: 0.23013374829170852,\n",
              " 106: 0.23013375810996023,\n",
              " 107: 0.2301337493121702,\n",
              " 108: 0.23013375343864292,\n",
              " 109: 0.23013374720822372,\n",
              " 110: 0.2301337292586721,\n",
              " 111: 0.23013372487252912,\n",
              " 112: 0.23013373501068285,\n",
              " 113: 0.23013374720822372,\n",
              " 114: 0.23013375310021184,\n",
              " 115: 0.2301337549372611,\n",
              " 116: 0.23013375810996023,\n",
              " 117: 0.23013374647045537,\n",
              " 118: 0.23013375465285482,\n",
              " 119: 0.23013375465285482,\n",
              " 120: 0.23013375242593753,\n",
              " 121: 0.23013375465285482,\n",
              " 122: 0.23013376199542174,\n",
              " 123: 0.23013374647045537,\n",
              " 124: 0.23013376209717182,\n",
              " 125: 0.23013374720822372,\n",
              " 126: 0.2301337493121702,\n",
              " 127: 0.23013372487252912,\n",
              " 128: 0.23013373501068285,\n",
              " 129: 0.2301337300007252,\n",
              " 130: 0.2301337441122801,\n",
              " 131: 0.23013382742904953}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cgCubk3o3Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ranked_sentences = sorted(((scores1[i],s) for i,s in enumerate(cor)), reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYxXTvf6vHmO",
        "colab_type": "code",
        "outputId": "8617405c-337e-4c6e-c888-3dbae412f2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ranked_sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.32465956564658704, '10 AI policy, now and'),\n",
              " (0.32465952064885595, 'Whats next for AI research?'),\n",
              " (0.3246594612461253,\n",
              "  'While impressive, these technologies are highly tailored to particular tasks.'),\n",
              " (0.3246594612461253,\n",
              "  'AI is also changing how people interact with technology.'),\n",
              " (0.32465946045194916,\n",
              "  'Great strides have also been made in machine translation among different languages, with more real-time person-to-person exchanges on the near horizon.'),\n",
              " (0.3246594604519491,\n",
              "  'Peoples future relationships with machines will become ever more nuanced, fluid, and personalized as AI systems learn to adapt to individual personalities and goals.'),\n",
              " (0.3246594604519491,\n",
              "  'Once a mostly academic area of study, twenty-first century AI enables a constellation of mainstream technologies that are having a substantial impact on everyday lives.'),\n",
              " (0.3246594604519491,\n",
              "  'On the other hand, if society approaches AI with a more open mind, the technologies emerging from the field could profoundly transform society for the better in the coming decades.'),\n",
              " (0.3246594604519491,\n",
              "  'Instead, increasingly useful applications of AI, with potentially profound positive impacts on our society and economy are likely to emerge between now and 2030, the period this report considers.'),\n",
              " (0.3246594604519491,\n",
              "  'In each domain, even as AI continues to deliver important benefits, it also raises important ethical and social issues, including privacy concerns.'),\n",
              " (0.3246594604519491,\n",
              "  'However, in many realms, AI will likely replace tasks rather than jobs in the near term, and will also create new kinds of jobs.'),\n",
              " (0.3246594604519491,\n",
              "  'Enabling more fluid interactions between people and promising AI technologies also remains a critical challenge in Education, which has seen considerable progress in the same period.'),\n",
              " (0.3246594604519491,\n",
              "  'But technical constraints and the high costs of reliable mechanical devices will continue to limit commercial opportunities to narrowly defined applications for the foreseeable future.'),\n",
              " (0.3246594604519491,\n",
              "  'Autonomous transportation will soon be commonplace and, as most peoples first experience with physically embodied AI systems, will strongly influence the publics perception of AI.'),\n",
              " (0.3246594604519491,\n",
              "  'As a society, we are now at a crucial juncture in determining how to deploy AI-based technologies in ways that promote, not hinder, democratic values such as freedom, equality, and transparency.'),\n",
              " (0.3246594604519491,\n",
              "  '7 An accurate and sophisticated picture of AIone that competes with its popular portrayalis hampered at the start by the difficulty of pinning down a precise definition of artificial intelligence.'),\n",
              " (0.3246594604426896,\n",
              "  'This studys focus on a typical North American city is deliberate and meant to highlight specific changes affecting the everyday lives of the millions of people who inhabit them.'),\n",
              " (0.3246594604426896,\n",
              "  'The latter raises the specter of innocent people being unjustifiably monitored, and care must be taken to avoid systematizing human bias and to protect civil liberties.'),\n",
              " (0.3246594604426896,\n",
              "  'Some traditional sources of entertainment have also embraced AI to compose music, create stage performances, and even to generate 3D scenes from natural language text.'),\n",
              " (0.3246594604426896,\n",
              "  'Natural Language Processing, often coupled with automatic speech recognition, is quickly becoming a commodity for widely spoken languages with large data sets.'),\n",
              " (0.3246594604426896,\n",
              "  'Longer term, AI may be thought of as a radically different mechanism for wealth creation in which everyone should be entitled to a portion of the worlds AI-produced treasures.'),\n",
              " (0.3246594604426896,\n",
              "  'In the typical North American city in 2030, physically embodied AI applications will not be limited to cars, but are likely to include trucks, flying vehicles, and personal robots.'),\n",
              " (0.3246594604426896,\n",
              "  'Beyond education, many opportunities exist for AI methods to assist Low-resource Communities by providing mitigations and solutions to a variety of social problems.'),\n",
              " (0.32465946044268956,\n",
              "  'Natural Language Processing (NLP) and knowledge representation and reasoning have enabled a machine to beat the Jeopardy champion and are bringing new power to Web searches.'),\n",
              " (0.32465946044268956,\n",
              "  'AI and robotics will also be applied across the globe in industries struggling to attract younger workers, such as agriculture, food processing, fulfillment centers, and factories.'),\n",
              " (0.3246594601703908,\n",
              "  'It has been the sub-area of AI most transformed by the rise of deep learning.'),\n",
              " (0.3246594601703908,\n",
              "  'Computer vision is currently the most prominent form of machine perception.'),\n",
              " (0.3246594601703908,\n",
              "  'AI will increasingly enable entertainment that is more interactive, personalized, and engaging.'),\n",
              " (0.32465946017039077,\n",
              "  'As a result, progress is uneven within and among the eight domains.'),\n",
              " (0.32465945481201997,\n",
              "  'Traditionally, funders have underinvested in AI research lacking commercial application.'),\n",
              " (0.32465945481201997,\n",
              "  'The research that fuels the AI revolution has also seen rapid changes.'),\n",
              " (0.32465945481201997,\n",
              "  'The enthusiasm with which people have already responded to AI-driven entertainment has been surprising.'),\n",
              " (0.32465945481201997,\n",
              "  'Robots and other AI technologies have already begun to displace jobs in some sectors.'),\n",
              " (0.32465945481201997,\n",
              "  'Much current research is focused on automatic image and video captioning.'),\n",
              " (0.32465945481201997,\n",
              "  'Many have already grown accustomed to touching and talking to their smart phones.'),\n",
              " (0.32465945481201997,\n",
              "  'It is not too soon for social debate on how the economic fruits of AI technologies should be shared.'),\n",
              " (0.3246594548120199,\n",
              "  'Some cut across sectors, such as employment/workplace and low-resource communities.'),\n",
              " (0.3246594548120199,\n",
              "  'Each application requires years of focused research and a careful, unique construction.'),\n",
              " (0.3246594544656324,\n",
              "  'Gaining public trust is also a challenge for AI use by Public Safety and Security professionals.'),\n",
              " (0.3246594544656324,\n",
              "  'AI will also lower the cost of many goods and services, effectively making everyone better off.'),\n",
              " (0.32465945446563227,\n",
              "  'While largely confined to academia over the past several decades, it is now seeing some practical, real-world successes.'),\n",
              " (0.32465945446563227,\n",
              "  'In fact, beneficial AI applications in schools, homes, and hospitals are already growing at an accelerated pace.'),\n",
              " (0.32465945446563227,\n",
              "  'For many applications, AI systems will have to work closely with care providers and patients to gain their trust.'),\n",
              " (0.32465945446563227,\n",
              "  'A prime example is Transportation, where a few key technologies have catalyzed the widespread adoption of AI with astonishing speed.'),\n",
              " (0.32465945446563227,\n",
              "  '5 how human labor is augmented or replaced by AI, creating new challenges for the economy and society more broadly.'),\n",
              " (0.32465945369570526,\n",
              "  'This alone will reconfigure the urban landscape, as traffic jams and parking challenges become obsolete.'),\n",
              " (0.32465945369570526,\n",
              "  'It promises to carry AI applications forward toward taking actions in the real world.'),\n",
              " (0.32465945369570526,\n",
              "  'Even Hollywood uses AI technologies to bring its dystopian AI fantasies to the screen.'),\n",
              " (0.32465945369570526,\n",
              "  'As with many aspects of AI, there is ongoing debate about the extent to which the technology replaces or enhances sociability.'),\n",
              " (0.3246594536957052,\n",
              "  'Interactive machine tutors are now being matched to students for teaching science, math, language, and other disciplines.'),\n",
              " (0.3246594536957052,\n",
              "  'In the approaches the Study Panel considered, none suggest there is currently a general purpose AI.'),\n",
              " (0.3246594536957052,\n",
              "  'For individuals, the quality of the lives we lead and how our contributions are valued are likely to shift gradually, but markedly.'),\n",
              " (0.3246594536957052,\n",
              "  'But the new jobs that will emerge are harder to imagine in advance than the existing jobs that will likely be lost.'),\n",
              " (0.3246594536957052,\n",
              "  'Advances in how intelligent machines interact naturally with caregivers, patients, and patients families are crucial.'),\n",
              " (0.3246594536957052,\n",
              "  'AI is poised to replace people in certain kinds of jobs, such as in the driving of taxis and trucks.'),\n",
              " (0.32465944929868196,\n",
              "  'Though drawing from a common source of research, AI technologies have influenced and will continue to influence these domains differently.'),\n",
              " (0.32465944929868196,\n",
              "  'These budding efforts suggest more could be done, particularly if agencies and organizations can engage and build trust with these communities.'),\n",
              " (0.32465944929868196,\n",
              "  'The report begins with a reflection on what constitutes Artificial Intelligence, and concludes with recommendations concerning AI-related policy.'),\n",
              " (0.32465944929868196,\n",
              "  'No machines with self-sustaining long-term goals and intent have been developed, nor are they likely to be developed in the near future.'),\n",
              " (0.32465944929868196,\n",
              "  'In each of these domains, the report both reflects on progress in the past fifteen years and anticipates developments in the coming fifteen years.'),\n",
              " (0.32465944929868196,\n",
              "  'Computer vision and AI planning, for example, drive the video games that are now a bigger entertainment industry than Hollywood.'),\n",
              " (0.32465944929868196,\n",
              "  '8 AI technologies could help address the needs of low-resource communities, and budding efforts are promising.'),\n",
              " (0.32465944927655177,\n",
              "  'Reinforcement learning is a framework that shifts the focus of machine learning from pattern recognition to experience-driven sequential decision-making.'),\n",
              " (0.32465944927655177,\n",
              "  'Collaborative systems research investigates models and algorithms to help develop autonomous systems that can work collaboratively with other systems and with humans.'),\n",
              " (0.32465944927655177,\n",
              "  '9 markets for data-driven products, and the economic incentives to find new products and markets, have also stimulated research advances.'),\n",
              " (0.3246594492765517,\n",
              "  'This report is the first in a series to be issued at regular intervals as a part of the One Hundred Year Study on Artificial Intelligence (AI100).'),\n",
              " (0.3246594492765517,\n",
              "  'They will facilitate delivery of online purchases through flying drones, self-driving trucks, or robots that can get up the stairs to the front door.'),\n",
              " (0.3246594492765517,\n",
              "  'North American cities and federal agencies have already begun to deploy AI technologies in border administration and law enforcement.'),\n",
              " (0.3246594492765517,\n",
              "  'In reality, AI is already changing our daily lives, almost entirely in ways that improve human health, safety, and productivity.'),\n",
              " (0.3246594492765517,\n",
              "  'By 2030, they will rely heavily upon them, including improved cameras and drones for surveillance, algorithms to detect financial fraud, and predictive policing.'),\n",
              " (0.3246594492617177,\n",
              "  'Though clinical applications have been slow to move from the computer science lab to the real-world, there are hopeful signs that the pace of innovation will improve.'),\n",
              " (0.3246594492617177,\n",
              "  'Other factors include the rise of cloud computing resources and consumer demand for widespread access to services such as speech recognition and navigation support.'),\n",
              " (0.3246594492617177,\n",
              "  'Foremost among them is the maturation of machine learning, stimulated in part by the rise of the digital economy, which both provides and leverages large amounts of data.'),\n",
              " (0.3246594492617177,\n",
              "  'Contrary to the more fantastic predictions for AI in the popular press, the Study Panel found no cause for concern that AI is an imminent threat to humankind.'),\n",
              " (0.3246594492617177,\n",
              "  'Advances in healthcare can be promoted via the development of incentives and mechanisms for sharing data and for removing overbearing policy, regulatory, and commercial obstacles.'),\n",
              " (0.32465944899478416,\n",
              "  'While the rate of progress in AI has been patchy and unpredictable, there have been significant advances since the fields inception sixty years ago.'),\n",
              " (0.32465944899478416,\n",
              "  'These AI applications will help monitor peoples well-being, alert them to risks ahead, and deliver services when needed or wanted.'),\n",
              " (0.32465944899478416,\n",
              "  'Some domains are primarily business sectors, such as transportation and healthcare, while others are more oriented to consumers, such as entertainment and home service robots.'),\n",
              " (0.32465944899478416,\n",
              "  'Research is now shifting to develop refined and capable systems that are able to interact with people through dialog, not just react to stylized requests.'),\n",
              " (0.32465944899478416,\n",
              "  'Advances in robotics will rely on commensurate advances to improve the reliability and generality of computer vision and other forms of machine perception.'),\n",
              " (0.32465944899478416,\n",
              "  'AI-based applications could improve health outcomes and the quality of life for millions of people in the coming years.'),\n",
              " (0.32465944899478416,\n",
              "  '6 OVERVIEW The frightening, futurist portrayals of Artificial Intelligence that dominate films and novels, and shape the popular imagination, are fictional.'),\n",
              " (0.3246594487962813,\n",
              "  'Unlike in the movies, there is no race of superhuman robots on the horizon or probably even possible.'),\n",
              " (0.3246594487962813,\n",
              "  'Research should be directed toward understanding how to leverage these attributes for individuals and societys benefit.'),\n",
              " (0.3246594487962813,\n",
              "  'Many people have already grown accustomed to touching and talking to their smart phones.'),\n",
              " (0.3246594487962813,\n",
              "  'For the first time, computers are able to perform some vision tasks better than people.'),\n",
              " (0.3246594487962812,\n",
              "  'Special purpose robots will deliver packages, clean offices, and enhance security.'),\n",
              " (0.3246594487962812,\n",
              "  'Peoples future relationships with machines will become ever more nuanced, fluid, and personalized.'),\n",
              " (0.3246594487962812,\n",
              "  'Each application typically requires years of specialized research and careful, unique construction.'),\n",
              " (0.3246594374000056,\n",
              "  'While drawing on common research and technologies, AI systems are specialized to accomplish particular tasks, and each application requires years of focused research and a careful, unique construction.'),\n",
              " (0.3246594374000056,\n",
              "  'Though quality education will always require active engagement by human teachers, AI promises to enhance education at all levels, especially by providing personalization at scale.'),\n",
              " (0.3246594374000056,\n",
              "  'These recommendations include accruing technical expertise about AI in government and devoting more resourcesand removing impedimentsto research on the fairness, security, privacy, and societal impacts of AI systems.'),\n",
              " (0.3246594374000056,\n",
              "  'Social and political decisions are likewise at play in AIs influences on Employment and Workplace trends, such as the safety nets needed to protect people from structural changes in the economy.'),\n",
              " (0.3246594374000056,\n",
              "  'Robotics is currently concerned with how to train a robot to interact with the world around it in generalizable and predictable ways, how to facilitate manipulation of objects in interactive environments, and how to interact with people.'),\n",
              " (0.3246594374000056,\n",
              "  'Over the next several years, AI research, systems development, and social and regulatory frameworks will shape how the benefits of AI are weighed against its costs and risks, and how broadly these benefits are spread.'),\n",
              " (0.3246594374000056,\n",
              "  'New platforms and Longer term, AI may be thought of as a radically different mechanism for wealth creation in which everyone should be entitled to a portion of the worlds AI-produced treasures.'),\n",
              " (0.3246594374000056,\n",
              "  'Machine learning has been propelled dramatically forward by impressive empirical successes of artificial neural networks, which can now be trained with huge data sets and large-scale computing.'),\n",
              " (0.3246594374000056,\n",
              "  'Innovations relying on computer-based vision, speech recognition, and Natural Language Processing have driven these changes, as have concurrent scientific and technological advances in related fields.'),\n",
              " (0.3246594374000056,\n",
              "  'Better chips, low-cost 3D sensors, cloud-based machine learning, and advances in speech understanding will enhance future robots services and their interactions with people.'),\n",
              " (0.3246594374000056,\n",
              "  'As cars become better drivers than people, city-dwellers will own fewer cars, live further from work, and spend time differently, leading to an entirely new urban organization.'),\n",
              " (0.32465943371085215,\n",
              "  'Internet of Things (IoT) research is devoted to the idea that a wide array of devices, including appliances, vehicles, buildings, and cameras, can be interconnected to collect and share their abundant sensory information to use for intelligent purposes.'),\n",
              " (0.32465943371085215,\n",
              "  'Deep learning, a class of learning procedures, has facilitated object recognition in images, video labeling, and activity recognition, and is making significant inroads into other areas of perception, such as audio, speech, and natural language processing.'),\n",
              " (0.32465943371085215,\n",
              "  'Artificial Intelligence (AI) is a science and a set of computational technologies that are inspired bybut typically operate quite differently fromthe ways people use their nervous systems and bodies to sense, learn, reason, and take action.'),\n",
              " (0.3246594325575807,\n",
              "  'In Healthcare, there has been an immense forward leap in collecting useful data from personal monitoring devices and mobile apps, from electronic health records (EHR) in clinical settings and, to a lesser extent, from surgical robots designed to assist with medical procedures and service robots supporting hospital operations.'),\n",
              " (0.32465943066861364,\n",
              "  'With targeted incentives and funding priorities, Society is now at a crucial juncture in determining how to deploy AI-based technologies in ways that promote rather than hinder democratic values such as freedom, equality, and transparency.'),\n",
              " (0.32465943066861364,\n",
              "  'This approach has been come to be known as deep learning. The leap in the performance of information processing algorithms has been accompanied by significant progress in hardware technology for basic operations such as sensing, perception, and object recognition.'),\n",
              " (0.32465943066861364,\n",
              "  'Crowdsourcing and human computation research investigates methods to augment computer systems by making automated calls to human expertise to solve problems that computers alone cannot solve well.'),\n",
              " (0.32465943066861364,\n",
              "  'And while the potential to abuse AI technologies must be acknowledged and addressed, their greater potential is, among other things, to make driving safer, help children learn, and extend and enhance peoples lives.'),\n",
              " (0.3246594306686135,\n",
              "  'Well-deployed AI prediction tools have the potential to provide new kinds of transparency about data and inferences, and may be applied to detect, remove, or reduce human bias, rather than reinforcing it.'),\n",
              " (0.3246594306686135,\n",
              "  'If society approaches these technologies primarily with fear and suspicion, missteps that slow AIs development or drive it underground will result, impeding important work on ensuring the safety and reliability of AI technologies.'),\n",
              " (0.3246594299875998,\n",
              "  'Natural Language Processing, machine learning, and crowdsourcing have boosted online learning and enabled teachers in higher education to multiply the size of their classrooms while addressing individual students learning needs and styles.'),\n",
              " (0.3246594299875998,\n",
              "  'Major research universities devote departments to AI studies, and technology companies such as Apple, Facebook, Google, IBM, and Microsoft spend heavily to explore AI applications they regard as critical to their futures.'),\n",
              " (0.3246594299875998,\n",
              "  'In similarly targeted applications, substantial increases in the future uses of AI technologies, including more self-driving cars, healthcare diagnostics and targeted treatments, and physical assistance for elder care can be expected.'),\n",
              " (0.3246594299875998,\n",
              "  'Entertainment has been transformed by social networks and other platforms for sharing and browsing blogs, videos, and photos, which rely on techniques actively developed in NLP, information retrieval, image processing, crowdsourcing, and machine learning.'),\n",
              " (0.32465942824199295,\n",
              "  'Over the next fifteen years in a typical North American city, the use of these technologies in the classroom and in the home is likely to expand significantly, provided they can be meaningfully integrated with face-to-face learning.'),\n",
              " (0.32465942824199295,\n",
              "  'Improvements in safe and reliable hardware will spur innovation over the next fifteen years, as they will with Home/Service Robots, which have already entered peoples houses, primarily in the form of vacuum cleaners.'),\n",
              " (0.3246594282419929,\n",
              "  'The field of AI is shifting toward building intelligent systems that can collaborate effectively with people, including creative ways to develop interactive and scalable ways for people to teach robots.'),\n",
              " (0.32465942684209553,\n",
              "  'Algorithmic game theory and computational social choice draw attention to the economic and social computing dimensions of AI, such as how systems can handle potentially misaligned incentives, including self-interested human participants or firms and the automated AI-based agents representing them.'),\n",
              " (0.32465942587530544,\n",
              "  'These trends drive the currently hot areas of AI research into both fundamental methods and application areas: Large-scale machine learning concerns the design of learning algorithms, as well as scaling existing algorithms, to work with extremely large data sets.'),\n",
              " (0.32465942103123047,\n",
              "  'Neuromorphic computing is a set of technologies that seek to mimic biological neural networks to improve the hardware efficiency and robustness of computing systems, often replacing an older emphasis on separate modules for input/ output, instruction-processing, and memory.'),\n",
              " (0.3246594210312304,\n",
              "  'The Study Panel further narrowed its inquiry to eight domains where AI is already having or is projected to have the greatest impact: transportation, healthcare, education, low-resource communities, public safety and security, employment and workplace, home/service robots, and entertainment.'),\n",
              " (0.3246594210312304,\n",
              "  'For example, in a mere fifteen years in a typical North American citythe time frame and scope of this report AI applications are likely to transform transportation toward self-driving vehicles with on-time pickup and delivery of people and packages.'),\n",
              " (0.3246594210312304,\n",
              "  'Deep learning, a form of machine learning based on layered representations of variables referred to as neural networks, has made speech-understanding practical on our phones and in our kitchens, and its algorithms can be applied widely to an array of applications that rely on pattern recognition.'),\n",
              " (0.3246594203292699,\n",
              "  'Now, as it becomes a central force in society, the field of AI is shifting toward building intelligent systems that can collaborate effectively with people, and that are more generally human-aware, including creative ways to develop interactive and scalable ways for people to teach robots.'),\n",
              " (0.32465941896937783,\n",
              "  'Using data mining and machine learning, for example, AI has been used to create predictive models to help government agencies address issues such as prevention of lead poisoning in at-risk children and distribution of food efficiently.'),\n",
              " (0.32465941896937783,\n",
              "  'At the same time, many of these developments will spur disruptions in Substantial increases in the future uses of AI applications, including more self-driving cars, healthcare diagnostics and targeted treatment, and physical assistance for elder care can be expected.'),\n",
              " (0.32465940998202464,\n",
              "  'Application design and policy decisions made in the near term are likely to have long-lasting influences on the nature and directions of such developments, making it important for AI researchers, developers, social scientists, and policymakers to balance the imperative to innovate with mechanisms to ensure that AIs economic and social benefits are broadly shared across society.'),\n",
              " (0.3246593787409826,\n",
              "  'Starting from a charge given by the AI100 Standing Committee to consider the likely influences of AI in a typical North American city by the year 2030, the 2015 Study Panel, comprising experts in AI and other relevant areas focused their attention on eight domains they considered most salient: transportation; service robots; healthcare; education; low-resource communities; public safety and security; employment and workplace; and entertainment.'),\n",
              " (0.32465936686934516,\n",
              "  'Each domain faces varied AI-related challenges, including the difficulty of creating safe and reliable hardware for sensing and effecting (transportation and service robots), the difficulty of smoothly interacting with human experts (healthcare and education), the challenge of gaining public trust (low-resource communities and public safety and security), the challenge of overcoming fears of marginalizing humans (employment and workplace) and the risk of diminishing interpersonal interaction (entertainment).'),\n",
              " (0.324659358431399,\n",
              "  'Though drawing from a common source of research, each domain reflects different AI influences and challenges, such as the difficulty of creating safe and reliable hardware (transportation and service robots), the difficulty of smoothly interacting with human experts (healthcare and education), the challenge of gaining public trust (low-resource communities and public safety and security), the challenge of overcoming fears of marginalizing humans (employment and workplace), and the social and societal risk of diminishing interpersonal interactions (entertainment).'),\n",
              " (0.324659358431399,\n",
              "  'Study Panel: Peter Stone, Chair, University of Texas at Austin, Rodney Brooks, Rethink Robotics, Erik Brynjolfsson, Massachussets Institute of Technology, Ryan Calo, University of Washington, Oren Etzioni, Allen Institute for AI, Greg Hager, Johns Hopkins University, Julia Hirschberg, Columbia University, Shivaram Kalyanakrishnan, Indian Institute of Technology Bombay, Ece Kamar, Microsoft Research, Sarit Kraus, Bar Ilan University.'),\n",
              " (0.32465932096047756,\n",
              "  'Kevin Leyton-Brown, University of British Columbia, David Parkes, Harvard University, William Press, University of Texas at Austin, AnnaLee (Anno) Saxenian, University of California, Berkeley, Julie Shah, Massachussets Institute of Technology, Milind Tambe, University of Southern California, Astro Teller, X Standing Committee of the One Hundred Year Study of Artificial Intelligence: Barbara J. Grosz, Chair, Russ Altman, Eric Horvitz, Alan Mackworth, Tom Mitchell, Deidre Mulligan, Yoav Shoham While drawing on common research and technologies, AI systems are specialized to accomplish particular tasks.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCaIPaTdpBMN",
        "colab_type": "code",
        "outputId": "eb302ea6-a36a-4a7f-f49d-1954b2a0465f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "#sorting the sentences in the reverse manner for getting sentences with high scores and printing them.\n",
        "for i in range(10):\n",
        "  print(ranked_sentences[i][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 AI policy, now and\n",
            "Whats next for AI research?\n",
            "While impressive, these technologies are highly tailored to particular tasks.\n",
            "AI is also changing how people interact with technology.\n",
            "Great strides have also been made in machine translation among different languages, with more real-time person-to-person exchanges on the near horizon.\n",
            "Peoples future relationships with machines will become ever more nuanced, fluid, and personalized as AI systems learn to adapt to individual personalities and goals.\n",
            "Once a mostly academic area of study, twenty-first century AI enables a constellation of mainstream technologies that are having a substantial impact on everyday lives.\n",
            "On the other hand, if society approaches AI with a more open mind, the technologies emerging from the field could profoundly transform society for the better in the coming decades.\n",
            "Instead, increasingly useful applications of AI, with potentially profound positive impacts on our society and economy are likely to emerge between now and 2030, the period this report considers.\n",
            "In each domain, even as AI continues to deliver important benefits, it also raises important ethical and social issues, including privacy concerns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWhEv1dpEul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}